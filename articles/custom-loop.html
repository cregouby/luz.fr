<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="fr">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Boucles personnalisées avec luz • luz.fr</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Boucles personnalisées avec luz">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Passer au contenu</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Navigation sur le site"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">luz.fr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Activer la navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><h6 class="dropdown-header" data-toc-skip>Utiliser luz</h6></li>
    <li><a class="dropdown-item" href="../articles/get-started.html">Bien démarrer</a></li>
    <li><a class="dropdown-item" href="../articles/custom-loop.html">Boucles personnalisées</a></li>
    <li><a class="dropdown-item" href="../articles/accelerator.html">l'API des périphériques d'accélération</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Guides</h6></li>
    <li><a class="dropdown-item" href="../articles/lr-finder.html">Recherche du taux d'apprentissage avec lr_finder</a></li>
    <li><a class="dropdown-item" href="../articles/checkpoints.html">Instantannés de modèles</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../articles/examples/index.html">Examples</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Référence</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changements</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlverse/luz/"><span class="fa fab fa-github fa-lg"></span> Contribuer</a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Boucles personnalisées avec luz</h1>
            
      
      <small class="dont-index">Source : <a href="https://github.com/cregouby/luz.fr/blob/HEAD/vignettes/custom-loop.Rmd" class="external-link"><code>vignettes/custom-loop.Rmd</code></a></small>
      <div class="d-none name"><code>custom-loop.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs" class="external-link">torch</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlverse.github.io/luz/" class="external-link">luz</a></span><span class="op">)</span></span></code></pre></div>
<p>Luz est une interface (API) de haut niveau pour torch, conçue pour
être très flexible, et ainsi d’avoir un contrôle complêt sur la boucle
d’entraînement.</p>
<p>Dans la <code><a href="../articles/get-started.html">vignette("get-started")</a></code>, nous avons vu les bases
de luz et comment modifier facilement des parties de la boucle
d’entraînement à l’aide de rappels (callbacks) et de métriques
personnalisées. Dans ce document, nous allons décrire en détail comment
luz permet à l’utilisateur d’avoir un contrôle très fin sur la boucle
d’entraînement.</p>
<p>Outre l’utilisation de callbacks, il existe trois autres façons
d’utiliser luz (en fonction du niveau de contrôle nécessaire) :</p>
<ul>
<li><p><strong>Optimiseurs ou fonctions de perte multiples</strong> :
Vous pouvez optimiser deux fonctions de perte, chacune avec son propre
optimiseur, tout en maintenant la possibilité de ne pas modifier les
appels <code>backward()</code> - <code>zero_grad()</code> et
<code><a href="https://rdrr.io/r/stats/step.html" class="external-link">step()</a></code>. C’est commun dans les modèles comme les GANs
(Réseaux Adversaires Génératifs) lorsqu’on a des réseaux neuronaux
concurrents entraînés avec différentes pertes et optimiseurs.</p></li>
<li><p><strong>Étapes complètement flexibles</strong> : Vous pouvez
contrôler complètement comment appeler <code>backward()</code>,
<code>zero_grad()</code> et <code><a href="https://rdrr.io/r/stats/step.html" class="external-link">step()</a></code>. Vous pouvez aussi avoir
un contrôle plus grand sur la calcul de gradients. Par exemple, vous
pouvez utiliser des ‘tailles de lot virtuelles’, où vous accumulez les
gradients pendant quelques étapes avant d’actualiser les poids.</p></li>
<li><p><strong>Boucles complètement flexibles</strong> : Votre boucle
d’entraînement peut être entièrement redessinée, et dans ce cas vous
utiliser luz pour gérer uniquement le déplacement des chargeurs de
données, optimiseurs et modèles vers un périphérique. Voir la
<code><a href="../articles/accelerator.html">vignette("accelerator")</a></code>.</p></li>
</ul>
<p>Considérons une version simplifiée du réseau <code>net</code> que
nous avons implémenté dans la <code><a href="../articles/get-started.html">vignette("get-started")</a></code> :</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">net</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_module.html" class="external-link">nn_module</a></span><span class="op">(</span></span>
<span>  <span class="st">"Net"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">fc1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">fc2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">fc1</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_relu.html" class="external-link">nnf_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">fc2</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>En utilisant l’API de haut niveau de luz, on peut l’entraîner comme
suit :</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitted</span> <span class="op">&lt;-</span> <span class="va">net</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="../reference/setup.html">setup</a></span><span class="op">(</span></span>
<span>    loss <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_cross_entropy_loss.html" class="external-link">nn_cross_entropy_loss</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    optimizer <span class="op">=</span> <span class="va">optim_adam</span>,</span>
<span>    metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      <span class="va">luz_metric_accuracy</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">fit</span><span class="op">(</span><span class="va">train_dl</span>, epochs <span class="op">=</span> <span class="fl">10</span>, valid_data <span class="op">=</span> <span class="va">test_dl</span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="optimiseurs-multiples">Optimiseurs multiples<a class="anchor" aria-label="anchor" href="#optimiseurs-multiples"></a>
</h2>
<p>Supposons que notre expérience consiste à ajuster la première couche
de connexion complète avec un taux d’apprentissage de 0.1 et la deuxième
avec un taux d’apprentissage de 0.01. Nous allons minimiser la même
<code><a href="https://rdrr.io/pkg/torch/man/nn_cross_entropy_loss.html" class="external-link">nn_cross_entropy_loss()</a></code> pour les deux couches, mais pour la
première, disons que nous voulons ajouter une régularisation L1.</p>
<p>Pour y arriver avec luz, on va ajouter deux méthodes à notre module
<code>net</code> :</p>
<ul>
<li><p><code>set_optimizers</code>: qui renvoie une liste d’optimiseurs
en fonction du contexte <code>ctx</code>.</p></li>
<li><p><code>loss</code>: qui calcule une fonction de coût différente
suivant l’optimiseur.</p></li>
</ul>
<p>Voyons le résultat dans le code :</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">net</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_module.html" class="external-link">nn_module</a></span><span class="op">(</span></span>
<span>  <span class="st">"Net"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">fc1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">fc1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">fc1</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_relu.html" class="external-link">nnf_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">fc2</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  set_optimizers <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">lr_fc1</span> <span class="op">=</span> <span class="fl">0.1</span>, <span class="va">lr_fc2</span> <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      opt_fc1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/optim_adam.html" class="external-link">optim_adam</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">fc1</span><span class="op">$</span><span class="va">parameters</span>, lr <span class="op">=</span> <span class="va">lr_fc1</span><span class="op">)</span>,</span>
<span>      opt_fc2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/optim_adam.html" class="external-link">optim_adam</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">fc2</span><span class="op">$</span><span class="va">parameters</span>, lr <span class="op">=</span> <span class="va">lr_fc2</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  loss <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">input</span>, <span class="va">target</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">pred</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="fu">model</span><span class="op">(</span><span class="va">input</span><span class="op">)</span></span>
<span>  </span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">opt_name</span> <span class="op">==</span> <span class="st">"opt_fc1"</span><span class="op">)</span> </span>
<span>      <span class="co"># ajout d'une régularisation L1 sur la couche 1</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_cross_entropy.html" class="external-link">nnf_cross_entropy</a></span><span class="op">(</span><span class="va">pred</span>, <span class="va">target</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/torch_norm.html" class="external-link">torch_norm</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">fc1</span><span class="op">$</span><span class="va">weight</span>, p <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span>    <span class="kw">else</span> <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">opt_name</span> <span class="op">==</span> <span class="st">"opt_fc2"</span><span class="op">)</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_cross_entropy.html" class="external-link">nnf_cross_entropy</a></span><span class="op">(</span><span class="va">pred</span>, <span class="va">target</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Il faut noter que l’initialisation des optimiseurs se fera avec le
résultat de la méthode <code>set_optimizers()</code> qui est une liste.
Et donc ici, nous aurons bien deux optimiseurs différents, appliqués
chacuns à des paramêtres du modèle différents, et avec un taux
d’apprentissage spécifique.</p>
<p>La méthode <code>loss()</code> a en charge le calcul de la fonction
de coût, pour faire la retro-propagation des gradients et mettre à jour
les poids du modèle. Cette méthode <code>loss()</code> accède à l’objet
<code>ctx</code> qui contient une variable <code>opt_name</code>
décrivant l’optimiseur en cours d’utilisation. On note que cette
fonction sera appellée une fois par optimiseur et par étape de la boucke
d’entrainement et de la boucle de validation. Référez vous à
<code><a href="../reference/ctx.html">help("ctx")</a></code> pour une information complète sur l’objet
contexte.</p>
<p>On peut maintenant utiliser <code>setup</code> et <code>fit</code>
avec ce module, mais sans préciser ni les paramêtres d’optimiseurs ni de
fonction de coût.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitted</span> <span class="op">&lt;-</span> <span class="va">net</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="../reference/setup.html">setup</a></span><span class="op">(</span>metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">luz_metric_accuracy</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>  <span class="fu">fit</span><span class="op">(</span><span class="va">train_dl</span>, epochs <span class="op">=</span> <span class="fl">10</span>, valid_data <span class="op">=</span> <span class="va">test_dl</span><span class="op">)</span></span></code></pre></div>
<p>Maintenant, nous allons re-implementer ce même modèle en utilisant
une approche légèrement plus flexible qui consiste à surcharger l’étape
d’apprentissage et de validation.</p>
</div>
<div class="section level2">
<h2 id="étape-complètement-flexible">Étape complètement flexible<a class="anchor" aria-label="anchor" href="#%C3%A9tape-compl%C3%A8tement-flexible"></a>
</h2>
<p>Au lieu d’implémenter la méthode <code>loss()</code>, nous pouvons
implémenter la méthode <code><a href="https://rdrr.io/r/stats/step.html" class="external-link">step()</a></code>. Cela permet de modifier en
toute flexibilité ce qui se passe lors de l’apprentissage et de la
validation pour chaque lot du jeu de données. C’est votre code qui est
maintenant responsable de mettre à jour les poids du modèle à chaque
appel des optimiseurs par retro-propagation des gradients.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">net</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_module.html" class="external-link">nn_module</a></span><span class="op">(</span></span>
<span>  <span class="st">"Net"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">fc1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">fc1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">fc1</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_relu.html" class="external-link">nnf_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">fc2</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  set_optimizers <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">lr_fc1</span> <span class="op">=</span> <span class="fl">0.1</span>, <span class="va">lr_fc2</span> <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      opt_fc1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/optim_adam.html" class="external-link">optim_adam</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">fc1</span><span class="op">$</span><span class="va">parameters</span>, lr <span class="op">=</span> <span class="va">lr_fc1</span><span class="op">)</span>,</span>
<span>      opt_fc2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/optim_adam.html" class="external-link">optim_adam</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">fc2</span><span class="op">$</span><span class="va">parameters</span>, lr <span class="op">=</span> <span class="va">lr_fc2</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  step <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">ctx</span><span class="op">$</span><span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="kw">for</span> <span class="op">(</span><span class="va">opt_name</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">optimizers</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>      <span class="va">ctx</span><span class="op">$</span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="fu">model</span><span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">input</span><span class="op">)</span></span>
<span>      <span class="va">opt</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="va">optimizers</span><span class="op">[[</span><span class="va">opt_name</span><span class="op">]</span><span class="op">]</span></span>
<span>      <span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_cross_entropy.html" class="external-link">nnf_cross_entropy</a></span><span class="op">(</span><span class="va">pred</span>, <span class="va">target</span><span class="op">)</span></span>
<span>      </span>
<span>      <span class="kw">if</span> <span class="op">(</span><span class="va">opt_name</span> <span class="op">==</span> <span class="st">"opt_fc1"</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="co"># ajout d'une régularisation L1 sur la couche 1</span></span>
<span>        <span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_cross_entropy.html" class="external-link">nnf_cross_entropy</a></span><span class="op">(</span><span class="va">pred</span>, <span class="va">target</span><span class="op">)</span> <span class="op">+</span> </span>
<span>          <span class="fu"><a href="https://rdrr.io/pkg/torch/man/torch_norm.html" class="external-link">torch_norm</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">fc1</span><span class="op">$</span><span class="va">weight</span>, p <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span>      <span class="op">}</span></span>
<span>        </span>
<span>      <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">training</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="va">opt</span><span class="op">$</span><span class="fu">zero_grad</span><span class="op">(</span><span class="op">)</span></span>
<span>        <span class="va">loss</span><span class="op">$</span><span class="fu">backward</span><span class="op">(</span><span class="op">)</span></span>
<span>        <span class="va">opt</span><span class="op">$</span><span class="fu">step</span><span class="op">(</span><span class="op">)</span>  </span>
<span>      <span class="op">}</span></span>
<span>      </span>
<span>      <span class="va">ctx</span><span class="op">$</span><span class="va">loss</span><span class="op">[[</span><span class="va">opt_name</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">loss</span><span class="op">$</span><span class="kw">detach</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Les choses importantes à noter ici sont :</p>
<ul>
<li><p>La méthode <code><a href="https://rdrr.io/r/stats/step.html" class="external-link">step()</a></code> est utilisée pour l’apprentissage
et la validation. Vous devez être prudent car vous ne devez modifier les
poids que pendant la phase d’apprentissage. Encore une fois, vous pouvez
obtenir des informations complètes sur l’objet de contexte avec
<code><a href="../reference/ctx.html">help("ctx")</a></code>.</p></li>
<li><p><code>ctx$optimizers</code> est une liste nommée contenant chaque
optimiseur qui a été créé lorsqu’on a appellé la méthode
<code>set_optimizers()</code>.</p></li>
<li><p>Vous devez assurer le suivi les pertes en cours de modification
en les enregistrant dans une liste nommée dans <code>ctx$loss</code>.
Conformément à la convention, nous réutilisons le nom que l’optimiseur
auquel elle se réfère. Il est recommandé de les déconnecter avec
<code>$detach()</code> avant leur sauvegarde pour réduire la
consommation de mémoire.</p></li>
<li><p>Les rappels qui seraient déclenchés dans la méthode
<code><a href="https://rdrr.io/r/stats/step.html" class="external-link">step()</a></code> par défaut comme
<code>on_train_batch_after_pred</code>,
<code>on_train_batch_after_loss</code>, etc., ne seront pas
automatiquement appelés. Vous pouvez toujours les déclencher
manuellement en ajoutant
<code>ctx$call_callbacks("&lt;nom du rappel&gt;</code>)<code>à l'intérieur de votre  étape d'apprentissage. Étudiez le code de</code>fit_one_batch()<code>et</code>valid_one_batch`
pour identifier tous les rappels qui ne seront pas déclenchés.</p></li>
<li><p>Si vous voulez que les métriques luz fonctionnent avec votre
méthode <code><a href="https://rdrr.io/r/stats/step.html" class="external-link">step()</a></code> personnalisée, vous devez assigner
<code>ctx$pred</code> aux prédictions du modèle car les métriques seront
toujours appelées avec
<code>metric$update(ctx$pred, ctx$target)</code>.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="étapes-suivantes">Étapes suivantes<a class="anchor" aria-label="anchor" href="#%C3%A9tapes-suivantes"></a>
</h2>
<p>Dans cet article, vous avez appris à personnaliser l’étape de
formation du boucle d’apprentissage en utilisant les fonctionnalités en
couche de luz.</p>
<p>Luz permet également des modifications plus flexibles de la boucle
d’apprentissage décrites dans le vignette “Accélérateur”
(<code><a href="../articles/accelerator.html">vignette("accelerator")</a></code>).</p>
<p>Vous devriez maintenant pouvoir suivre les exemples marqués avec les
catégories ‘intermédiaire’ et ‘avancé’ dans la galerie des <a href="https://mlverse.github.io/luz/articles/examples/index.html" class="external-link">exemples</a>
de luz</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table des matières"><h2>Sur cette page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Développé par Christophe Regouby.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site créé avec <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
