[{"path":"https://cregouby.github.io/luz.fr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 luz.fr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://cregouby.github.io/luz.fr/articles/accelerator.html","id":"exemple","dir":"Articles","previous_headings":"","what":"Exemple","title":"L'API des accélérateurs","text":"L’usage est facile à comprendre sur un exemple de différence diff du code avec une boucle d’apprentissage torch brut. Au travers des modifications de code mises en valeur, vous comprenez que vous n’avez plus besoin de déplacer manuellement les données et les modèles entre périphériques, ce qui rend votre code plus lisible et moins sujet aux erreurs. Vous pouvez trouver des informations supplémentaires en utilisant help(accelerator).","code":"library(torch) + library(luz)  + acc <- accelerator() - device <- \"cpu\"  data <- tensor_dataset(   x = torch_randn(100, 10),   y = torch_rand(100, 1) )  dl <- dataloader(data, batch_size = 10)  model <- nn_linear(10, 1) - model$to(device = device) opt <- optim_adam(model$parameters)  + c(model, opt, dl) %<-% acc$prepare(model, opt, dl)  model$train() coro::loop(for (batch in dl) {    opt$zero_grad()  -  preds <- model(batch$x$to(device = device)) +  preds <- model(batch$x) -  loss <- nnf_mse_loss(preds, batch$y$to(device = device)) +  loss <- nnf_mse_loss(preds, batch$y)    loss$backward()   opt$step() })"},{"path":"https://cregouby.github.io/luz.fr/articles/checkpoints.html","id":"relancer-des-apprentissages-qui-ont-échoués","dir":"Articles","previous_headings":"","what":"Relancer des apprentissages qui ont échoués","title":"Sauvegarder des instantannés de vos modèle","text":"Si vous avez un long processus d’apprentissage qui peut échouer pour n’importe quelle raison (ordinateur coupé, noeud d’un cluster perdu, etc), il est recommandé d’ajouter luz_callback_autoresume() à votre liste de callbacks. luz_callback_autoresume() sauvegardera automatiquement tout l’état de votre modèle à la fin de chaque époque. Si quelque chose se passe mal pendant l’apprentissage, vous pouvez simplement relancer le même script, sans aucun changement, le dernier instantanné du modèle sera rechargé et l’apprentissage reprendra là où il s’est arrêté. Par exemple, prennons un jeu de données d’entraînement aléatoire généré et un modèle linéaire pour montrer comment fonctionne autoresume. Voici les données d’entraînement : Et la définition du modèle : Voici comment créer un callbacks qui simule une erreur aléatoire. Ce callbacks lève juste une erreur d’exécution R à la 5ème époque d’apprentissage du modèle. Ccommençons par entraîner en ajoutant le luz_callback_auto_resume(): Pour relancer l’apprentissage du modèle exactement là où il s’est arrêté, vous n’avez qu’à relancer la fonction fit() avec le même modèle, les callbacks, etc. : Ainsi, le processus l’apprentissage du modèle continuera exactement là où il s’est arrêté. Les registres (de métriques et de pertes), l’optimiseur et l’état du modèle sont récupérés à partir de l’état précédent pour avoir les résultats complets :","code":"x <- torch_randn(1000, 10) y <- torch_randn(1000, 1) model <- nn_linear %>%   setup(optimizer = optim_sgd, loss = nnf_mse_loss) %>%   set_hparams(in_features = 10, out_features = 1) %>%   set_opt_hparams(lr = 0.01) interrupt <- luz_callback(   \"interrupt\",   failed = FALSE,   on_epoch_end = function() {     if (ctx$epoch == 5 && !self$failed) {       self$failed <- TRUE       stop(\"Error on epoch 5\")     }   } ) autoresume <- luz_callback_auto_resume(path = \"state.pt\") inter <- interrupt()  # Une erreur se produira à la 5ème époque et le modèle sera arrêté. results <- model %>% fit(   list(x, y),   callbacks = list(inter, autoresume),   verbose = FALSE ) #> Error in get(paste0(generic, \".\", class), envir = get_method_env()) :  #>   objet 'type_sum.accel' introuvable #> Error in `FUN()`: #> ! Error while calling callback with class <interrupt/LuzCallback/R6> at #>   on_epoch_end. #> Caused by error in `self[[callback_nm]]()`: #> ! Error on epoch 5 results <- model %>% fit(   list(x, y),   callbacks = list(inter, autoresume),   verbose = FALSE ) plot(results)"},{"path":"https://cregouby.github.io/luz.fr/articles/checkpoints.html","id":"sauvegarde-automatique","dir":"Articles","previous_headings":"","what":"Sauvegarde automatique","title":"Sauvegarder des instantannés de vos modèle","text":"Si vous désirez avoir un contrôle plus fin sur la façon dont les sauvegardes sont gérées, vous pouvez utiliser luz_callback_model_checkpoint() pour enregistrer des sauvegardes dans un fichier ou un répertoire spécifié. Essayons d’utiliser le même exemple que dans la section précédente : Nous générerons d’abord quelques données. Définissons à nouveau notre modèle : Entraînons maintenant le modèle en utilisant luz_callback_model_checkpoint(). Vous pouvez maintenant voir que le répertoire checkpoints contient des fichiers avec des sauvegardes de l’état pour chaque epoch. Par défaut, luz_callback_model_checkpoint enregistrera l’état pour chaque epochs et formattera le nom en y incluant la valeur de la perte. Ce formattage peut être configuré dans le paramètre path, voir ?luz_callback_model_checkpoint pour plus de détails. Enfin, vous pouvez charger une sauvegarde spécifique dans le modèle entrainé à l’aide de luz_load_checkpoint. Notez que la chargement de la sauvegarde dans un module fitted remplace les poids sur le modèle en mémoire. Vous pouvez ensuite commencer à faire des prédictions ou évaluer votre modèle avec les poids tout juste chargés. Si vous voullez démarrer une nouvelle époque d’apprentissage depuis une sauvegarde, vous pouvez utiliser luz_callback_resume_from_checkpoint() . Par défaut, il n’aura enregistré que les poids du modèle dans le fichier de sauvegarde, mais vous pouvez configurer pour restorer aussi les registres, callbacks et états de l’optimiseur. Si le répertoire des sauvegardes existantes est indiqué, alors l’apprentissage reprendra à partir du dernier fichier de sauvegarde renvoyé par fs::dir_ls. Voici comment utiliser ce callbacks :","code":"x <- torch_randn(1000, 10) y <- torch_randn(1000, 1) model <- nn_linear %>%   setup(optimizer = optim_sgd, loss = nnf_mse_loss) %>%   set_hparams(in_features = 10, out_features = 1) %>%   set_opt_hparams(lr = 0.01) checkpoint <- luz_callback_model_checkpoint(   path = \"checkpoints/\",    monitor = \"train_loss\" )  results <- model %>% fit(   list(x, y),   callbacks = list(checkpoint),   verbose = FALSE ) fs::dir_ls(\"checkpoints\") #> checkpoints/epoch-01-train_loss-1.237.pt #> checkpoints/epoch-02-train_loss-1.065.pt #> checkpoints/epoch-03-train_loss-1.026.pt #> checkpoints/epoch-04-train_loss-1.004.pt #> checkpoints/epoch-05-train_loss-1.004.pt #> checkpoints/epoch-06-train_loss-1.005.pt #> checkpoints/epoch-07-train_loss-0.999.pt #> checkpoints/epoch-08-train_loss-0.998.pt #> checkpoints/epoch-09-train_loss-1.001.pt #> checkpoints/epoch-10-train_loss-1.002.pt luz_load_checkpoint(results, fs::dir_ls(\"checkpoints\")[1]) resume <- luz_callback_resume_from_checkpoint(path = \"checkpoints/\") results <- model %>% fit(   list(x, y),   callbacks = list(resume),   verbose = FALSE ) plot(results)"},{"path":"https://cregouby.github.io/luz.fr/articles/checkpoints.html","id":"états-des-callbacks-personnalisés","dir":"Articles","previous_headings":"Sauvegarde automatique","what":"États des callbacks personnalisés","title":"Sauvegarder des instantannés de vos modèle","text":"Parfois, les rappels ont également besoin de conserver leurs états internes afin de continuer l’apprentissage exactement à partir là où il s’est arrêté. Dans ce cas, les callbacks peuvent mettre en œuvre les méthodes state_dict() et le load_state_dict() qui sont appelées automatiquement lors des sauvegardes et rechargements. Par exemple, imaginez que vous avez crée un callbacks qui suit les gradients des poids du modèle à chaque epoch. Vous voulez utiliser les poids suivis pour analyser plus en profondeur la procédure d’apprentissage. Ce rappel pourrait être configuré comme suit: Dans l’exemple ci-dessus, le champ gradients est un état dans le callbacks. Si l’apprentissage échoue pour une raison quelconque, les états seront perdues. Nous pouvons le rendre persistant en utilisant les méthodes state_dict() et load_state_dict() comme suit :","code":"cb_weight_grad <- luz_callback(   \"weight_grad\",   gradients = list(),   initialize = function(track_weights) {     self$track_weights   },   on_train_batch_before_step = function() {     gradients[[ctx$epoch]] <- list()     for (w in self$track_weights) {       gradients[[ctx$epoch]][[w]] <- self$model$parameters[[w]]     }   } ) cb_weight_grad <- luz_callback(   \"weight_grad\",   gradients = list(),   initialize = function(track_weights) {     self$track_weights   },   on_train_batch_before_step = function() {     gradients[[ctx$epoch]] <- list()     for (w in self$track_weights) {       gradients[[ctx$epoch]][[w]] <- self$model$parameters[[w]]     }   },   state_dict = function() {     list(gradients = self$gradients)   },   load_state_dict = function(d) {     self$gradients <- d$gradients   } )"},{"path":"https://cregouby.github.io/luz.fr/articles/custom-loop.html","id":"optimiseurs-multiples","dir":"Articles","previous_headings":"","what":"Optimiseurs multiples","title":"Boucles personnalisées avec luz","text":"Supposons que notre expérience consiste à ajuster la première couche de connexion complète avec un taux d’apprentissage de 0.1 et la deuxième avec un taux d’apprentissage de 0.01. Nous allons minimiser la même nn_cross_entropy_loss() pour les deux couches, mais pour la première, disons que nous voulons ajouter une régularisation L1. Pour y arriver avec luz, va ajouter deux méthodes à notre module net : set_optimizers: qui renvoie une liste d’optimiseurs en fonction du contexte ctx. loss: qui calcule une fonction de coût différente suivant l’optimiseur. Voyons le résultat dans le code : Il faut noter que l’initialisation des optimiseurs se fera avec le résultat de la méthode set_optimizers() qui est une liste. Et donc ici, nous aurons bien deux optimiseurs différents, appliqués chacuns à des paramêtres du modèle différents, et avec un taux d’apprentissage spécifique. La méthode loss() en charge le calcul de la fonction de coût, pour faire la retro-propagation des gradients et mettre à jour les poids du modèle. Cette méthode loss() accède à l’objet ctx qui contient une variable opt_name décrivant l’optimiseur en cours d’utilisation. note que cette fonction sera appellée une fois par optimiseur et par étape de la boucke d’entrainement et de la boucle de validation. Référez vous à help(\"ctx\") pour une information complète sur l’objet contexte. peut maintenant utiliser setup et fit avec ce module, mais sans préciser ni les paramêtres d’optimiseurs ni de fonction de coût. Maintenant, nous allons re-implementer ce même modèle en utilisant une approche légèrement plus flexible qui consiste à surcharger l’étape d’apprentissage et de validation.","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$fc1 <- nn_linear(100, 50)     self$fc1 <- nn_linear(50, 10)   },   forward = function(x) {     x %>%        self$fc1() %>%        nnf_relu() %>%        self$fc2()   },   set_optimizers = function(lr_fc1 = 0.1, lr_fc2 = 0.01) {     list(       opt_fc1 = optim_adam(self$fc1$parameters, lr = lr_fc1),       opt_fc2 = optim_adam(self$fc2$parameters, lr = lr_fc2)     )   },   loss = function(input, target) {     pred <- ctx$model(input)        if (ctx$opt_name == \"opt_fc1\")        # ajout d'une régularisation L1 sur la couche 1       nnf_cross_entropy(pred, target) + torch_norm(self$fc1$weight, p = 1)     else if (ctx$opt_name == \"opt_fc2\")       nnf_cross_entropy(pred, target)   } ) fitted <- net %>%    setup(metrics = list(luz_metric_accuracy)) %>%    fit(train_dl, epochs = 10, valid_data = test_dl)"},{"path":"https://cregouby.github.io/luz.fr/articles/custom-loop.html","id":"étape-complètement-flexible","dir":"Articles","previous_headings":"","what":"Étape complètement flexible","title":"Boucles personnalisées avec luz","text":"Au lieu d’implémenter la méthode loss(), nous pouvons implémenter la méthode step(). Cela permet de modifier en toute flexibilité ce qui se passe lors de l’apprentissage et de la validation pour chaque lot du jeu de données. C’est votre code qui est maintenant responsable de mettre à jour les poids du modèle à chaque appel des optimiseurs par retro-propagation des gradients. Les choses importantes à noter ici sont : La méthode step() est utilisée pour l’apprentissage et la validation. Vous devez être prudent car vous ne devez modifier les poids que pendant la phase d’apprentissage. Encore une fois, vous pouvez obtenir des informations complètes sur l’objet de contexte avec help(\"ctx\"). ctx$optimizers est une liste nommée contenant chaque optimiseur qui été créé lorsqu’appellé la méthode set_optimizers(). Vous devez assurer le suivi les pertes en cours de modification en les enregistrant dans une liste nommée dans ctx$loss. Conformément à la convention, nous réutilisons le nom que l’optimiseur auquel elle se réfère. Il est recommandé de les déconnecter avec $detach() avant leur sauvegarde pour réduire la consommation de mémoire. Les rappels qui seraient déclenchés dans la méthode step() par défaut comme on_train_batch_after_pred, on_train_batch_after_loss, etc., ne seront pas automatiquement appelés. Vous pouvez toujours les déclencher manuellement en ajoutant ctx$call_callbacks(\"<nom du rappel>)à l'intérieur de votre  étape d'apprentissage. Étudiez le code defit_one_batch()etvalid_one_batch` pour identifier tous les rappels qui ne seront pas déclenchés. Si vous voulez que les métriques luz fonctionnent avec votre méthode step() personnalisée, vous devez assigner ctx$pred aux prédictions du modèle car les métriques seront toujours appelées avec metric$update(ctx$pred, ctx$target).","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$fc1 <- nn_linear(100, 50)     self$fc1 <- nn_linear(50, 10)   },   forward = function(x) {     x %>%        self$fc1() %>%        nnf_relu() %>%        self$fc2()   },   set_optimizers = function(lr_fc1 = 0.1, lr_fc2 = 0.01) {     list(       opt_fc1 = optim_adam(self$fc1$parameters, lr = lr_fc1),       opt_fc2 = optim_adam(self$fc2$parameters, lr = lr_fc2)     )   },   step = function() {     ctx$loss <- list()     for (opt_name in names(ctx$optimizers)) {            ctx$pred <- ctx$model(ctx$input)       opt <- ctx$optimizers[[opt_name]]       loss <- nnf_cross_entropy(pred, target)              if (opt_name == \"opt_fc1\") {         # ajout d'une régularisation L1 sur la couche 1         loss <- nnf_cross_entropy(pred, target) +            torch_norm(self$fc1$weight, p = 1)       }                if (ctx$training) {         opt$zero_grad()         loss$backward()         opt$step()         }              ctx$loss[[opt_name]] <- loss$detach()     }   } )"},{"path":"https://cregouby.github.io/luz.fr/articles/custom-loop.html","id":"étapes-suivantes","dir":"Articles","previous_headings":"","what":"Étapes suivantes","title":"Boucles personnalisées avec luz","text":"Dans cet article, vous avez appris à personnaliser l’étape de formation du boucle d’apprentissage en utilisant les fonctionnalités en couche de luz. Luz permet également des modifications plus flexibles de la boucle d’apprentissage décrites dans le vignette “Accélérateur” (vignette(\"accelerator\")). Vous devriez maintenant pouvoir suivre les exemples marqués avec les catégories ‘intermédiaire’ et ‘avancé’ dans la galerie des exemples de luz","code":""},{"path":"https://cregouby.github.io/luz.fr/articles/examples/mnist-autoencoder.html","id":"ensembles-et-chargeurs--","dir":"Articles > Examples","previous_headings":"","what":"Ensembles et chargeurs —————————————————-","title":"Autoencodeur","text":"dir <- “./mnist” # répertoire de mise en cache","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/articles/examples/mnist-autoencoder.html","id":"category-basic","dir":"Articles > Examples","previous_headings":"Modifiez le dataset MNIST afin que la cible soit identique à l’entrée.","what":"category: ‘basic’","title":"Autoencodeur","text":"","code":"# Packages ---------------------------------------------------------------- library(torch) library(torchvision) library(luz)  # Jeu de données et chargeurs de données ----------------------------------------------------  dir <- \"./mnist\" # répertoire de mise en cache  # Modification du jeu de données MNIST afin que la cible soit identique à l'entrée. mnist_dataset2 <- torch::dataset(   inherit = mnist_dataset,   .getitem = function(i) {     output <- super$.getitem(i)     output$y <- output$x     output   } )  train_ds <- mnist_dataset2(   dir,   download = TRUE,   transform = transform_to_tensor )  test_ds <- mnist_dataset2(   dir,   train = FALSE,   transform = transform_to_tensor )  train_dl <- dataloader(train_ds, batch_size = 128, shuffle = TRUE) test_dl <- dataloader(test_ds, batch_size = 128)  # Construction du réseau ---------------------------------------------------  net <- nn_module(   \"Net\",   initialize = function() {     self$encoder <- nn_sequential(       nn_conv2d(1, 6, kernel_size=5),       nn_relu(),       nn_conv2d(6, 16, kernel_size=5),       nn_relu()     )     self$decoder <- nn_sequential(       nn_conv_transpose2d(16, 6, kernel_size = 5),       nn_relu(),       nn_conv_transpose2d(6, 1, kernel_size = 5),       nn_sigmoid()     )   },   forward = function(x) {     x %>%       self$encoder() %>%       self$decoder()   },   predict = function(x) {     self$encoder(x) %>%       torch_flatten(start_dim = 2)   } )  # Entraînement du modèle -------------------------------------------------------------------  fitted <- net %>%   setup(     loss = nn_mse_loss(),     optimizer = optim_adam   ) %>%   fit(train_dl, epochs = 1, valid_data = test_dl)  # Inférence ------------------------------------------------------  preds <- predict(fitted, test_dl)  # Sérialisation ---------------------------------------------------------------  luz_save(fitted, \"mnist-autoencoder.pt\")"},{"path":"https://cregouby.github.io/luz.fr/articles/examples/text-generation.html","id":"données","dir":"Articles > Examples","previous_headings":"","what":"Données","title":"Entraîner un modèle linguistique causal à partir de zéro","text":"La première étape est d’implémenter un jeu de données torch qui rassemble des données et les pré-traite pour qu’elles soient au format approprié pour entraîner le modèle. Cela signifie que nous devons : Télécharger les données textuelles Entraîner un tokeniseur pour ce jeu de données Être en mesure de produire des séquences de tokens dans le format attendu par le modèle Nous allons utiliser 2 jeux de données disponibles sur le Hub d’Hugging Face. Le premier contient tous les codes sources des paquets R disponibles sur CRAN. Le second contient tous les codes R qui sont disponibles dans les dumps GitHub. Les deux jeux de données sont au format Parquet. Nous allons implémenter une fonction qui télécharge et cache les données, puis renvoie une seule table au format arrow contenant toutes les données. Ensuite, nous implémentons une fonction qui entraîne un tokeniseur sur notre jeu de données. Nous pouvons enfin implémenter le jeu de données torch que nous allons utiliser pour entraîner le modèle. Nous allons utiliser torch::iterable_dataset au lieu de torch::dataset. La principale motivation est que nous ne pouvons pas vraiment savoir le nombre total d’échantillons dans le jeu de données, donc nous pouvons implémenter une méthode .getitem() pour obtenir n’importe quel échantillon arbitraire. Ainsi, nous implémentons la méthode .iter qui retourne un nouvel échantillon à chaque appel. Ce jeu de données est bien trop volumineux pour entraîner le modèle sur tous les documents dans cet exemple. Il est également difficile de prédire combien de temps cela prendra d’arriver à la fin de l’entraînement. Pour simplifier, nous définissons un jeu de données itérable utilisé pour exécuter le jeu de données ci-dessus pendant un nombre fixe d’étapes. Ce n’est pas nécessaire, mais rend l’utilisation de luz plus agréable, car nous pouvons facilement définir combien de tokens nous voulons entraîner notre modèle. Maintenant, nous pouvons définir le modèle que nous allons entraîner. Nous utiliserons une version légère de GPT2. Nous définissons également une méthode generate nous permettant d’échantillonner à partir du modèle donné un contexte initial. Pour faciliter l’inspection de la formation, nous définirons également un callback qui imprime un échantillon du modèle à chaque époque. Nous pouvons maintenant entraîner le modèle. Nous définissons un entraînement du modèle pour un demi-milliard de tokens pendant un total de 100 époques. Ensuite, nous pouvons utiliser le modèle pour générer du texte en fonction d’un prompt avec :","code":"read_dataset <- function(source) {   d <- source |>     hfhub::hub_snapshot(repo_type = \"dataset\", allow_patterns = \"parquet$\") |>     fs::path(\"data/r\") |>     arrow::open_dataset() |>     dplyr::filter(stringr::str_detect(path, \".*\\\\.[rR]$\")) |>     dplyr::select(content) |>     dplyr::mutate(content = arrow::cast(content, arrow::string())) |>     dplyr::filter(!is.na(content)) |>     dplyr::collect() %>%     # le jeu de données contient des caractères utf8 invalides...     # nous devons les supprimer, sinon on obtient une erreur des tokenizers     dplyr::filter(utf8::utf8_valid(content)) }  read_datasets <- function() {   dplyr::bind_rows(     read_dataset(\"dfalbel/cran-packages\"),     read_dataset(\"dfalbel/github-r-repos\")   ) } create_tokenizer <- function(text, vocab_size, special_tokens) {   tok <- tok::tokenizer$new(tok::model_bpe$new())    tok$pre_tokenizer <- tok::pre_tokenizer_byte_level$new(add_prefix_space = FALSE)   tok$decoder <- tok::decoder_byte_level$new()   tok$post_processor <- tok::processor_byte_level$new(trim_offsets = FALSE)    tok$train_from_memory(     text,     tok::trainer_bpe$new(vocab_size = vocab_size, special_tokens = special_tokens)   )   tok }  # code de débogage pour le tokeniseur # data <- read_datasets() # tok <- create_tokenizer(data$content) r_sources_dataset <- torch::iterable_dataset(   \"r_sources_dataset\",   initialize = function(root = \".\", vocab_size = 20000, context_length = 128) {     self$data <- read_datasets()     self$context_length <- context_length     self$index <- sample.int(nrow(self$data))      # nous créons un tokeniseur que si celui-ci n'existe pas déjà, sinon nous le chargeons simplement     tok_path <- file.path(root, glue::glue(\"tokenizer-{vocab_size}.json\"))     if (!file.exists(tok_path)) {       self$tok <- create_tokenizer(         as.character(self$data$content),         vocab_size,         c(\"<fbegin>\", \"<fend>\")       )       fs::dir_create(root)       self$tok$save(tok_path)     } else {       self$tok <- tok::tokenizer$from_file(tok_path)     }   },   .iter = function() {     i <- 1L     sequence <- c()     function() {       while (length(sequence) < (self$context_length + 1) && i <= nrow(self$data)) {         sequence <<- c(           sequence,           self$tok$encode(paste(\"<fbegin>\", as.character(self$data$content[self$index[i]]), \"<fend>\"))$ids         )         i <- i + 1L       }        if (length(sequence) < (self$context_length + 1)) {         return(coro::exhausted())       }        on.exit({         sequence <<- sequence[-seq_len(self$context_length)]       })       list(         input_ids = sequence[seq_len(self$context_length)] + 1L,         labels = sequence[2:(self$context_length + 1)] + 1L       )     }   } )  # code de débogage pour le jeu de données # ds <- r_sources_dataset(\"~/Downloads/\") # it <- ds$.iter() # it() # ds$tok$get_vocab_size() fixed_steps_iterable_dataset <- iterable_dataset(   \"fixed_steps_dataset\",   initialize = function(dataset, steps) {     self$dataset <- dataset     self$steps <- steps   },   .iter = function() {     i <- 1L     iter <- NULL     function() {       if (i > self$steps) {         return(coro::exhausted())       }        i <<- i + 1L        if (is.null(iter) || coro::is_exhausted(data <- iter())) {         iter <<- self$dataset$.iter()         data <- iter()       }        data     }   },   .length = function() {     self$steps   } ) net <- nn_module(   initialize = function() {     self$gpt <- minhub::gpt2(       vocab_size = 20000,       pdrop = 0.1     )   },   forward = function(x) {     self$gpt(x)$transpose(2,3)   },   generate = function(x, temperature = 1, iter = 50, top_k = 10) {     # échantillonne à partir du modèle given un vecteur de contexte.     for (i in seq_len(iter)) {       logits <- self$forward(x)[,,-1]       logits <- logits/temperature       c(prob, ind) %<-% logits$topk(top_k)       logits <- torch_full_like(logits, -Inf)$scatter_(-1, ind, prob)       logits <- nnf_softmax(logits, dim = -1)       id_next <- torch_multinomial(logits, num_samples = 1)       x <- torch_cat(list(x, id_next), dim = 2)     }     x   } )  # code de débogage pour le modèle # ds <- torch::dataloader(r_sources_dataset(\"~/Downloads/\"), batch_size = 32) # batch <- coro::collect(ds, 1)[[1]] # str(batch) # m <- net() # str(m(batch$input_ids)) # échantillonne à partir du modèle en utilisant le contexte. generate <- function(model, tok, context, ...) {   local_no_grad() # désactive les gradients pour l'échantillonnage   x <- tok$encode(context)$ids + 1L   x <- torch_tensor(x)[NULL,]$to(device = model$device)   content <- as.integer(model$generate(x, ...)$cpu())   tok$decode(content - 1L) }  display_cb <- luz_callback(   initialize = function() {},   on_epoch_end = function() {     local_no_grad()     # sample from the model...     context <- \"# creates a linear model\"     text <- generate(ctx$model, dataset$dataset$tok, context, iter = 100)     cli::cli_rule()     cat(text, \"\\n\")     cli::cli_rule()   } ) n_tokens <- 500e6 batch_size <- 16 epochs <- 100 context_length <- 256L  steps <- n_tokens / context_length / epochs dataset <- fixed_steps_iterable_dataset(   r_sources_dataset(context_length = context_length),   steps = steps )  fitted <- net %>%   setup(     optimizer = optim_adam,     loss = nn_cross_entropy_loss()   ) %>%   set_opt_hparams(lr = 3e-4) |>   fit(     dataset,     epochs = epochs,     dataloader_options = list(batch_size = batch_size),     callbacks = list(       luz_callback_lr_scheduler(         torch::lr_one_cycle,         max_lr = 0.1,         epochs = epochs,         steps_per_epoch = steps/batch_size,         call_on = \"on_batch_end\"       ),       luz_callback_gradient_clip(max_norm = 1),       display_cb()     ),     verbose = TRUE   )  luz::luz_save(fitted, \"model.pt\") fitted <- luz::luz_load(\"model.pt\") tok <- tok::tokenizer$from_file(\"tokenizer-20000.json\") context <- \"#' Crée un modèle linéaire linear_model <- function(x, y) { \" text <- generate(fitted$model, tok, context, iter = 100) cat(text)"},{"path":"https://cregouby.github.io/luz.fr/articles/get-started.html","id":"entraînement-dun-nn_module","dir":"Articles","previous_headings":"","what":"Entraînement d’un nn_module","title":"Bien démarrer avec luz","text":"Luz tente, autant que possible, de réutiliser les structures existantes de torch. Aussi, un réseau de neurones est défini avec luz exactement de la même manière qu’avec torch brut. Par exemple, voici la définition d’un réseau convolutif (CNN feed-forward) qui peut être utilisé, par exemple, pour classer les images du jeu de données MNIST: Nous pouvons entraîner ce réseau en lui appliquant un jeu de données via le chargeur de donnée train_dl et l’évaluer grace au torch::dataloaders() nomé test_dl avec: Voyons en détail ce qui se passe dans lee précédent bloc de code : La fonction setup vous permet de configurer la fonction de coût (objectif) et l’optimiseur que vous utiliserez pour entraîner votre modèle. En option, vous pouvez passer une liste de métriques qui sont suivies pendant la procédure d’apprentissage. Remarque : la fonction de coût peut être n’importe quelle fonction prenant en entrée input et target et retournant une valeur de tenseur scalaire, et l’optimiseur peut être n’importe quel optimiseur de torch natif ou personnalisé, créé avec la fonction torch::optimizer(). La fonction set_hparams() permet de définir les hyper-paramètres qui doivent être passées à la méthode initialize() du module. Par exemple, ici nous passons num_classes = 10 qui définit la taille de la dernière couche du réseau. La fonction set_opt_hparams() vous permet de passer des hyper-paramètres utilisés par la fonction d’optimisation. Par exemple, l’optimiseur choisi ici optim_adam() peut prendre le paramètre lr spécifiant le taux d’apprentissage et nous le spécifions avec lr = 0.003. La méthode fit va prendre les spécifications du modèle fournies par setup() et exécuter la boucle d’apprentissage en utilisant les jeux de donnée d’entraînement et de validation spécifiés dans des torch::dataloaders() pendant le nombre d’époques. Remarque : nous réutilisons les structures de données de base de torch pour les chargeurs de donnée, au lieu de recréer notre propre fonctionnalité de chargement de données. L’objet retourné fitted contient le modèle entraîné ainsi que le registre des métriques et de la fonction de pertes produites au cours de l’apprentissage. Il pourra être utilisé pour faire de prédictions sur des données nouvelles, et pour l’évaluation du modèle entraîné sur d’autres jeux de données. Au moment du lancement de la boucle de calcul, luz utilise l’accélérateur le plus rapide possible; si une carte graphique (GPU) doté de CUDA est disponible, elle sera utilisée, sinon le calcul sera affecté à la CPU. Il déplace également automatiquement les données, les optimisateurs et les modèles vers le périphérique sélectionné afin d’éviter de le programmer manuellement (qui constitue une grande source d’erreurs en général). Pour créer des prédictions à partir du modèle entraîné, vous pouvez utiliser la méthode predict:","code":"net <- nn_module(   \"Net\",   initialize = function(num_class) {     self$conv1 <- nn_conv2d(1, 32, 3, 1)     self$conv2 <- nn_conv2d(32, 64, 3, 1)     self$dropout1 <- nn_dropout2d(0.25)     self$dropout2 <- nn_dropout2d(0.5)     self$fc1 <- nn_linear(9216, 128)     self$fc2 <- nn_linear(128, num_class)   },   forward = function(x) {     x <- self$conv1(x)     x <- nnf_relu(x)     x <- self$conv2(x)     x <- nnf_relu(x)     x <- nnf_max_pool2d(x, 2)     x <- self$dropout1(x)     x <- torch_flatten(x, start_dim = 2)     x <- self$fc1(x)     x <- nnf_relu(x)     x <- self$dropout2(x)     x <- self$fc2(x)     x   } ) fitted <- net %>%   setup(     loss = nn_cross_entropy_loss(),     optimizer = optim_adam,     metrics = list(       luz_metric_accuracy     )   ) %>%   set_hparams(num_class = 10) %>%    set_opt_hparams(lr = 0.003) %>%    fit(train_dl, epochs = 10, valid_data = test_dl) predictions <- predict(fitted, test_dl)"},{"path":"https://cregouby.github.io/luz.fr/articles/get-started.html","id":"la-boucle-dentraînement","dir":"Articles","previous_headings":"","what":"La boucle d’entraînement","title":"Bien démarrer avec luz","text":"Maintenant que vous avez une idée générale sur la façon d’utiliser la fonction fit, il est important d’avoir un aperçu de ce qui se passe à l’intérieur. Voici le pseudocode de ce que fit exécute. Sans vous montrer l’intégralité des opérations, cela devrait vous aider à construire votre intuition:","code":"# -> Initialiser les objets : modèle, optimiseurs. # -> Sélectionner le périphérique d'apprentissage (GPU, ...). # -> Déplacer les données, le modèle et les optimiseurs vers le périphérique sélectionné. # -> Lancer l'apprentissage for (epoch in 1:epochs) {   # -> Procédure d'apprentissage   for (batch in train_dl) {     # -> Calculer la méthode `forward` du modèle.     # -> Calculer la perte.     # -> Mettre à jour les poids.     # -> Enregistrer les métriques et suivre la perte.   }   # -> Procédure de validation   for (batch in valid_dl) {     # -> Calculer la méthode `forward` du modèle.     # -> Calculer la perte.     # -> Enregistrer les métriques et suivre la perte.   } } # -> Fin de l'apprentissage"},{"path":"https://cregouby.github.io/luz.fr/articles/get-started.html","id":"les-métriques","dir":"Articles","previous_headings":"","what":"Les métriques","title":"Bien démarrer avec luz","text":"L’un des paramêtres les plus importantes des projets d’apprentissage automatique est le choix de la métrique d’évaluation. Luz permet de suivre de nombreuses métriques différentes pendant l’apprentissage avec un effort de codage minime. Pour suivre les métriques, il suffit de modifier le paramètre metrics dans la fonction setup: Luz fournit des implémentations de quelques-unes des métriques les plus utilisées. Si une métrique n’est pas disponible, vous pouvez toujours la créer à l’aide de la fonction luz_metric(). Pour implémenter une nouvelle métrique luz_metric, il faut définir 3 méthodes : initialize : définit l’état initial de la métrique. Cette fonction est appelée à chaque époque pour les boucles d’entraînement et de validation. update : met à jour l’état interne de la métrique. Cette fonction est appelée après chaque lot d’entraînement et de validation en comparant les prédictions obtenues par le modèle et les valeurs cibles renvoyées par le chargeur de données. compute : utilise l’état interne pour calculer les valeurs de la métrique. Cette fonction est appelée toutes les fois où il faut mettre à jour la métrique. Par exemple, elle est appelée après chaque lot d’entraînement pour afficher les informations de progression, mais seulement appelée une fois par époque pour enregistrer sa valeur lorsqu’il n’y pas de barre de progression. Vous pouvez définir un champ optionnel abbrev qui donne à la métrique une abréviation utilisée lors de l’affichage des informations de métrique dans la console ou dans les enregistrements. Si aucune valeur n’est fournie pour abbrev, le nom de classe de la métrique est utilisé. Essayons maintenant de voir l’implémentation de luz_metric_accuracy pour mettre en œuvre une nouvelle métrique : Remarque: Il est préférable que la fonction compute retourne des valeurs R natives plutôt qu’éventuellement des tenseurs torch. D’autres parties de luz s’attendent à des valeurs R et s’y attacheront.","code":"fitted <- net %>%   setup(     ...     metrics = list(       luz_metric_accuracy     )   ) %>%   fit(...) luz_metric_accuracy <- luz_metric(   # Une abréviation à afficher dans les barres de progression ou    # lors de l'affichage des informations de progression   abbrev = \"Acc\",    # Initialisation pour la métrique. Les métriques sont initialisées   # à chaque époque, pour les entraînements et pour les validations.   initialize = function() {     self$correct <- 0     self$total <- 0   },   # Mise à jour à chaque lot d'entraînement ou de validation.   # La fonction update prend `preds`    # et `target` en paramètres et met à jour l'état interne `self`.   update = function(preds, target) {     pred <- torch::torch_argmax(preds, dim = 2)     self$correct <- self$correct + (pred == target)$       to(dtype = torch::torch_float())$       sum()$       item()     self$total <- self$total + pred$numel()   },   # Utilise l'état interne pour demander la valeur de la métrique.   compute = function() {     self$correct/self$total   } )"},{"path":"https://cregouby.github.io/luz.fr/articles/get-started.html","id":"évaluation","dir":"Articles","previous_headings":"","what":"Évaluation","title":"Bien démarrer avec luz","text":"Une fois le modèle entraîné, vous voulez certainement évaluer sa performance sur un autre jeu de données. Pour cela, luz fournit la fonction ?evaluate qui prend, en entrée, un modèle ajusté et un jeu de données et calcule les métriques attachées au modèle. La fonction evaluate() retourne un objet de type luz_module_evaluation. Vous pouvez l’interroger pour les métriques à l’aide de la fonction get_metrics() ou simplement imprimer pour voir les résultats. Par exemple :","code":"evaluation <- fitted %>% evaluate(data = valid_dl) metrics <- get_metrics(evaluation) print(evaluation) #> Error in get(paste0(generic, \".\", class), envir = get_method_env()) :  #>   objet 'type_sum.accel' introuvable #> A `luz_module_evaluation` #> -- Results --------------------------------------------------------------------- #> loss: 1.8892 #> mae: 1.0522 #> mse: 1.645 #> rmse: 1.2826"},{"path":"https://cregouby.github.io/luz.fr/articles/get-started.html","id":"personnalisation-avec-les-points-darrêt-ou-callbacks","dir":"Articles","previous_headings":"","what":"Personnalisation avec les points d’arrêt ou callbacks","title":"Bien démarrer avec luz","text":"Luz fournit différentes façons de personnaliser la boucle d’apprentissage, en fonction du niveau de contrôle dont vous avez besoin pendant qu’elle s’exécute. La façon la plus rapide et la plus « réutilisable » est via les rappels ou callbacks. Ils permettent de créer des modifications d’apprentissage qui peuvent être utiles dans diverses situations. La boucle d’apprentissage de luz dispose de nombreux rappels qui peuvent, chacuns, appeler des fonctions R arbitraires. Cette fonctionnalité vous permet de personnaliser le processus d’apprentissage sans entrer dans la logique générale de l’apprentissage. Luz implémente 3 rappels par défaut qui se produisent dans chaque procédure d’apprentissage : callback train-eval: bascule le modèle en mode train() ou eval() selon si la procédure est en cours d’entraînement ou de validation. callback metrics : évalue les métriques au cours du processus d’entraînement et de validation. callback progress : implémente une barre de progression et affiche des informations sur la progression des lots et des époques pendant l’apprentissage. Vous pouvez également mettre en place des rappels personnalisés qui modifient ou agissent spécifiquement pour votre procédure d’apprentissage, c’est ce que nous allons montrer dans l’exemple suivant. Implémentons un callback qui affiche ‘Itération n’ (où n est le numéro d’itération) pour chaque lot du jeu de données d’apprentissage et ‘Fini!’ lorsque la fin d’une époque est atteinte. Pour cela, nous utilisons la fonction luz_callback() : luz_callback() prend des fonctions nommées en argument ..., où le nom indique le moment auquel le callback doit être appelé. Par exemple, on_train_batch_end() est appelé pour chaque fin de lot lors du processus d’apprentissage, et on_epoch_end() est appelé à la fin de chaque époque. La valeur retournée par luz_callback() est une fonction qui s’intancie au moment du callback. Les callbacks peuvent avoir besoin de paramètres d’initialisation, comme par exemple le nom d’un fichier où vous souhaitez enregistrer les résultats. Dans ce cas, vous pouvez passer par une méthode initialize lors de la définition du callback, et disposer ces paramètres dans l’objet self. Dans l’exemple ci-dessus, le callback un paramètre message qui sera utilisé pour etre affiché à la fin de chaque époque. Une fois que le callback est défini, il peut être passé à la fonction fit via le paramètre callbacks : Les callbacks peuvent être déclenchés à de nombreuses positions de la boucle d’apprentissage, y compris en combinaison les uns avec les autres. Voici un aperçu des positions possibles pour insérer les callbacks : Chaque étape marquée avec on_* est une position dans le processus d’apprentissage qui est disponible pour déclencher les callbacks. L’autre partie importante des callbacks est l’objet contexte ctx . Voir help(\"ctx\") pour plus de détails. Par défaut, les callbacks sont déclenchés dans l’ordre dans lequel ils ont été passés à fit (ou predict ou evaluate), mais vous pouvez fournir un attribut weight qui contrôlera l’ordre croissant dans lequel il sera appelé. Par exemple, si un callback un weight = 10 et un autre un weight = 1, alors le premier est appelé après le second. Les callbacks qui ne spécifient pas d’attribut de poids sont considérés comme ayant un weight = 0. Certains callbacks intégrés dans luz fournissent déjà une valeur de poids. Par exemple, ?luz_callback_early_stopping une valeur de poids de Inf, puisque en général souhaite l’exécuter à la toute fin dans la boucle. Notez que les callbacks peuvent être combinés pour effectuer des opérations complexes sur le processus d’apprentissage. La variable ctx est un objet utilisé dans luz pour partager des informations entre la boucle d’entraînement et les callbacks, les méthodes du modèle et les métriques. La table suivante décrit les informations disponibles par défaut dans ctx. D’autres rappels peuvent potentiellement modifier ces attributs ou en ajouter de nouveaux. Attributs du contexte Les attributs de ctx peuvent être utilisés pour produire le comportement souhaité des callbacks. Vous pouvez trouver de plus amples informations sur l’objet de contexte à l’aide de help(\"ctx\"). Dans notre exemple, nous utilisons l’attribut ctx$iter pour afficher le numéro d’itération pour chaque lot d’apprentissage.","code":"print_callback <- luz_callback(   name = \"print_callback\",   initialize = function(message) {     self$message <- message   },   on_train_batch_end = function() {     cat(\"Itération \", ctx$iter, \"\\n\")   },   on_epoch_end = function() {     cat(self$message, \"\\n\")   } ) fitted <- net %>%   setup(...) %>%   fit(..., callbacks = list(     print_callback(message = \"Fini!\")   )) Début de boucle d'ajustement    - on_fit_begin   Début de l'époque      - on_epoch_begin     Début de l'apprentissage        - on_train_begin       Début de la boucle sur le lot          - on_train_batch_begin           Début du lot d'apprentissage par défaut             - on_train_batch_after_pred             - on_train_batch_after_loss             - on_train_batch_before_backward             - on_train_batch_before_step             - on_train_batch_after_step           Fin du lot d'apprentissage par défaut :          - on_train_batch_end       Fin de la boucle de batch        - on_train_end     Fin de l'apprentissage     Début de la validation        - on_valid_begin       Début de la boucle sur le lot          - on_valid_batch_begin           Début du lot de validation par défaut             - on_valid_batch_after_pred             - on_valid_batch_after_loss           Fin du lot de validation par défaut          - on_valid_batch_end       Fin de la boucle sur le lot        - on_valid_end     Fin de la validation       - on_epoch_end   Fin de l'époque    - on_fit_end Fin de l'ajustement"},{"path":"https://cregouby.github.io/luz.fr/articles/get-started.html","id":"étapes-suivantes","dir":"Articles","previous_headings":"","what":"Étapes suivantes","title":"Bien démarrer avec luz","text":"Dans cet article, vous avez appris à entraîner votre premier modèle en utilisant luz et les bases de la personnalisation en utilisant à la fois des métriques personnalisées et des callbacks. Luz permet également des modifications plus flexibles du processus d’apprentissage décrites dans la vignette(\"custom-loop\"). Vous devriez maintenant être en mesure de suivre les exemples marqués avec la catégorie ‘basique’ dans la galerie d’exemples.","code":""},{"path":"https://cregouby.github.io/luz.fr/authors.html","id":null,"dir":"","previous_headings":"","what":"Auteur·rice·s","title":"Auteur·rice·s et Citation","text":"Christophe Regouby. Auteur·rice, mainteneur·se, titulaire des droits d'auteur.","code":""},{"path":"https://cregouby.github.io/luz.fr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Auteur·rice·s et Citation","text":"Regouby C (2025). luz.fr: Une interface de programmation de haut-niveau pour 'torch'. R package version 0.4.0.9000, https://cregouby.github.io/luz.fr/.","code":"@Manual{,   title = {luz.fr: Une interface de programmation de haut-niveau pour 'torch'},   author = {Christophe Regouby},   year = {2025},   note = {R package version 0.4.0.9000},   url = {https://cregouby.github.io/luz.fr/}, }"},{"path":"https://cregouby.github.io/luz.fr/index.html","id":"luzfr-","dir":"","previous_headings":"","what":"Une interface de programmation de haut-niveau pour torch","title":"Une interface de programmation de haut-niveau pour torch","text":"Le paquet d’internationalisation de {luz} en français (fr_FR)","code":""},{"path":"https://cregouby.github.io/luz.fr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Une interface de programmation de haut-niveau pour torch","text":"Vous pouvez installer la version de development de {luz.fr} depuis GitHub via:","code":"# install.packages(\"devtools\") devtools::install_github(\"cregouby/luz.fr\")"},{"path":"https://cregouby.github.io/luz.fr/index.html","id":"exemple","dir":"","previous_headings":"","what":"Exemple","title":"Une interface de programmation de haut-niveau pour torch","text":"Voici comment utiliser {luz} avec l’aide en français :","code":"# configure la session en langue française Sys.setenv(LANGUAGE = \"fr\")  # charge la librairie d'aide de luz en traduction française et {luz} library(luz.fr) library(luz)  # consulte l'aide normalement ??lr_finder"},{"path":"https://cregouby.github.io/luz.fr/reference/accelerator.html","id":null,"dir":"Reference","previous_headings":"","what":"Crée un accélérateur  🌐  Create an accelerator — accelerator","title":"Crée un accélérateur  🌐  Create an accelerator — accelerator","text":"Crée un accélérateur","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/accelerator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Crée un accélérateur  🌐  Create an accelerator — accelerator","text":"","code":"accelerator(   device_placement = TRUE,   cpu = FALSE,   cuda_index = torch::cuda_current_device() )"},{"path":"https://cregouby.github.io/luz.fr/reference/accelerator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Crée un accélérateur  🌐  Create an accelerator — accelerator","text":"device_placement (booléen) si l'objet accelerator doit gérer le placement sur les cartes accélératrices. Par défaut : TRUE cpu (booléen) le processus d'apprentissage doit-il s'exécuter sur le processeur central ? cuda_index (entier) index de la carte CUDA à utiliser si plusieurs GPUs sont disponibles. Par défaut : le résultat de torch::cuda_current_device()","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/as_dataloader.html","id":null,"dir":"Reference","previous_headings":"","what":"Crée un chargeur de données à partir de son entrée.  🌐  Creates a dataloader from its input — as_dataloader","title":"Crée un chargeur de données à partir de son entrée.  🌐  Creates a dataloader from its input — as_dataloader","text":"as_dataloader est utilisé en interne par luz pour convertir les entrées data et valid_data passés à fit.luz_module_generator() en un torch::dataloader","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/as_dataloader.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Crée un chargeur de données à partir de son entrée.  🌐  Creates a dataloader from its input — as_dataloader","text":"","code":"as_dataloader(x, ...)  # Méthode S3 pour la classe dataset as_dataloader(x, ..., batch_size = 32)  # Méthode S3 pour la classe iterable_dataset as_dataloader(x, ..., batch_size = 32)  # Méthode S3 pour la classe list as_dataloader(x, ...)  # Méthode S3 pour la classe dataloader as_dataloader(x, ...)  # Méthode S3 pour la classe matrix as_dataloader(x, ...)  # Méthode S3 pour la classe numeric as_dataloader(x, ...)  # Méthode S3 pour la classe array as_dataloader(x, ...)  # Méthode S3 pour la classe torch_tensor as_dataloader(x, ...)"},{"path":"https://cregouby.github.io/luz.fr/reference/as_dataloader.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Crée un chargeur de données à partir de son entrée.  🌐  Creates a dataloader from its input — as_dataloader","text":"x l'objet d'entrée. ... Passé à torch::dataloader(). batch_size (entier, facultatif) : nombre d'observations par lot (par défaut: 32).","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/as_dataloader.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Crée un chargeur de données à partir de son entrée.  🌐  Creates a dataloader from its input — as_dataloader","text":"Les méthodes as_dataloader permettent de choisir finement les paramètres par défaut pour la taille du lot, les workers parallèles, etc. Elle permet aux utilisateurs de tester rapidement fit.luz_module_generator() sans avoir besoin de créer un torch::dataset et un torch::dataloader pour l'expérimentation.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/as_dataloader.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Crée un chargeur de données à partir de son entrée.  🌐  Creates a dataloader from its input — as_dataloader","text":"as_dataloader(dataset) : Convertit un torch::dataset() en un torch::dataloader(). as_dataloader(iterable_dataset) : Convertit un torch::iterable_dataset() en un torch::dataloader() as_dataloader(list) : Convertit une liste de tenseurs ou d'arrays ayant tous la même taille dans leur première dimension en un torch::dataloader() as_dataloader(dataloader) : Retourne le même chargeur de données as_dataloader(matrix) : Convertit la matrice en un chargeur de données as_dataloader(numeric) : Convertit le vecteur numérique en un chargeur de données as_dataloader(array) : Convertit l'array en un chargeur de données as_dataloader(torch_tensor) : Convertit le tenseur en un chargeur de données","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/as_dataloader.html","id":"overriding","dir":"Reference","previous_headings":"","what":"Overriding","title":"Crée un chargeur de données à partir de son entrée.  🌐  Creates a dataloader from its input — as_dataloader","text":"Vous pouvez implémenter votre propre méthode S3 de as_dataloader si vous voulez que votre structure de données soit automatiquement prise en charge par luz's fit.luz_module_generator(). La méthode doit satisfaire les conditions suivantes : La méthode doit retourner un torch::dataloader(). L'unique argument requis est `x`. Vous avez des paramètres avec de bonnes valeurs par défaut pour tous les autres arguments. Il faut éviter l'implémentation de méthodes as_dataloader pour les classes S3 courantes comme data.frames. Si nécessaire, il est préférable d'affecter une classe S3 spécifique aux inputs et d'implémenter as_dataloader pour cette classe.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":null,"dir":"Reference","previous_headings":"","what":"Objet de type contexte  🌐  Context object — context","title":"Objet de type contexte  🌐  Context object — context","text":"Objet de type context stockant des informations sur le contexte d'entraînement du modèle. Voir également ctx.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Objet de type contexte  🌐  Context object — context","text":"buffers une liste de buffers que les callbacks peuvent utiliser pour une écriture temporaire d'information dans le  ctx.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"active-bindings","dir":"Reference","previous_headings":"","what":"Active bindings","title":"Objet de type contexte  🌐  Context object — context","text":"records stores information values logged self$log. device allows querying current accelerator device callbacks list callbacks called. iter current iteration batch current batch data. list input data targets. input shortcut ctx$batch[[1]] target shortcut ctx$batch[[2]] min_epochs minimum number epochs model run . max_epochs maximum number epochs model run. hparams list hyperparameters used initialize ctx$model. opt_hparams list hyperparameters used initialize ctx$optimizers. train_data dataloader used training model valid_data dataloader using model validation accelerator accelerator() used move data, model etc correct device. optimizers named list optimizers used model training. verbose bool wether process verbose mode . handlers List error handlers can used. See rlang::try_fetch() info. epoch_handlers List error handlers can used. See rlang::try_fetch() info. training bool indicating model training validation mode. model model trained. pred Last predicted values. opt Current optimizer. opt_name Current optimizer name. data Current dataloader use. loss_fn Loss function used train model loss Last computed loss values. Detached graph. loss_grad Last computed loss value, detached, can additional tranformation. epoch Current epoch. metrics List metrics tracked process. step_opt Defines step called optimizer. must function taking optimizer argument.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Objet de type contexte  🌐  Context object — context","text":"context$new() context$log() context$log_metric() context$get_log() context$get_metrics() context$get_metric() context$get_formatted_metrics() context$get_metrics_df() context$set_verbose() context$clean() context$call_callbacks() context$state_dict() context$unsafe_set_records() context$clone()","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Objet de type contexte  🌐  Context object — context","text":"Initializes context object minimal necessary information.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$new(verbose, accelerator, callbacks, training)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"verbose Whether context verbose mode . accelerator luz accelerator() configures device placement others. callbacks list callbacks used model. See luz_callback(). training boolean indicates context training mode .","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-log-","dir":"Reference","previous_headings":"","what":"Method log()","title":"Objet de type contexte  🌐  Context object — context","text":"Allows logging arbitrary information ctx.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$log(what, set, value, index = NULL, append = TRUE)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"(string) logging. set (string) Usually 'train' 'valid' indicating set want lot . can arbitrary info. value value log value Arbitrary value log. index Index value logged. NULL value added end list, otherwise index used. append TRUE value corresponding index already exists, value appended current value. FALSE value overwritten favor new value.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-log-metric-","dir":"Reference","previous_headings":"","what":"Method log_metric()","title":"Objet de type contexte  🌐  Context object — context","text":"Log metric gen name value. Metric values indexed epoch.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$log_metric(name, value)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"name name metric value value log value Arbitrary value log.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-get-log-","dir":"Reference","previous_headings":"","what":"Method get_log()","title":"Objet de type contexte  🌐  Context object — context","text":"Get specific value log.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$get_log(what, set, index = NULL)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"(string) logging. set (string) Usually 'train' 'valid' indicating set want lot . can arbitrary info. index Index value logged. NULL value added end list, otherwise index used.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-get-metrics-","dir":"Reference","previous_headings":"","what":"Method get_metrics()","title":"Objet de type contexte  🌐  Context object — context","text":"Get metric given epoch set.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$get_metrics(set, epoch = NULL)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"set (string) Usually 'train' 'valid' indicating set want lot . can arbitrary info. epoch epoch want extract metrics .","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-get-metric-","dir":"Reference","previous_headings":"","what":"Method get_metric()","title":"Objet de type contexte  🌐  Context object — context","text":"Get value metric given name, epoch set.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$get_metric(name, set, epoch = NULL)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"name name metric set (string) Usually 'train' 'valid' indicating set want lot . can arbitrary info. epoch epoch want extract metrics .","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-get-formatted-metrics-","dir":"Reference","previous_headings":"","what":"Method get_formatted_metrics()","title":"Objet de type contexte  🌐  Context object — context","text":"Get formatted metrics values","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$get_formatted_metrics(set, epoch = NULL)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"set (string) Usually 'train' 'valid' indicating set want lot . can arbitrary info. epoch epoch want extract metrics .","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-get-metrics-df-","dir":"Reference","previous_headings":"","what":"Method get_metrics_df()","title":"Objet de type contexte  🌐  Context object — context","text":"Get data.frame containing metrics.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$get_metrics_df()"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-set-verbose-","dir":"Reference","previous_headings":"","what":"Method set_verbose()","title":"Objet de type contexte  🌐  Context object — context","text":"Allows setting verbose attribute.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$set_verbose(verbose = NULL)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"verbose boolean. TRUE verbose mode used. FALSE non verbose. NULL use result interactive().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-clean-","dir":"Reference","previous_headings":"","what":"Method clean()","title":"Objet de type contexte  🌐  Context object — context","text":"Removes unnecessary information context object.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$clean()"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-call-callbacks-","dir":"Reference","previous_headings":"","what":"Method call_callbacks()","title":"Objet de type contexte  🌐  Context object — context","text":"Call selected callbacks. name callback types call, eg 'on_epoch_begin'.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$call_callbacks(name)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-8","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"name name metric","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-state-dict-","dir":"Reference","previous_headings":"","what":"Method state_dict()","title":"Objet de type contexte  🌐  Context object — context","text":"Returns list containing minimal information context. Used create returned values.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-11","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$state_dict()"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-unsafe-set-records-","dir":"Reference","previous_headings":"","what":"Method unsafe_set_records()","title":"Objet de type contexte  🌐  Context object — context","text":"sure know ?","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-12","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$unsafe_set_records(records)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-9","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"records New set records set.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Objet de type contexte  🌐  Context object — context","text":"objects class cloneable method.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"usage-13","dir":"Reference","previous_headings":"","what":"Usage","title":"Objet de type contexte  🌐  Context object — context","text":"","code":"context$clone(deep = FALSE)"},{"path":"https://cregouby.github.io/luz.fr/reference/context.html","id":"arguments-10","dir":"Reference","previous_headings":"","what":"Arguments","title":"Objet de type contexte  🌐  Context object — context","text":"deep Whether make deep clone.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/ctx.html","id":null,"dir":"Reference","previous_headings":"","what":"Objet Context  🌐  Context object — ctx","title":"Objet Context  🌐  Context object — ctx","text":"Les objets context sont utilisés par luz pour l'échange d'information entre méthodes, métriques et callbaks.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/ctx.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Objet Context  🌐  Context object — ctx","text":"L'objet ctx est utilisé par luz pour partager des méthodes entre la boucle d'entraînement, les callbacks, les méthodes du modèles et les métriques. La table ci-dessous liste les informations disponibles dans ctx par défaut. Les autres callbacks peuvent potentiellement modifier ces attributs et en ajouter d'autres. Attributs du contexte","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/evaluate.html","id":null,"dir":"Reference","previous_headings":"","what":"Évalue un modèle entraîné sur un jeu de données  🌐  Evaluates a fitted model on a dataset — evaluate","title":"Évalue un modèle entraîné sur un jeu de données  🌐  Evaluates a fitted model on a dataset — evaluate","text":"Évalue un modèle entraîné sur un jeu de données","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/evaluate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Évalue un modèle entraîné sur un jeu de données  🌐  Evaluates a fitted model on a dataset — evaluate","text":"","code":"evaluate(   object,   data,   ...,   metrics = NULL,   callbacks = list(),   accelerator = NULL,   verbose = NULL,   dataloader_options = NULL )"},{"path":"https://cregouby.github.io/luz.fr/reference/evaluate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Évalue un modèle entraîné sur un jeu de données  🌐  Evaluates a fitted model on a dataset — evaluate","text":"object Un modèle entraîné. data (dataloader, dataset ou liste) Un chargeur de données créé avec torch::dataloader() sur lequel évaluer le modèle, ou un dataset créé avec torch::dataset() ou une liste. Les chargeur de donnéess et les datasets doivent retourner une liste avec au plus 2 items. Le premier item sera utilisé comme prédicteurs pour le module et le second sera utilisé comme variable à prédire pour la fonction de perte. ... Inutilisé metrics Une liste de métriques de luz à appliquer pendant l'évaluation. Si NULL (par défaut) alors les mêmes métriques que les métriques d'entraînement sont évaluées. callbacks (facultatif) Une liste de callbacks définis avec luz_callback() qui seront appelés pendant la procédure d'entraînement. Les callbacks luz_callback_metrics(), luz_callback_progress() et luz_callback_train_valid() sont toujours ajoutés par défaut. accelerator Un accélérateur accelerator() à utiliser pour le calcul des objets tels que les modules nn, les optimiseurs et les batch de données. verbose (booléen) La procédure d'entraînement doit-elle produire des messages dans la console. Par défaut, elle produira des messages s'il y une interface graphique (c'est-à-dire si interactive() est vrai), sinon elle ne produira pas de messages. dataloader_options Des options utilisées lors de la création d'un chargeur de données. Voir torch::dataloader(). Par défautshuffle=TRUE pour les données d'entraînement et batch_size=32. Il y aura une erreur si non NULL et si data est déja un chargeur de données.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/evaluate.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Évalue un modèle entraîné sur un jeu de données  🌐  Evaluates a fitted model on a dataset — evaluate","text":"Une fois que vous avez entraîné un modèle, vous pouvez évaluer sa performance sur un autre jeu de données. Pour cela, luz fournit la fonction evaluate. Cette dernière prend en argument un modèle entraîné et un jeu de données, puis calcule les métriques liées au modèle. La fonction evaluate retourne un objet luz_module_evaluation, que vous pouvez consulter grâce à la fonction get_metrics() ou simplement print pour voir les résultats. Par exemple:","code":"evaluation <- fitted  metrics <- get_metrics(evaluation) print(evaluation) ## A `luz_module_evaluation` ## -- Results --------------------------------------------------------------------- ## loss: 1.5146 ## mae: 1.0251 ## mse: 1.5159 ## rmse: 1.2312"},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/fit.luz_module_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Entraîne un nn_module  🌐  Fit a nn_module — fit.luz_module_generator","title":"Entraîne un nn_module  🌐  Fit a nn_module — fit.luz_module_generator","text":"Entraîne un nn_module","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/fit.luz_module_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Entraîne un nn_module  🌐  Fit a nn_module — fit.luz_module_generator","text":"","code":"# Méthode S3 pour la classe luz_module_generator fit(   object,   data,   epochs = 10,   callbacks = NULL,   valid_data = NULL,   accelerator = NULL,   verbose = NULL,   ...,   dataloader_options = NULL )"},{"path":"https://cregouby.github.io/luz.fr/reference/fit.luz_module_generator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Entraîne un nn_module  🌐  Fit a nn_module — fit.luz_module_generator","text":"object Un nn_module qui est passé par la commande setup(). data (dataloader, dataset ou list) Un chargeur de donnée créé avec torch::dataloader() utilisé pour l'entraînement du modèle, ou un jeu de données créé avec torch::dataset() ou une liste. Les chargeurs de donnée et les jeux de données doivent renvoyer une liste contenant au plus 2 éléments. Le premier élément sera utilisé comme entrée pour le module et le second comme variable à prédire pour la fonction de perte. epochs (entier) Le nombre maximal d'époques d'entraînement du modèle. Si une valeur unique est fournie, elle sera prise comme max_epochs et min_epochs sera à 0. Si un vecteur de deux nombres est fourni, la première valeur sera min_epochs et la seconde valeur sera max_epochs. Le nombre minimum et maximum d'époques sont inclus dans l'objet context sous forme de ctx$min_epochs et ctx$max_epochs, respectivement. callbacks (optionnel) Une liste de callbacks définis avec luz_callback() qui seront appelés pendant la procédure d'entraînement. Les callbacks luz_callback_metrics(), luz_callback_progress() et luz_callback_train_valid() sont toujours ajoutés par défaut. valid_data (dataloader, dataset, liste ou réel; optionnel) Un chargeur de donnée créé avec torch::dataloader() ou un jeu de données créé avec torch::dataset() qui sera utilisé pendant la procédure de validation. Ils doivent retourner une liste contenant (input, target). Si data est un torch::dataset() ou une liste, vous pouvez également fournir une valeur numérique entre 0 et 1 - et dans ce cas, une échantillonnage aléatoire avec taille correspondante à celle proportionnelle à partir de data sera utilisée pour la validation. accelerator (accelerator, optional) Un objet accelerator() optionnel utilisé pour configurer le device cible du calcul pour des composants tels que les modules nn, les optimiseurs et batches de données. verbose (booléen, optionnel) La procédure d'entraînement doit-elle produire ses messages vers la console pendant l'entraînement. Par défaut, elle produira des message si interactive() est TRUE, sinon elle ne publiera pas vers la console. ... Inutilisé dataloader_options Options utilisées lors de la création d'un chargeur de donnée. Voir torch::dataloader(). shuffle=TRUE par défaut pour les données d'entraînement et batch_size=32 par défaut. Il y aura erreur si ce n'est pas NULL quand data est déjà un chargeur de donnée.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/fit.luz_module_generator.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Entraîne un nn_module  🌐  Fit a nn_module — fit.luz_module_generator","text":"Un objet entraîné qui peut être enregistré avec luz_save(), affiché avec print() et visualisé avec plot().","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/get_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Extrait les métriques de l'objet  🌐  Get metrics from the object — get_metrics","title":"Extrait les métriques de l'objet  🌐  Get metrics from the object — get_metrics","text":"Extrait les métriques de l'objet","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/get_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Extrait les métriques de l'objet  🌐  Get metrics from the object — get_metrics","text":"","code":"get_metrics(object, ...)  # Méthode S3 pour la classe luz_module_fitted get_metrics(object, ...)"},{"path":"https://cregouby.github.io/luz.fr/reference/get_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extrait les métriques de l'objet  🌐  Get metrics from the object — get_metrics","text":"object L'objet d'où extraire les métriques ... Inutilisé","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/get_metrics.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Extrait les métriques de l'objet  🌐  Get metrics from the object — get_metrics","text":"Un data.frame contenant les valeurs des métriques","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/get_metrics.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Extrait les métriques de l'objet  🌐  Get metrics from the object — get_metrics","text":"get_metrics(luz_module_fitted): Extrait les métriques d'un modèle luz entraîné.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/lr_finder.html","id":null,"dir":"Reference","previous_headings":"","what":"Recherche du taux d'apprentissage  🌐  Learning Rate Finder — lr_finder","title":"Recherche du taux d'apprentissage  🌐  Learning Rate Finder — lr_finder","text":"Recherche du taux d'apprentissage","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/lr_finder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Recherche du taux d'apprentissage  🌐  Learning Rate Finder — lr_finder","text":"","code":"lr_finder(   object,   data,   steps = 100,   start_lr = 1e-07,   end_lr = 0.1,   log_spaced_intervals = TRUE,   ...,   verbose = NULL )"},{"path":"https://cregouby.github.io/luz.fr/reference/lr_finder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recherche du taux d'apprentissage  🌐  Learning Rate Finder — lr_finder","text":"object Un module nn qui été configuré par setup(). data (dataloader) Un chargeur de donnée créé avec torch::dataloader(), utilisé pour le recherche de taux d'apprentissage. steps (entier) Le nombre d'itérations pour la recherche de taux d'apprentissage. Défaut : 100. start_lr (réel) La limite basse du taux d'apprentissage. end_lr (réel) La limite haute du taux d'apprentissage. log_spaced_intervals (booléen) Doit-découper logarithmiquement l'intervalle entre start_lr et end_lr (Si FALSE : intervalles uniformes). Défaut : TRUE ... Autres arguments passés à fit. verbose Doit-afficher un barre de progression pendant la recherche.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/lr_finder.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Recherche du taux d'apprentissage  🌐  Learning Rate Finder — lr_finder","text":"Un dataframe de deux colonnes : taux d'apprentissage et valeur de la fonction de perte","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback.html","id":null,"dir":"Reference","previous_headings":"","what":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","title":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","text":"Crée un nouveau callback","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","text":"","code":"luz_callback(   name = NULL,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame(),   inherit = NULL )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","text":"name nom du callback ... Méthodes publiques du callback. Le nom des méthodes est utilisé pour savoir comment elles doivent être appelées. Voir la section détails. private Une liste optionnelle de méthodes privées, qui peuvent être des fonctions et non-des fonctions. active Une liste optionnelle de fonctions d'active binding. parent_env Un environnement à utiliser comme parent pour les objets nouvellement créés. inherit Un objet R6ClassGenerator duquel hériter; autrement dit, une super-classe. Cela est capturé comme une expression non-évaluée qui sera évaluée dans parent_env chaque fois qu'un objet est instancié.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","text":"Un callback luz_callback que l'peut passer à fit.luz_module_generator().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","text":"Let’s implement callback prints ‘Iteration n’ (n iteration number) every batch training set ‘Done’ epoch finished. task use luz_callback function:   luz_callback() takes named functions ... arguments, name indicates moment callback called. instance on_train_batch_end() called every batch end training procedure, on_epoch_end() called end every epoch. returned value luz_callback() function initializes instance callback. Callbacks can initialization parameters, like name file want log results. case, can pass initialize method creating callback definition, save parameters self object. example, callback message parameter printed end epoch. callback defined can passed fit function via callbacks parameter:   Callbacks can called many different positions training loop, including combinations . ’s overview possible callback breakpoints:   Every step market on_* point training procedure available callbacks called. important part callbacks ctx (context) object. See help(\"ctx\") details. default, callbacks called order passed fit (predict evaluate), can provide weight attribute control order called. example, one callback weight = 10 another weight = 1, first one called second one. Callbacks don’t specify weight attribute considered weight = 0. built-callbacks luz already provide weight value. example, ?luz_callback_early_stopping weight Inf, since general want run last thing loop.","code":"print_callback <- luz_callback(   name = \"print_callback\",   initialize = function(message) {     self$message <- message   },   on_train_batch_end = function() {     cat(\"Iteration \", ctx$iter, \"\\n\")   },   on_epoch_end = function() {     cat(self$message, \"\\n\")   } ) fitted <- net    setup(...)    fit(..., callbacks = list(     print_callback(message = \"Done!\")   )) Start Fit    - on_fit_begin   Start Epoch Loop      - on_epoch_begin     Start Train        - on_train_begin       Start Batch Loop          - on_train_batch_begin           Start Default Training Step             - on_train_batch_after_pred             - on_train_batch_after_loss             - on_train_batch_before_backward             - on_train_batch_before_step             - on_train_batch_after_step           End Default Training Step:          - on_train_batch_end       End Batch Loop        - on_train_end     End Train     Start Valid        - on_valid_begin       Start Batch Loop          - on_valid_batch_begin           Start Default Validation Step             - on_valid_batch_after_pred             - on_valid_batch_after_loss           End Default Validation Step          - on_valid_batch_end       End Batch Loop        - on_valid_end     End Valid       - on_epoch_end   End Epoch Loop    - on_fit_end End Fit"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback.html","id":"prediction-callbacks","dir":"Reference","previous_headings":"","what":"Prediction callbacks","title":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","text":"can also use callbacks using predict(). case supported callback methods detailed .","code":"Start predict  - on_predict_begin  Start prediction loop   - on_predict_batch_begin   - on_predict_batch_end  End prediction loop  - on_predict_end End predict"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback.html","id":"evaluate-callbacks","dir":"Reference","previous_headings":"","what":"Evaluate callbacks","title":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","text":"Les fonctions de callback peuvent également être utilisées avec evaluate(), dans ce cas, les callbacks utilisés sont équivalents à ceux de la boucle de validation lors de l'utilisation de fit():","code":"Début de Validation  - on_valid_begin  Début de Boucle de Validation du Lot   - on_valid_batch_begin   Début de l'étape de Validation par défaut    - on_valid_batch_after_pred    - on_valid_batch_after_loss   Fin de l'étape de Validation par défaut   - on_valid_batch_end  Fin du Lot  - on_valid_end Fin de Validation"},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Créer un nouveau callback  🌐  Create a new callback — luz_callback","text":"","code":"print_callback <- luz_callback(  name = \"print_callback\",  on_train_batch_end = function() {    cat(\"Iteration \", ctx$iter, \"\\n\")  },  on_epoch_end = function() {    cat(\"Done!\\n\")  } ) #> Error in luz_callback(name = \"print_callback\", on_train_batch_end = function() {    cat(\"Iteration \", ctx$iter, \"\\n\")}, on_epoch_end = function() {    cat(\"Done!\\n\")}): impossible de trouver la fonction \"luz_callback\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_auto_resume.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback de reprise de l'entraînement du modèle.  🌐  Resume training callback — luz_callback_auto_resume","title":"Callback de reprise de l'entraînement du modèle.  🌐  Resume training callback — luz_callback_auto_resume","text":"Ce callback vous permet de reprendre l'entraînement du modèle.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_auto_resume.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback de reprise de l'entraînement du modèle.  🌐  Resume training callback — luz_callback_auto_resume","text":"","code":"luz_callback_auto_resume(path = \"./state.pt\")"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_auto_resume.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback de reprise de l'entraînement du modèle.  🌐  Resume training callback — luz_callback_auto_resume","text":"path Chemin où sauvegarder les fichiers d'instantané du modèle.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_auto_resume.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Callback de reprise de l'entraînement du modèle.  🌐  Resume training callback — luz_callback_auto_resume","text":"Quand l'utilise, les poids du modèle et l'état de l'optimiseur sont sérialisés à la fin de chaque époque. Si quelque chose échoue pendant l'entraînement, réexécuter le même script reprendra l'entraînement du modèle à l'époque qui suit la dernière époque sérialisée.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_auto_resume.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Callback de reprise de l'entraînement du modèle.  🌐  Resume training callback — luz_callback_auto_resume","text":"En général, vous voudrez ajouter ce callback en dernier dans la liste de callbacks, car ainsi, l'état sérialisé est susceptible de contenir toutes les modifications possibles apportées par d'autres callbacks à 'on_epoch_end'. Le weight par défaut de ce callback est Inf. Voir la vignette sur les instantanés pour plus de détails.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_auto_resume.html","id":"customizing-serialization","dir":"Reference","previous_headings":"","what":"Customizing serialization","title":"Callback de reprise de l'entraînement du modèle.  🌐  Resume training callback — luz_callback_auto_resume","text":"Par défaut, le modèle, l'état de l'optimiseur et l'état des callbacks sont sérialisés. Les callbacks peuvent être utilisés pour personnaliser la sérialisation en implémentant les méthodes state_dict() et load_state_dict(). Si ces méthodes sont implémentées, alors state_dict() est appelée à la fin de chaque époque et load_state_dict() est appelée lorsque le modèle reprend.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_csv_logger.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback pour journaliser les métriques en CSV  🌐  CSV logger callback — luz_callback_csv_logger","title":"Callback pour journaliser les métriques en CSV  🌐  CSV logger callback — luz_callback_csv_logger","text":"Logs metrics obtained training fiel disk. file 1 line epoch/validation.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_csv_logger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback pour journaliser les métriques en CSV  🌐  CSV logger callback — luz_callback_csv_logger","text":"","code":"luz_callback_csv_logger(path)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_csv_logger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback pour journaliser les métriques en CSV  🌐  CSV logger callback — luz_callback_csv_logger","text":"path chemin de fichier sur le disque.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_early_stopping.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback d'arrêt précoce  🌐  Early stopping callback — luz_callback_early_stopping","title":"Callback d'arrêt précoce  🌐  Early stopping callback — luz_callback_early_stopping","text":"Stoppe l'entraînement lorsque le métrique suivie cesse de s'améliorer","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_early_stopping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback d'arrêt précoce  🌐  Early stopping callback — luz_callback_early_stopping","text":"","code":"luz_callback_early_stopping(   monitor = \"valid_loss\",   min_delta = 0,   patience = 0,   mode = \"min\",   baseline = NULL )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_early_stopping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback d'arrêt précoce  🌐  Early stopping callback — luz_callback_early_stopping","text":"monitor Une chaîne au format <set>_<metric> où <set> peut être 'train' ou 'valid' et <metric> est l'abréviation d'une métrique qui est suivie pendant l'entraînement. Le nom de la métrique est insensible à la casse. min_delta Amélioration minimale pour réinitialiser le compteur de patience. patience Nombre d'époques sans amélioration avant de stopper l'entraînement. mode Spécifie la direction considérée comme une amélioration. Par défaut, 'min' est utilisé. Cela peut également être 'max' (lorque cherche à maximiser la métrique) et 'zero' (plus proche de zéro est mieux). baseline Une valeur initiale qui sera utilisée comme la meilleure valeur vue. L'entraînement s'arrêtera si aucune valeur meilleure que la valeur de référence n'est trouvée dans les premières patience époques.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_early_stopping.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Callback d'arrêt précoce  🌐  Early stopping callback — luz_callback_early_stopping","text":"Un luz_callback qui déclenche l'arrêt précoce de l'entraînement.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_early_stopping.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Callback d'arrêt précoce  🌐  Early stopping callback — luz_callback_early_stopping","text":"Ce callback ajoute un callback on_early_stopping qui peut être utilisé pour appeler d'autres callbacks dès que l'entraînement s'arrête . Si verbose=TRUE dans fit.luz_module_generator(), alors un message est imprimé lors de l'arrêt précoce de l'entraînement.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_early_stopping.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Callback d'arrêt précoce  🌐  Early stopping callback — luz_callback_early_stopping","text":"","code":"cb <- luz_callback_early_stopping() #> Error in luz_callback_early_stopping(): impossible de trouver la fonction \"luz_callback_early_stopping\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_gradient_clip.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback d'écrêtage du gradient  🌐  Gradient clipping callback — luz_callback_gradient_clip","title":"Callback d'écrêtage du gradient  🌐  Gradient clipping callback — luz_callback_gradient_clip","text":"En ajoutant le callback GradientClip, la norme norm_type (par défaut:2) des gradients est écrêtée à la valeur max_norm (par défaut: 1) utilisant torch::nn_utils_clip_grad_norm_(), ce qui peut éviter la divergence de la fonction de coût.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_gradient_clip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback d'écrêtage du gradient  🌐  Gradient clipping callback — luz_callback_gradient_clip","text":"","code":"luz_callback_gradient_clip(max_norm = 1, norm_type = 2)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_gradient_clip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback d'écrêtage du gradient  🌐  Gradient clipping callback — luz_callback_gradient_clip","text":"max_norm (entier ou réel) : norme maximale des gradients norm_type (entier ou réel) : type de la norme p utilisée. Peut être Inf pour la norme infinie.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_gradient_clip.html","id":"r-f-rences","dir":"Reference","previous_headings":"","what":"Références","title":"Callback d'écrêtage du gradient  🌐  Gradient clipping callback — luz_callback_gradient_clip","text":"Voir FastAI documentation pour le callback de GradientClip.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_interrupt.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback d'interruption  🌐  Interrupt callback — luz_callback_interrupt","title":"Callback d'interruption  🌐  Interrupt callback — luz_callback_interrupt","text":"Ajoute un gestionnaire qui permet d'interrompre la boucle d'apprentissage en utilisant ctrl + C. Enregistre également un point d'interruption on_interrupt afin que les utilisateurs puissent enregistrer d'autres callbacks qui seront exécutés lors de l'interruption de la boucle d'apprentissage.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_interrupt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback d'interruption  🌐  Interrupt callback — luz_callback_interrupt","text":"","code":"luz_callback_interrupt()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_interrupt.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Callback d'interruption  🌐  Interrupt callback — luz_callback_interrupt","text":"Un luz_callback","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_interrupt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Callback d'interruption  🌐  Interrupt callback — luz_callback_interrupt","text":"Vous n'avez généralement pas à utiliser ces callbacks par vous-même, car ils sont toujours inclus par défaut dans fit.luz_module_generator().","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_interrupt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Callback d'interruption  🌐  Interrupt callback — luz_callback_interrupt","text":"","code":"interrupt_callback <- luz_callback_interrupt() #> Error in luz_callback_interrupt(): impossible de trouver la fonction \"luz_callback_interrupt\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_keep_best_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Conserver le meilleur modèle  🌐  Keep the best model — luz_callback_keep_best_model","title":"Conserver le meilleur modèle  🌐  Keep the best model — luz_callback_keep_best_model","text":"À chaque époque, si il y amélioration dans la métrique surveillée, sauvegarde les poids du modèle dans un fichier temporaire. Lorsque l'entraînement est terminé, recharge les poids du meilleur modèle.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_keep_best_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Conserver le meilleur modèle  🌐  Keep the best model — luz_callback_keep_best_model","text":"","code":"luz_callback_keep_best_model(   monitor = \"valid_loss\",   mode = \"min\",   min_delta = 0 )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_keep_best_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conserver le meilleur modèle  🌐  Keep the best model — luz_callback_keep_best_model","text":"monitor Une chaîne au format <set>_<metric> où <set> peut être 'train' ou 'valid' et <metric> est l'abréviation d'une métrique qui est suivie pendant l'entraînement. Le nom de la métrique est insensible à la casse. mode Spécifie la direction considérée comme une amélioration. Par défaut, 'min' est utilisé. Cela peut également être 'max' (lorque cherche à maximiser la métrique) et 'zero' (plus proche de zéro est mieux). min_delta Amélioration minimale pour réinitialiser le compteur de patience.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_keep_best_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Conserver le meilleur modèle  🌐  Keep the best model — luz_callback_keep_best_model","text":"","code":"cb <- luz_callback_keep_best_model() #> Error in luz_callback_keep_best_model(): impossible de trouver la fonction \"luz_callback_keep_best_model\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_lr_scheduler.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback de modification du taux d'apprentissage  🌐  Learning rate scheduler callback — luz_callback_lr_scheduler","title":"Callback de modification du taux d'apprentissage  🌐  Learning rate scheduler callback — luz_callback_lr_scheduler","text":"Initialisation et exécution des torch::lr_scheduler()s.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_lr_scheduler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback de modification du taux d'apprentissage  🌐  Learning rate scheduler callback — luz_callback_lr_scheduler","text":"","code":"luz_callback_lr_scheduler(   lr_scheduler,   ...,   call_on = \"on_epoch_end\",   opt_name = NULL )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_lr_scheduler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback de modification du taux d'apprentissage  🌐  Learning rate scheduler callback — luz_callback_lr_scheduler","text":"lr_scheduler Un torch::lr_scheduler() qui sera initialisé avec l'optimiseur et les paramètres ... . ... Arguments supplémentaires passés avec l'optimiseur à lr_scheduler. call_on Le point d'arrêt du callback auquel scheduler$step() est appelé. Par défaut c'est 'on_epoch_end'. Voir luz_callback() pour plus d'informations. opt_name Nom de l'optimiseur qui sera affecté par ce callback. Doit correspondre au nom donné dans set_optimizers. Si votre module un seul optimiseur, opt_name n'est pas utilisé.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_lr_scheduler.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Callback de modification du taux d'apprentissage  🌐  Learning rate scheduler callback — luz_callback_lr_scheduler","text":"Un générateur luz_callback().","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_lr_scheduler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Callback de modification du taux d'apprentissage  🌐  Learning rate scheduler callback — luz_callback_lr_scheduler","text":"","code":"if (torch::torch_is_installed()) { cb <- luz_callback_lr_scheduler(torch::lr_step, step_size = 30) } #> Error in luz_callback_lr_scheduler(torch::lr_step, step_size = 30): impossible de trouver la fonction \"luz_callback_lr_scheduler\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback sur les métriques  🌐  Metrics callback — luz_callback_metrics","title":"Callback sur les métriques  🌐  Metrics callback — luz_callback_metrics","text":"Suit les métriques passées à setup() pendant l'entraînement et la validation.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback sur les métriques  🌐  Metrics callback — luz_callback_metrics","text":"","code":"luz_callback_metrics()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_metrics.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Callback sur les métriques  🌐  Metrics callback — luz_callback_metrics","text":"Un luz_callback","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_metrics.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Callback sur les métriques  🌐  Metrics callback — luz_callback_metrics","text":"Ce callback s'occupe de 2 attributs de  ctx: ctx$metrics: stocke les objets de métriques courants qui sont réinitialisés une fois par époque, et qui seront plus tard mis à jour pas update() et calculés pas compute() à chaque lot. Vous aurez rarement besoin de travailler avec ces métriques. ctx$records$metrics: Stocke les métriques pour entraînement et validation pour chaque époque. La structure est très similaire à ctx$losses.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_metrics.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Callback sur les métriques  🌐  Metrics callback — luz_callback_metrics","text":"En général, vous n'avez pas besoin d'utiliser explicitement le callback de métriques car il est utilisé par défaut dans fit.luz_module_generator().","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixed_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback de gestion automatique de la précision mixte  🌐  Automatic Mixed Precision callback — luz_callback_mixed_precision","title":"Callback de gestion automatique de la précision mixte  🌐  Automatic Mixed Precision callback — luz_callback_mixed_precision","text":"Ce callback activera l'entraînement du modèle torch::local_autocast() pendant la phase forward() et pendant le calcul de la fonction de coût. Il désactivera ensuite l'autocast et normalisera la fonction de coût avant la phase backward() et opt$step(). Pour en savoir plus, voir  ici.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixed_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback de gestion automatique de la précision mixte  🌐  Automatic Mixed Precision callback — luz_callback_mixed_precision","text":"","code":"luz_callback_mixed_precision(...)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixed_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback de gestion automatique de la précision mixte  🌐  Automatic Mixed Precision callback — luz_callback_mixed_precision","text":"... Passé à torch::cuda_amp_grad_scaler().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixed_precision.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Callback de gestion automatique de la précision mixte  🌐  Automatic Mixed Precision callback — luz_callback_mixed_precision","text":"Un callback de type luz_callback","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixup.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback de mixup  🌐  Mixup callback — luz_callback_mixup","title":"Callback de mixup  🌐  Mixup callback — luz_callback_mixup","text":"Mise en œuvre de 'mixup: Beyond Empirical Risk Minimization'. Actuellement testé uniquement pour les données catégorielles, où les variables à prédire sont encodées comme des entiers, et pas encodées en binaire un-contre-tous. Ce callback doit être utilisé simultanément avec `nn_mixup_loss()`.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback de mixup  🌐  Mixup callback — luz_callback_mixup","text":"","code":"luz_callback_mixup(alpha = 0.4, ..., run_valid = FALSE, auto_loss = FALSE)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback de mixup  🌐  Mixup callback — luz_callback_mixup","text":"alpha paramètre de la distribution béta utilisée pour échantillonner les coefficients de mélange ... actuellement non utilisé. Juste pour forcer des arguments nommés. run_valid Doit-il s'exécuter aussi pendant la validation ? auto_loss Doit-modifier automatiquement la fonction de coût ? Cela créera une fonction de perte mixup basée sur la fonction de coût. Si TRUE, assurez-vous que votre fonction de coût n'applique pas de réduction. Si run_valid=FALSE, la fonction de coût sera réduite à sa moyenne pendant la validation.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixup.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Callback de mixup  🌐  Mixup callback — luz_callback_mixup","text":"Un callback `luz_callback`","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_mixup.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Callback de mixup  🌐  Mixup callback — luz_callback_mixup","text":"Dans l'ensemble, nous suivons l'implémentation de fastai décrite ici. À savoir, Nous travaillons avec un seul chargeur de donnée, en mélangeant deux observations aléatoirement à partir du même lot. Nous combinons linéairement les pertes calculées pour les deux cibles : loss(output, new_target) = weight * loss(output, target1) + (1-weight) * loss(output, target2) Nous tirons des coefficients de mélange différents pour chaque paire. Nous remplaçons weight par weight = max(weight, 1-weight) pour éviter les répétitions. (torch::torch_is_installed()) mixup_callback <- luz_callback_mixup() nn_mixup_loss(), nnf_mixup()Autres luz_callbacks: luz_callback_auto_resume(), luz_callback_csv_logger(), luz_callback_early_stopping(), luz_callback_interrupt(), luz_callback_keep_best_model(), luz_callback_lr_scheduler(), luz_callback_metrics(), luz_callback_mixed_precision(), luz_callback_model_checkpoint(), luz_callback_profile(), luz_callback_progress(), luz_callback_resume_from_checkpoint(), luz_callback_train_valid(), luz_callback()  luz_callbacks","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_model_checkpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Sauvegarde un instantanné du modèle  🌐  Checkpoints model weights — luz_callback_model_checkpoint","text":"","code":"luz_callback_model_checkpoint(   path,   monitor = \"valid_loss\",   save_best_only = FALSE,   mode = \"min\",   min_delta = 0 )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_model_checkpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sauvegarde un instantanné du modèle  🌐  Checkpoints model weights — luz_callback_model_checkpoint","text":"path Chemin pour sauvegarder le modèle sur disque dur. Le chemin est interpolé avec glue, donc vous pouvez utiliser tout attribut dans le ctx en utilisant '{ctx$epoch}'. Par exemple, les valeurs epoch et monitor sont déjà présentes dans l'environnement. Si le chemin spécifié est un répertoire (se termine par / ou }), alors les modèles sont sauvegardés avec le nom fourni par \\verb{epoch-{epoch:02d}-{self$monitor}-{monitor:.3f}.pt}. Voir les exemples. Vous pouvez utiliser \\code{\\link[=sprintf]{sprintf()}} pour formater rapidement les valeurs, par exemple:\\code{'{epoch:02d}'}. monitorUne chaîne au format <set>_<metric> où <set> peut être 'train' ou 'valid' et <metric> est l'abréviation de toute métrique suivie pendant l'entraînement. Le nom de la métrique est insensible à la casse. save_best_onlySi TRUE, les modèles ne sont sauvegardés que si ils améliorent un modèle précédemment enregistré. modeSpécifie la direction considérée comme une amélioration. Par défaut, 'min' est utilisé. Cela peut également être 'max' (lorque cherche à maximiser la métrique) et 'zero' (plus proche de zéro est mieux). min_deltaDifférence minimale à considérer comme une amélioration. Seulement utilisée lorsque save_best_only=TRUE. Sauvegarde l'instantanné du modèle selon la métrique spécifiée et le comportement. mode et min_delta ne sont utilisés que lorsque save_best_only=TRUE. save_best_only écrasera les modèles enregistrés si le paramètre path ne différencie pas les noms des modèles par epochs.Voir la vignette sur les instantanés pour plus de détails. luz_callback_model_checkpoint(path= \"path//dir\") luz_callback_model_checkpoint(path= \"path//dir/epoch-epoch:02d/model.pt\") luz_callback_model_checkpoint(path= \"path//dir/epoch-epoch:02d/model-monitor:.2f.pt\") Autres callbacks luz: luz_callback_auto_resume(), luz_callback_csv_logger(), luz_callback_early_stopping(), luz_callback_interrupt(), luz_callback_keep_best_model(), luz_callback_lr_scheduler(), luz_callback_metrics(), luz_callback_mixup(), luz_callback_model_checkpoint(), luz_callback_profile(), luz_callback_progress(), luz_callback_resume_from_checkpoint(), luz_callback_train_valid(), luz_callback()  luz_callbacks","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_profile.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback de profilage  🌐  Profile callback — luz_callback_profile","title":"Callback de profilage  🌐  Profile callback — luz_callback_profile","text":"Calcule les temps pour les opérations de haut niveau dans les boucles d'apprentissage.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_profile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback de profilage  🌐  Profile callback — luz_callback_profile","text":"","code":"luz_callback_profile()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_profile.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Callback de profilage  🌐  Profile callback — luz_callback_profile","text":"Un callback de type luz_callback","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_profile.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Callback de profilage  🌐  Profile callback — luz_callback_profile","text":"Les valeurs sont enregistrés dans ctx$records$profile. Les temps sont en secondes. Les données sont stockées avec la structure suivante : fit temps de l'ensemble de la precedure fit. epoch temps par époque.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_profile.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Callback de profilage  🌐  Profile callback — luz_callback_profile","text":"En général, vous n'avez pas besoin d'utiliser ce callback par vous-même car il est toujours inclus par défaut dans fit.luz_module_generator().","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_profile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Callback de profilage  🌐  Profile callback — luz_callback_profile","text":"","code":"profile_callback <- luz_callback_profile() #> Error in luz_callback_profile(): impossible de trouver la fonction \"luz_callback_profile\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_progress.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback de progression  🌐  Progress callback — luz_callback_progress","title":"Callback de progression  🌐  Progress callback — luz_callback_progress","text":"Affiche une bare de progression pendant l'entraînement.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_progress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Callback de progression  🌐  Progress callback — luz_callback_progress","text":"","code":"luz_callback_progress()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_progress.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Callback de progression  🌐  Progress callback — luz_callback_progress","text":"Un callback de type luz_callback","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_progress.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Callback de progression  🌐  Progress callback — luz_callback_progress","text":"En général, vous n'avez pas besoin d'utiliser ce callback par vous-même car il est toujours inclus par défaut en fit.luz_module_generator(). L'affichage peut être désactivé en passant verbose=FALSE à fit.luz_module_generator().","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_resume_from_checkpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Permettre la reprise de l'entraînement du modèle à partir d'un instantané spécifique.  🌐  Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","title":"Permettre la reprise de l'entraînement du modèle à partir d'un instantané spécifique.  🌐  Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","text":"Permet de reprendre l'entraînement d'un modèle à partir d'un instantanné.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_resume_from_checkpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Permettre la reprise de l'entraînement du modèle à partir d'un instantané spécifique.  🌐  Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","text":"","code":"luz_callback_resume_from_checkpoint(   path,   ...,   restore_model_state = TRUE,   restore_records = FALSE,   restore_optimizer_state = FALSE,   restore_callbacks_state = FALSE )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_resume_from_checkpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permettre la reprise de l'entraînement du modèle à partir d'un instantané spécifique.  🌐  Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","text":"path Chemin du fichier de poids intermédiaires. ... inutilisé restore_model_state Wether restore model state callback. restore_records Doit-restaurer les enregistrements à partir de l'instantané. restore_optimizer_state Doit-restaurer l'état de l'optimiseur à partir de l'instantané. restore_callbacks_state Doit-restaurer l'état des callbacks à partir de l'instantané.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_resume_from_checkpoint.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Permettre la reprise de l'entraînement du modèle à partir d'un instantané spécifique.  🌐  Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","text":"Voir la vignette sur les instantanés pour plus de détails.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_tfevents.html","id":null,"dir":"Reference","previous_headings":"","what":"callback tfevent  🌐  tfevents callback — luz_callback_tfevents","title":"callback tfevent  🌐  tfevents callback — luz_callback_tfevents","text":"Enregistre des métriques et d'autres informations du modèle sous forme de fichier tfevents. Quand tensorboard est installé, il peut être utilisé pour visualiser les résultats.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_tfevents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"callback tfevent  🌐  tfevents callback — luz_callback_tfevents","text":"","code":"luz_callback_tfevents(logdir = \"logs\", histograms = FALSE, ...)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_tfevents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"callback tfevent  🌐  tfevents callback — luz_callback_tfevents","text":"logdir Un répertoire où sera écrit le journal. histograms Un booléen spécifiant si les histogrammes des poids du modèle doivent être enregistrés. Peut aussi être un vecteur de chaîne de caractères spécifiant les noms des paramètres à enregistrer (noms identiques à names(model$parameters)). ... Inutilisé","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_tfevents.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"callback tfevent  🌐  tfevents callback — luz_callback_tfevents","text":"","code":"tensorboard --logdir=logs"},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_train_valid.html","id":null,"dir":"Reference","previous_headings":"","what":"callback train-eval  🌐  Train-eval callback — luz_callback_train_valid","title":"callback train-eval  🌐  Train-eval callback — luz_callback_train_valid","text":"Bascule les paramètres importants entre les modes d'apprentissage et de validation.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_train_valid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"callback train-eval  🌐  Train-eval callback — luz_callback_train_valid","text":"","code":"luz_callback_train_valid()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_train_valid.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"callback train-eval  🌐  Train-eval callback — luz_callback_train_valid","text":"Un luz_callback","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_train_valid.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"callback train-eval  🌐  Train-eval callback — luz_callback_train_valid","text":"Il s'occupe des trois attributs suivants de l'objet ctx : ctx$model: Gère l'appel à ctx$model$train() et ctx$model$eval(), lorsque c'est approprié. ctx$training: Fixe ce fanion à TRUE lors de l'apprentissage et à FALSE lors de la validation. ctx$loss: Réinitialise l'attribut loss à list() lorsque l'apprentissage ou la validation est terminé.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_callback_train_valid.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"callback train-eval  🌐  Train-eval callback — luz_callback_train_valid","text":"general need explicitly use metrics callback used default fit.luz_module_generator().","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Charge un modèle entrainé depuis le disque  🌐  Load trained model — luz_load","title":"Charge un modèle entrainé depuis le disque  🌐  Load trained model — luz_load","text":"Charge un modèle entraîné. Voir la documentation dans luz_save().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Charge un modèle entrainé depuis le disque  🌐  Load trained model — luz_load","text":"","code":"luz_load(path)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Charge un modèle entrainé depuis le disque  🌐  Load trained model — luz_load","text":"path path file system save object.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load_checkpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Charge un instantanné  🌐  Loads a checkpoint — luz_load_checkpoint","title":"Charge un instantanné  🌐  Loads a checkpoint — luz_load_checkpoint","text":"Fonctionne avec les instantanés créés avec luz_callback_model_checkpoint().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load_checkpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Charge un instantanné  🌐  Loads a checkpoint — luz_load_checkpoint","text":"","code":"luz_load_checkpoint(obj, path, ...)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load_checkpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Charge un instantanné  🌐  Loads a checkpoint — luz_load_checkpoint","text":"obj Object want laod checkpoint. path Chemin de l'instantané sur le disque. ... inutilisé.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load_model_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Charge des poids sauvegardés sur disque, dans un modèle.  🌐  Loads model weights into a fitted object. — luz_load_model_weights","title":"Charge des poids sauvegardés sur disque, dans un modèle.  🌐  Loads model weights into a fitted object. — luz_load_model_weights","text":"Peut être utile quand vous avez sauvegardé des instantanés de modèle pendant l'entraînement, et que vous voulez restaurer le meilleur instantané à la fin.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load_model_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Charge des poids sauvegardés sur disque, dans un modèle.  🌐  Loads model weights into a fitted object. — luz_load_model_weights","text":"","code":"luz_load_model_weights(obj, path, ...)  luz_save_model_weights(obj, path)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load_model_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Charge des poids sauvegardés sur disque, dans un modèle.  🌐  Loads model weights into a fitted object. — luz_load_model_weights","text":"obj Objet luz sur lequel copier les nouveaux poids. path Chemin du fichier de poids sauvegardé sur le disque. ... Autres arguments passés à torch_load().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load_model_weights.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Charge des poids sauvegardés sur disque, dans un modèle.  🌐  Loads model weights into a fitted object. — luz_load_model_weights","text":"Retourne NULL de manière invisible.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_load_model_weights.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Charge des poids sauvegardés sur disque, dans un modèle.  🌐  Loads model weights into a fitted object. — luz_load_model_weights","text":"luz_save_model_weights opère directement sur l'objet, c-à-d qu'il modifie le modèle pour lui affecter les nouveaux poids.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Crée une nouvelle métrique luz  🌐  Creates a new luz metric — luz_metric","title":"Crée une nouvelle métrique luz  🌐  Creates a new luz metric — luz_metric","text":"Crée une nouvelle métrique luz","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Crée une nouvelle métrique luz  🌐  Creates a new luz metric — luz_metric","text":"","code":"luz_metric(   name = NULL,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame(),   inherit = NULL )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Crée une nouvelle métrique luz  🌐  Creates a new luz metric — luz_metric","text":"name string naming new metric. ... named list public methods. implement least initialize, update compute. See details section information. private optional list private members, can functions non-functions. active optional list active binding functions. parent_env environment use parent newly-created objects. inherit R6ClassGenerator object inherit ; words, superclass. captured unevaluated expression evaluated parent_env time object instantiated.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Crée une nouvelle métrique luz  🌐  Creates a new luz metric — luz_metric","text":"Renvoie la nouvelle métrique luz.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Crée une nouvelle métrique luz  🌐  Creates a new luz metric — luz_metric","text":"Pour implémenter un nouveau luz_metric, il faut implémenter 3 méthodes: initialize: définit l'état initial de la métrique. Cette fonction est appelée pour chaque époque dans les boucles d'entraînement et de validation. update: met à jour l'état interne de la métrique. Cette fonction est appelée à chaque étape d'entraînement et de validation avec les prédictions obtenues par le modèle et les valeurs cibles obtenues à partir du chargeur de donnée. compute: utilise l'état interne pour calculer les valeurs du métrique. Cette fonction est appelée chaque fois que nous devons obtenir la valeur actuelle du métrique. Eg, elle est appelée chaque étape d'entraînement pour les métriques affichées dans la bare de progression, mais uniquement appelée une fois par époque pour enregistrer sa valeur lorsque la bare de progression n'est pas affichée. Optionnellement, vous pouvez implémenter un champ abbrev qui donne à la métrique un abrégé que l'utilisera lors de l'  affichage d'informations sur les métriques dans le console ou enregistrer. Si aucun abbrev n'est passé, le nom de classe sera utilisé. Voyons comment implémenter luz_metric_accuracy pour voir comment implémenter une nouvelle métrique:   strongNote : Il est recommandé que le métrique compute renvoie des valeurs régulières R au lieu de tenseurs torch car c'est ce qui est attendu par les autres parties de luz.","code":"luz_metric_accuracy <- luz_metric(  # Un abrégé à afficher dans les barreaux de progression, ou n# lorsque l'on imprime la progression   abbrev = \"Acc\",   # Configuration initiale pour le métrique. Les métriques sont initialisées   # à chaque époque, pour les boucles d'entraînement et de validation   initialize = function() {     self$correct <- 0     self$total <- 0   },  # Exécuter à chaque étape d'entraînement ou de validation et mettre à jour  # l'état interne. La fonction update prend `preds` et `target` en paramètres.  update = function(preds, target) {     pred <- torch::torch_argmax(preds, dim = 2)  self$correct <- self$correct + (pred == target)$       to(dtype = torch::torch_float())$  sum()$       item()        self$total <- self$total + pred$numel()   },  # Utiliser l'état interne pour interroger la valeur du métrique   compute = function() {  self$correct/self$total   } )"},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Crée une nouvelle métrique luz  🌐  Creates a new luz metric — luz_metric","text":"","code":"luz_metric_accuracy <- luz_metric(   # An abbreviation to be shown in progress bars, or   # when printing progress   abbrev = \"Acc\",   # Initial setup for the metric. Metrics are initialized   # every epoch, for both training and validation   initialize = function() {     self$correct <- 0     self$total <- 0   },   # Run at every training or validation step and updates   # the internal state. The update function takes `preds`   # and `target` as parameters.   update = function(preds, target) {     pred <- torch::torch_argmax(preds, dim = 2)     self$correct <- self$correct + (pred == target)$       to(dtype = torch::torch_float())$       sum()$       item()     self$total <- self$total + pred$numel()   },   # Use the internal state to query the metric value   compute = function() {     self$correct/self$total   } ) #> Error in luz_metric(abbrev = \"Acc\", initialize = function() {    self$correct <- 0    self$total <- 0}, update = function(preds, target) {    pred <- torch::torch_argmax(preds, dim = 2)    self$correct <- self$correct + (pred == target)$to(dtype = torch::torch_float())$sum()$item()    self$total <- self$total + pred$numel()}, compute = function() {    self$correct/self$total}): impossible de trouver la fonction \"luz_metric\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Précision (accuracy)  🌐  Accuracy — luz_metric_accuracy","title":"Précision (accuracy)  🌐  Accuracy — luz_metric_accuracy","text":"Calcule la précision (accuracy) pour les problèmes de classification multi-classes.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Précision (accuracy)  🌐  Accuracy — luz_metric_accuracy","text":"","code":"luz_metric_accuracy()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_accuracy.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Précision (accuracy)  🌐  Accuracy — luz_metric_accuracy","text":"Renvoie la nouvelle métrique luz.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_accuracy.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Précision (accuracy)  🌐  Accuracy — luz_metric_accuracy","text":"Cette métrique s'attend à des logits ou des probabilités à chaque mise à jour. Elle prend alors l'argmax par colonne et le compare à la variable cible.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Précision (accuracy)  🌐  Accuracy — luz_metric_accuracy","text":"","code":"if (torch::torch_is_installed()) { library(torch) metric <- luz_metric_accuracy() metric <- metric$new() metric$update(torch_randn(100, 10), torch::torch_randint(1, 10, size = 100)) metric$compute() } #> Error in luz_metric_accuracy(): impossible de trouver la fonction \"luz_metric_accuracy\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Précision binaire  🌐  Binary accuracy — luz_metric_binary_accuracy","title":"Précision binaire  🌐  Binary accuracy — luz_metric_binary_accuracy","text":"Calcule la précision pour les problèmes de classification binaire pour un modèle avec des probabilités en sortie. Le plus souvent, associé à torch::nn_bce_loss().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Précision binaire  🌐  Binary accuracy — luz_metric_binary_accuracy","text":"","code":"luz_metric_binary_accuracy(threshold = 0.5)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Précision binaire  🌐  Binary accuracy — luz_metric_binary_accuracy","text":"threshold valeur de seuil pour classifier les observations en 0 ou 1.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Précision binaire  🌐  Binary accuracy — luz_metric_binary_accuracy","text":"Renvoie la nouvelle métrique luz.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Précision binaire  🌐  Binary accuracy — luz_metric_binary_accuracy","text":"","code":"if (torch::torch_is_installed()) { library(torch) metric <- luz_metric_binary_accuracy(threshold = 0.5) metric <- metric$new() metric$update(torch_rand(100), torch::torch_randint(0, 1, size = 100)) metric$compute() } #> Error in luz_metric_binary_accuracy(threshold = 0.5): impossible de trouver la fonction \"luz_metric_binary_accuracy\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy_with_logits.html","id":null,"dir":"Reference","previous_headings":"","what":"Précision binaire avec logits  🌐  Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","title":"Précision binaire avec logits  🌐  Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"Calcule la précision (accuracy) pour les problèmes de classification binaire pour un modèle avec des logits en sortie. Le plus souvent, associé à torch::nn_bce_with_logits_loss().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy_with_logits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Précision binaire avec logits  🌐  Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"","code":"luz_metric_binary_accuracy_with_logits(threshold = 0.5)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy_with_logits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Précision binaire avec logits  🌐  Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"threshold valeur de seuil pour classifier les observations en 0 ou 1.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy_with_logits.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Précision binaire avec logits  🌐  Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"Renvoie la nouvelle métrique luz.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy_with_logits.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Précision binaire avec logits  🌐  Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"Les probabilités sont calcullées avec torch::nnf_sigmoid() et le threshold permet de classifier en 0 ou 1.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_accuracy_with_logits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Précision binaire avec logits  🌐  Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"","code":"if (torch::torch_is_installed()) { library(torch) metric <- luz_metric_binary_accuracy_with_logits(threshold = 0.5) metric <- metric$new() metric$update(torch_randn(100), torch::torch_randint(0, 1, size = 100)) metric$compute() } #> Error in luz_metric_binary_accuracy_with_logits(threshold = 0.5): impossible de trouver la fonction \"luz_metric_binary_accuracy_with_logits\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_auroc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calcule la surface sous la courbe de ROC  🌐  Computes the area under the ROC — luz_metric_binary_auroc","title":"Calcule la surface sous la courbe de ROC  🌐  Computes the area under the ROC — luz_metric_binary_auroc","text":"Pour éviter de stocker toutes les prédictions et les valeurscibles pour une époque, nous calculons des matrices de confusion sur une plage de seuils établis à l'avance.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_auroc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Calcule la surface sous la courbe de ROC  🌐  Computes the area under the ROC — luz_metric_binary_auroc","text":"","code":"luz_metric_binary_auroc(   num_thresholds = 200,   thresholds = NULL,   from_logits = FALSE )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_auroc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calcule la surface sous la courbe de ROC  🌐  Computes the area under the ROC — luz_metric_binary_auroc","text":"num_thresholds Nombre de seuils utilisés pour calculer les matrices de confusion. Lorsqu'utilisés, les seuils sont créés en prenant num_thresholds valeurs linéairement espacées sur l'intervale [0, 1]. thresholds (facultatif) Si des seuils sont fournis, alors ceux-ci sont utilisés pour calculer les matrices de confusion et le paramètre num_thresholds est ignoré. from_logits Booléen indiquant si les prédictions sont des logits, dans ce cas nous utilisons la fonction sigmoid pour les placer dans l'intervalle [0, 1].","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_binary_auroc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Calcule la surface sous la courbe de ROC  🌐  Computes the area under the ROC — luz_metric_binary_auroc","text":"","code":"if (torch::torch_is_installed()){ library(torch) actual <- c(1, 1, 1, 0, 0, 0) predicted <- c(0.9, 0.8, 0.4, 0.5, 0.3, 0.2)  y_true <- torch_tensor(actual) y_pred <- torch_tensor(predicted)  m <- luz_metric_binary_auroc(thresholds = predicted) m <- m$new()  m$update(y_pred[1:2], y_true[1:2]) m$update(y_pred[3:4], y_true[3:4]) m$update(y_pred[5:6], y_true[5:6])  m$compute() } #> Error in luz_metric_binary_auroc(thresholds = predicted): impossible de trouver la fonction \"luz_metric_binary_auroc\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Erreur absolue moyenne  🌐  Mean absolute error — luz_metric_mae","title":"Erreur absolue moyenne  🌐  Mean absolute error — luz_metric_mae","text":"Calcule l'erreur absolue moyenne.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Erreur absolue moyenne  🌐  Mean absolute error — luz_metric_mae","text":"","code":"luz_metric_mae()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_mae.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Erreur absolue moyenne  🌐  Mean absolute error — luz_metric_mae","text":"Renvoie la nouvelle métrique luz.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_mae.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Erreur absolue moyenne  🌐  Mean absolute error — luz_metric_mae","text":"","code":"if (torch::torch_is_installed()) { library(torch) metric <- luz_metric_mae() metric <- metric$new() metric$update(torch_randn(100), torch_randn(100)) metric$compute() } #> Error in luz_metric_mae(): impossible de trouver la fonction \"luz_metric_mae\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Erreur quadratique moyenne (MSE)  🌐  Mean squared error — luz_metric_mse","title":"Erreur quadratique moyenne (MSE)  🌐  Mean squared error — luz_metric_mse","text":"Calcule l'erreur quadratique moyenne (MSE).","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Erreur quadratique moyenne (MSE)  🌐  Mean squared error — luz_metric_mse","text":"","code":"luz_metric_mse()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_mse.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Erreur quadratique moyenne (MSE)  🌐  Mean squared error — luz_metric_mse","text":"Renvoie la nouvelle métrique luz.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_multiclass_auroc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calcule la surface sour la courbe de ROC dans le cas multi-classe.  🌐  Computes the multi-class AUROC — luz_metric_multiclass_auroc","title":"Calcule la surface sour la courbe de ROC dans le cas multi-classe.  🌐  Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"La définition de  Keras est utilisée par défaut. Cela équivaut à la méthode 'micro' dans SciKit Learn. Voir docs.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_multiclass_auroc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Calcule la surface sour la courbe de ROC dans le cas multi-classe.  🌐  Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"","code":"luz_metric_multiclass_auroc(   num_thresholds = 200,   thresholds = NULL,   from_logits = FALSE,   average = c(\"micro\", \"macro\", \"weighted\", \"none\") )"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_multiclass_auroc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calcule la surface sour la courbe de ROC dans le cas multi-classe.  🌐  Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"num_thresholds Nombre de seuils utilisés pour calculer les matrices de confusion. Lorsqu'utilisés, les seuils sont créés en prenant num_thresholds valeurs linéairement espacées sur l'intervale [0, 1]. thresholds (facultatif) Si des seuils sont fournis, alors ceux-ci sont utilisés pour calculer les matrices de confusion et le paramètre num_thresholds est ignoré. from_logits Si TRUE alors nous appliquons torch::nnf_softmax() sur les predictions avant le calcul de la métrique. average La méthode pour moyenner : 'micro' : Empile toutes les classes et calcule l'AUC comme si c'était un problème de classification binaire. 'macro' : Trouve l'AUC pour chaque classe et calcule leur moyenne. 'weighted' : Trouve l'AUC pour chaque classe et calcule leur moyenne pondéré en fonction du nombre d'instances pour chaque classe. 'none' : Retourne l'AUC pour chaque classe dans une liste.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_multiclass_auroc.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Calcule la surface sour la courbe de ROC dans le cas multi-classe.  🌐  Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"Notez que le déséquilibre des classes peut affecter cette métrique, contrairement à l'AUC pour une classification binaire.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_multiclass_auroc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Calcule la surface sour la courbe de ROC dans le cas multi-classe.  🌐  Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"","code":"if (torch::torch_is_installed()) { library(torch) actual <- c(1, 1, 1, 0, 0, 0) + 1L predicted <- c(0.9, 0.8, 0.4, 0.5, 0.3, 0.2) predicted <- cbind(1-predicted, predicted)  y_true <- torch_tensor(as.integer(actual)) y_pred <- torch_tensor(predicted)  m <- luz_metric_multiclass_auroc(thresholds = as.numeric(predicted),                                  average = \"micro\") m <- m$new()  m$update(y_pred[1:2,], y_true[1:2]) m$update(y_pred[3:4,], y_true[3:4]) m$update(y_pred[5:6,], y_true[5:6]) m$compute() } #> Error in luz_metric_multiclass_auroc(thresholds = as.numeric(predicted),     average = \"micro\"): impossible de trouver la fonction \"luz_metric_multiclass_auroc\""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_rmse.html","id":null,"dir":"Reference","previous_headings":"","what":"Erreur quadratique moyenne (RMSE)  🌐  Root mean squared error — luz_metric_rmse","title":"Erreur quadratique moyenne (RMSE)  🌐  Root mean squared error — luz_metric_rmse","text":"Calcule l'erreur quadratique moyenne (RMSE).","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_rmse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Erreur quadratique moyenne (RMSE)  🌐  Root mean squared error — luz_metric_rmse","text":"","code":"luz_metric_rmse()"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_rmse.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Erreur quadratique moyenne (RMSE)  🌐  Root mean squared error — luz_metric_rmse","text":"Renvoie la nouvelle métrique luz.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_set.html","id":null,"dir":"Reference","previous_headings":"","what":"Crée un ensemble de métriques  🌐  Creates a metric set — luz_metric_set","title":"Crée un ensemble de métriques  🌐  Creates a metric set — luz_metric_set","text":"Un ensemble de métriques à utiliser pour specifier les métriques à utiliser pendant l'entraînement, l'évaluation, ou les deux.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Crée un ensemble de métriques  🌐  Creates a metric set — luz_metric_set","text":"","code":"luz_metric_set(metrics = NULL, train_metrics = NULL, valid_metrics = NULL)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_metric_set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Crée un ensemble de métriques  🌐  Creates a metric set — luz_metric_set","text":"metrics Une liste de luz_metrics à utiliser pour l'entraînement et la validation train_metrics Une liste de luz_metrics à utiliser seulement pour l'entraînement valid_metrics Une liste de luz_metrics à utiliser seulement pour la validation","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Enregistre in objet luz sur disque  🌐  Saves luz objects to disk — luz_save","title":"Enregistre in objet luz sur disque  🌐  Saves luz objects to disk — luz_save","text":"originalAllows saving luz fitted models disk. Objects can loaded back luz_load().  translationAllows saving luz fitted models disk. Objects can loaded back luz_load().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Enregistre in objet luz sur disque  🌐  Saves luz objects to disk — luz_save","text":"","code":"luz_save(obj, path, ...)"},{"path":"https://cregouby.github.io/luz.fr/reference/luz_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enregistre in objet luz sur disque  🌐  Saves luz objects to disk — luz_save","text":"obj Un objet de classe 'luz_module_fitted', résultat de fit.luz_module_generator(). path path file system save object. ... inutilisé","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_save.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Enregistre in objet luz sur disque  🌐  Saves luz objects to disk — luz_save","text":"Les objets sont sauvegardés au format .rds, mais le obj$model est d'abord sérialisé avec torch_save avant cela.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/luz_save.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Enregistre in objet luz sur disque  🌐  Saves luz objects to disk — luz_save","text":"L'objet ctx est sérialisé naivement, c-à-d. que utilise saveRDS()directement pour le sérialiser. Ne comptez pas sur luz_save pour des objet non sérialisables dans le ctx comme des torch_tensors ou des pointeurs externes en général.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/nn_mixup_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Fonction de coût à utiliser avec callbacks_mixup().  🌐  Loss to be used with callbacks_mixup(). — nn_mixup_loss","title":"Fonction de coût à utiliser avec callbacks_mixup().  🌐  Loss to be used with callbacks_mixup(). — nn_mixup_loss","text":"Pendant la phase d'entraînement, calcule la fonction de coût par rapport à deux cibles individuelles, leur alloue chacune un poids et les combine linéairement pour obtenir la perte moyenne du lot. Pour la validation et le test, se réfère au tenseur de perte passé.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/nn_mixup_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Fonction de coût à utiliser avec callbacks_mixup().  🌐  Loss to be used with callbacks_mixup(). — nn_mixup_loss","text":"","code":"nn_mixup_loss(loss)"},{"path":"https://cregouby.github.io/luz.fr/reference/nn_mixup_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fonction de coût à utiliser avec callbacks_mixup().  🌐  Loss to be used with callbacks_mixup(). — nn_mixup_loss","text":"loss Le fonction de coût sous-jacente de nn_module à appeler. Elle doit supporter le champ reduction. Pendant l'entraînement, l'attribut sera modifié en 'none' afin que nous obtenions le coût pour les observations individuelles. Voir par exemple la documentation du champ reduction dans torch::nn_cross_entropy_loss().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/nn_mixup_loss.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Fonction de coût à utiliser avec callbacks_mixup().  🌐  Loss to be used with callbacks_mixup(). — nn_mixup_loss","text":"Doit être utilisé simultanément avec luz_callback_mixup().","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/nnf_mixup.html","id":null,"dir":"Reference","previous_headings":"","what":"Logique de mélange  🌐  Mixup logic — nnf_mixup","title":"Logique de mélange  🌐  Mixup logic — nnf_mixup","text":"La logique sous-jacente à luz_callback_mixup().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/nnf_mixup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Logique de mélange  🌐  Mixup logic — nnf_mixup","text":"","code":"nnf_mixup(x, y, weight)"},{"path":"https://cregouby.github.io/luz.fr/reference/nnf_mixup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logique de mélange  🌐  Mixup logic — nnf_mixup","text":"x un lot des variables d'entrées y un lot des variables cible weight les coefficients de pondération à utiliser avec torch_lerp()","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/nnf_mixup.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Logique de mélange  🌐  Mixup logic — nnf_mixup","text":"Une liste contenant : x, le nouveau lot d'entrées mélangé y, une liste contenant : ys, une liste contenant : y1, la cible originale y1 y2, la cible mélangée y2 weight, les poids de mélange","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/nnf_mixup.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Logique de mélange  🌐  Mixup logic — nnf_mixup","text":"Sur la base des lots d'entrées et de cibles passés en argument, ainsi que des poids de mélange appropriés, la fonction remplace le lot actuel par de nouveaux tenseurs. Le nouveau lot d'entrées est une combinaison linéaire pondérée des éléments du lot d'entrées initial, tandis que le nouveau lot de cibles rassemble les cibles originales, ainsi que les poids de mélange, dans une liste imbriquée.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/nnf_mixup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Logique de mélange  🌐  Mixup logic — nnf_mixup","text":"","code":"if (torch::torch_is_installed()) { batch_x <- torch::torch_randn(c(10, 768)) batch_y <- torch::torch_randn(10) weight <- torch::torch_tensor(rep(0.9, 10))$view(c(10, 1)) nnf_mixup(batch_x, batch_y, weight) } #> Error in nnf_mixup(batch_x, batch_y, weight): impossible de trouver la fonction \"nnf_mixup\""},{"path":"https://cregouby.github.io/luz.fr/reference/predict.luz_module_fitted.html","id":null,"dir":"Reference","previous_headings":"","what":"Crée des prédictions pour un modèle entraîné  🌐  Create predictions for a fitted model — predict.luz_module_fitted","title":"Crée des prédictions pour un modèle entraîné  🌐  Create predictions for a fitted model — predict.luz_module_fitted","text":"Crée des prédictions pour un modèle entraîné","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/predict.luz_module_fitted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Crée des prédictions pour un modèle entraîné  🌐  Create predictions for a fitted model — predict.luz_module_fitted","text":"","code":"# Méthode S3 pour la classe luz_module_fitted predict(   object,   newdata,   ...,   callbacks = list(),   accelerator = NULL,   verbose = NULL,   dataloader_options = NULL )"},{"path":"https://cregouby.github.io/luz.fr/reference/predict.luz_module_fitted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Crée des prédictions pour un modèle entraîné  🌐  Create predictions for a fitted model — predict.luz_module_fitted","text":"object L'objet modèle entraîné retourné par fit.luz_module_generator() newdata (dataloader, dataset, liste ou tableau) renvoyant une liste avec au moins un élément. Les autres éléments ne sont pas utilisés. ... Inutilisé callbacks (liste, optionnel) Une liste d'appels de callback définis avec luz_callback() qui seront appelés pendant la procédure d'entraînement. Les appels de callback luz_callback_metrics(), luz_callback_progress() et luz_callback_train_valid() sont toujours ajoutés par défaut. accelerator (accélérateur, optionnel) Un objet d'accélérateur accelerator() utilisé pour configurer l'emplacement du calcul des composants tels que les nn_modules, les optimiseurs et les lots de données. verbose (booléen, optionnel) La procédure d'entraînement doit-elle émettre des messages vers la console pendant l'entraînement. Par défaut, elle produira des messages si interactive() est TRUE. dataloader_options Options utilisées lors de la création d'un chargeur de donnée. Voir torch::dataloader(). shuffle=TRUE par défaut pour les données d'entraînement et batch_size=32 par défaut. Il produira une erreur si ce n'est pas NULL et que data est déjà un chargeur de donnée.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objets exportés des autres paquets  🌐  Objects exported from other packages — reexports","title":"Objets exportés des autres paquets  🌐  Objects exported from other packages — reexports","text":"Ces objects sont importés d'autres paquets. Suivez les liens suivants pour consulter leur documentation. generics fit","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/set_hparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Définit les hyper-paramètres d'un module  🌐  Set hyper-parameter of a module — set_hparams","title":"Définit les hyper-paramètres d'un module  🌐  Set hyper-parameter of a module — set_hparams","text":"Cette fonction est utilisée pour définir les hyper-paramètres avant d'appeler fit pour les luz_modules.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/set_hparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Définit les hyper-paramètres d'un module  🌐  Set hyper-parameter of a module — set_hparams","text":"","code":"set_hparams(module, ...)"},{"path":"https://cregouby.github.io/luz.fr/reference/set_hparams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Définit les hyper-paramètres d'un module  🌐  Set hyper-parameter of a module — set_hparams","text":"module Un nn_module après son initialisation par setup(). ... Les paramètres définis ici seront utilisés pour initialiser le nn_module, c'est-à-dire qu'ils seront passés tels quels à la méthode initialize du nn_module de base.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/set_hparams.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Définit les hyper-paramètres d'un module  🌐  Set hyper-parameter of a module — set_hparams","text":"Le même module luz","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/set_opt_hparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Définit les hyper-paramètres de l'optimiseur  🌐  Set optimizer hyper-parameters — set_opt_hparams","title":"Définit les hyper-paramètres de l'optimiseur  🌐  Set optimizer hyper-parameters — set_opt_hparams","text":"Cette fonction est utilisée pour définir les hyper-paramètres à l'initialisation de l'optimiseur.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/set_opt_hparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Définit les hyper-paramètres de l'optimiseur  🌐  Set optimizer hyper-parameters — set_opt_hparams","text":"","code":"set_opt_hparams(module, ...)"},{"path":"https://cregouby.github.io/luz.fr/reference/set_opt_hparams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Définit les hyper-paramètres de l'optimiseur  🌐  Set optimizer hyper-parameters — set_opt_hparams","text":"module Un nn_module après son initialisation par setup(). ... Les paramètres passés ici seront utilisés pour initialiser les optimiseurs. Par exemple, si votre optimiseur est optim_adam et vous passez lr=0.1, alors la fonction  optim_adam est appelée avec optim_adam(parameters, lr=0.1) lors de l'entraînement du modèle.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/set_opt_hparams.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Définit les hyper-paramètres de l'optimiseur  🌐  Set optimizer hyper-parameters — set_opt_hparams","text":"même module luz","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/reference/setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialise l'usage d'un nn_module avec luz  🌐  Set's up a nn_module to use with luz — setup","title":"Initialise l'usage d'un nn_module avec luz  🌐  Set's up a nn_module to use with luz — setup","text":"La fonction d'initialiation, utilisée pour définir les attributs et les méthodes importantes pour que le nn_modules fonctionne avec luz.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Initialise l'usage d'un nn_module avec luz  🌐  Set's up a nn_module to use with luz — setup","text":"","code":"setup(module, loss = NULL, optimizer = NULL, metrics = NULL, backward = NULL)"},{"path":"https://cregouby.github.io/luz.fr/reference/setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialise l'usage d'un nn_module avec luz  🌐  Set's up a nn_module to use with luz — setup","text":"module (nn_module) Le nn_module à utiliser. loss (fonction, optionnel) Une fonction avec la signature function(input, target). Elle est uniquement requise si votre  nn_module n'implémente pas une fonction de coût nomée loss. optimizer (optimiseur torch, optionnel) Une fonction avec la signature function(parameters, ...) qui est utilisée pour initialiser un optimiseur à partir des paramètres du modèle. metrics (liste, optionnel) Une liste de métriques à suivre pendant la procédure d'entraînement. Si vous voulez que des métriques soient évaluées uniquement pendant l'entraînement ou la validation, vous pouvez passer un objet luz_metric_set() pour spécifier les métriques utilisées à chaque étape. backward (fonction) Une fonction qui prend des valeurs retournées par la fonction de coût comme paramètres. Elle doit appeler $backward() ou torch::autograd_backward(). En général, vous n'avez pas besoin de définir ce paramètre sauf si vous devez personnaliser comment luz appelle la méthode backward(), par exemple, si vous devez ajouter des arguments supplémentaires à l'appel de la méthode. Notez que cela devient une méthode du nn_module, donc elle peut être utilisée par votre step() personnalisé si vous le redéfinissez.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/setup.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Initialise l'usage d'un nn_module avec luz  🌐  Set's up a nn_module to use with luz — setup","text":"Un module luz qui peut être entraîné avec fit().","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/setup.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Initialise l'usage d'un nn_module avec luz  🌐  Set's up a nn_module to use with luz — setup","text":"Elle s'assure que le module ait tous les ingrédients nécessaires pour être entraîné.","code":""},{"path":"https://cregouby.github.io/luz.fr/reference/setup.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialise l'usage d'un nn_module avec luz  🌐  Set's up a nn_module to use with luz — setup","text":"Elle ajoute également un champ de device actif qui peut être utilisé pour interroger le device courant du module dans les méthodes, comme par exemple self$device. Cela est utile lorsque ctx() n'est pas disponible, par exemple, lorsque vous appelez des méthodes en dehors de luz. Les utilisateurs peuvent personnaliser la valeur par défaut en implémentant une méthode active de device dans le module d'entrée.","code":""},{"path":[]},{"path":"https://cregouby.github.io/luz.fr/news/index.html","id":"luzfr-040","dir":"Changelog","previous_headings":"","what":"luz.fr 0.4.0","title":"luz.fr 0.4.0","text":"Initial function help translation.","code":""},{"path":"https://cregouby.github.io/luz.fr/news/index.html","id":"luzfr-049002","dir":"Changelog","previous_headings":"","what":"luz.fr 0.4.9002","title":"luz.fr 0.4.9002","text":"Vignettes translation pkgdown publication github page. add function reference translation github page","code":""}]
