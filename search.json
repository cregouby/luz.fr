[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 luz.fr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/accelerator.html","id":"exemple","dir":"Articles","previous_headings":"","what":"Exemple","title":"API des accélérateurs","text":"L’API des accélérateurs est mieux expliquée sur un exemple de différence diff du code dans une boucle d’apprentissage torch brut. Avec les modifications de code montrées, vous n’avez plus besoin de déplacer manuellement les données et les paramètres entre périphériques, ce qui rend votre code plus facile à lire et moins sujet aux erreurs. Vous pouvez trouver des informations supplémentaires en utilisant help(accelerator).","code":"library(torch) + library(luz)  + acc <- accelerator() - device <- \"cpu\"  data <- tensor_dataset(   x = torch_randn(100, 10),   y = torch_rand(100, 1) )  dl <- dataloader(data, batch_size = 10)  model <- nn_linear(10, 1) - model$to(device = device) opt <- optim_adam(model$parameters)  + c(model, opt, dl) %<-% acc$prepare(model, opt, dl)  model$train() coro::loop(for (batch in dl) {    opt$zero_grad()  -  preds <- model(batch$x$to(device = device)) +  preds <- model(batch$x) -  loss <- nnf_mse_loss(preds, batch$y$to(device = device)) +  loss <- nnf_mse_loss(preds, batch$y)    loss$backward()   opt$step() })"},{"path":"/articles/checkpoints.html","id":"relancer-des-apprentissages-qui-ont-échoués","dir":"Articles","previous_headings":"","what":"Relancer des apprentissages qui ont échoués","title":"Sauvegarder des instantannés de vos modèle","text":"Si vous avez un long processus d’apprentissage qui peut échouer pour n’importe quelle raison (ordinateur coupé, noeud d’un cluster perdu, etc), recommande d’ajouter luz_callback_autoresume() à votre liste de callbacks. luz_callback_autoresume() sauvegardera automatiquement tout l’état de votre modèle à la fin de chaque époque. Si quelque chose se passe mal pendant l’apprentissage, vous pouvez simplement relancer le même script, sans aucun changement et l’instantanné sera rechargé et l’apprentissage reprendra là où il s’est arrêté. Pour exemple, prennons un jeu de données d’entraînement aléatoire généré et un modèle linéaire pour montrer comment fonctionne autoresume. Voici les données d’entraînement : Et la définition du modèle : Voici comment créer un callbacks qui simule une erreur aléatoire. Ce callbacks lève juste une erreur d’exécution R à la 5ème époque d’apprentissage du modèle. Ccommençons par entraîner en ajoutant le luz_callback_auto_resume(): Pour relancer l’apprentissage du modèle exactement là où il s’est arrêté vous n’avez qu’à relancer la fonction fit() avec le même modèle, les callbacks, etc. : Ainsi, le processus l’apprentissage du modèle continuera exactement là où il s’est arrêté. Les relevés (de métriques et de pertes), optimiseur et état du modèle sont récupérés à partir de l’état précédent pour avoir les résultats complets :","code":"x <- torch_randn(1000, 10) y <- torch_randn(1000, 1) model <- nn_linear %>%   setup(optimizer = optim_sgd, loss = nnf_mse_loss) %>%   set_hparams(in_features = 10, out_features = 1) %>%   set_opt_hparams(lr = 0.01) interrupt <- luz_callback(   \"interrupt\",   failed = FALSE,   on_epoch_end = function() {     if (ctx$epoch == 5 && !self$failed) {       self$failed <- TRUE       stop(\"Error on epoch 5\")     }   } ) autoresume <- luz_callback_auto_resume(path = \"state.pt\") inter <- interrupt()  # Une erreur se produira à la 5ème époque et le modèle sera arrêté. results <- model %>% fit(   list(x, y),   callbacks = list(inter, autoresume),   verbose = FALSE ) #> Error in `FUN()`: #> ! Error while calling callback with class <interrupt/LuzCallback/R6> at #>   on_epoch_end. #> Caused by error in `self[[callback_nm]]()`: #> ! Error on epoch 5 results <- model %>% fit(   list(x, y),   callbacks = list(inter, autoresume),   verbose = FALSE ) plot(results)"},{"path":"/articles/checkpoints.html","id":"sauvegarde-automatique","dir":"Articles","previous_headings":"","what":"Sauvegarde automatique","title":"Sauvegarder des instantannés de vos modèle","text":"Parfois, vous voulez avoir un contrôle plus grand sur la façon dont les sauvegardes sont gérées. Dans ce cas, vous pouvez utiliser luz_callback_model_checkpoint() pour enregistrer des sauvegardes dans un fichier ou un répertoire spécifié. Essayons d’utiliser le même exemple que dans la section précédente : Nous générerons d’abord quelques données. Définissons ensuite notre modèle : Entraînons maintenant le modèle en utilisant luz_callback_model_checkpoint(). Vous pouvez maintenant voir que le répertoire checkpoints contient des fichiers avec des sauvegardes de l’état pour chaque epoch. Par défaut, luz_callback_model_checkpoint enregistrera l’état pour chaque epochs et formattera le nom en y incluant la perte résultante. Cela peut être configuré dans le paramètre path, voir ?luz_callback_model_checkpoint pour plus de détails. Enfin, vous pouvez charger une sauvegarde spécifique dans le modèle entrainé à l’aide de luz_load_checkpoint. Notez que la chargement de la sauvegarde dans un module fitted change les poids du modèle -place. Vous pouvez ensuite commencer à faire des prédictions ou évaluer votre modèle avec les poids tout juste chargés. Si vous voullez démarrer une nouvelle époque d’apprentissage depuis une sauvegarde, vous pouvez utiliser luz_callback_resume_from_checkpoint() . Par défaut, il n’aura enregistré que les poids du modèle dans le fichier de sauvegarde, mais vous pouvez configurer pour restorer aussi les registres, callbacks et états de l’appelant et l’optimiseur. Si le répertoire des sauvegardes est fourni, alors l’apprentissage sera reprie à partir du dernier fichier de sauvegarde renvoyé par fs::dir_ls. Voici comment utiliser ce callbacks :","code":"x <- torch_randn(1000, 10) y <- torch_randn(1000, 1) model <- nn_linear %>%   setup(optimizer = optim_sgd, loss = nnf_mse_loss) %>%   set_hparams(in_features = 10, out_features = 1) %>%   set_opt_hparams(lr = 0.01) checkpoint <- luz_callback_model_checkpoint(   path = \"checkpoints/\",    monitor = \"train_loss\" )  results <- model %>% fit(   list(x, y),   callbacks = list(checkpoint),   verbose = FALSE ) fs::dir_ls(\"checkpoints\") #> checkpoints/epoch-01-train_loss-1.237.pt #> checkpoints/epoch-02-train_loss-1.065.pt #> checkpoints/epoch-03-train_loss-1.026.pt #> checkpoints/epoch-04-train_loss-1.004.pt #> checkpoints/epoch-05-train_loss-1.004.pt #> checkpoints/epoch-06-train_loss-1.005.pt #> checkpoints/epoch-07-train_loss-0.999.pt #> checkpoints/epoch-08-train_loss-0.998.pt #> checkpoints/epoch-09-train_loss-1.001.pt #> checkpoints/epoch-10-train_loss-1.002.pt luz_load_checkpoint(results, fs::dir_ls(\"checkpoints\")[1]) resume <- luz_callback_resume_from_checkpoint(path = \"checkpoints/\") results <- model %>% fit(   list(x, y),   callbacks = list(resume),   verbose = FALSE ) plot(results)"},{"path":"/articles/checkpoints.html","id":"etats-des-callbacks-personnalisés","dir":"Articles","previous_headings":"Sauvegarde automatique","what":"Etats des callbacks personnalisés","title":"Sauvegarder des instantannés de vos modèle","text":"Parfois, les rappels ont également besoin de conserver leurs états internes afin de continuer l’apprentissage exactement à partir là où il s’est arrêté. Dans ce cas, les callbacks peuvent mettre en œuvre les méthodes state_dict() et le load_state_dict() qui sont appelées automatiquement lors des sauvegardes et rechargements. Par exemple, imaginez que vous avez un callbacks qui suit des gradients pour les poids à chaque epoch. Vous voulez utiliser les poids suivis pour analyser plus en profondeur la procédure d’apprentissage. Il pourrait être modifié comme suit: Dans l’exemple ci-dessus, le champ gradients est un état dans le callbacks. Si l’apprentissage échoue pour une raison quelconque, les états seront perdues. Nous pouvons le rendre plus robuste en utilisant les méthodes state_dict() et load_state_dict() comme suit :","code":"cb_weight_grad <- luz_callback(   \"weight_grad\",   gradients = list(),   initialize = function(track_weights) {     self$track_weights   },   on_train_batch_before_step = function() {     gradients[[ctx$epoch]] <- list()     for (w in self$track_weights) {       gradients[[ctx$epoch]][[w]] <- self$model$parameters[[w]]     }   } ) cb_weight_grad <- luz_callback(   \"weight_grad\",   gradients = list(),   initialize = function(track_weights) {     self$track_weights   },   on_train_batch_before_step = function() {     gradients[[ctx$epoch]] <- list()     for (w in self$track_weights) {       gradients[[ctx$epoch]][[w]] <- self$model$parameters[[w]]     }   },   state_dict = function() {     list(gradients = self$gradients)   },   load_state_dict = function(d) {     self$gradients <- d$gradients   } )"},{"path":"/articles/custom_loop.html","id":"optimiseurs-multiples","dir":"Articles","previous_headings":"","what":"Optimiseurs multiples","title":"Boucles personnalisées avec luz","text":"Supposons que nous voulions faire une expérience où nous formons la première couche de connexion complète avec un taux d’apprentissage de 0.1 et la deuxième avec un taux d’apprentissage de 0.01. Nous allons minimiser la même nn_cross_entropy_loss() pour les deux, mais pour la première couche nous voulons ajouter une régularisation L1. Nous pouvons finalement utiliser setup et fit sur ce module, mais nous ne devons plus spécifier les optimiseurs et les fonctions de perte. Maintenant, nous allons re-implementer ce même modèle en utilisant une approche légèrement plus flexible qui consiste à surcharger l’étape d’apprentissage et de validation.","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$fc1 <- nn_linear(100, 50) %>%       l1()     self$fc2 <- nn_linear(50, 10)   },   forward = function(x) {     x %>%        self$fc1() %>%        nnf_relu() %>%        self$fc2()   } ) fitted <- net %>%    setup(metrics = list(luz_metric_accuracy)) %>%    fit(train_dl, epochs = 10, valid_data = test_dl)"},{"path":"/articles/custom_loop.html","id":"étape-complètement-flexible","dir":"Articles","previous_headings":"","what":"Étape complètement flexible","title":"Boucles personnalisées avec luz","text":"Au lieu d’implémenter la méthode loss(), nous pouvons implémenter la méthode step(). Cela permet de modifier en toute flexibilité ce qui se passe lors de l’apprentissage et de la validation pour chaque lot dans le jeu de données. Vous êtes maintenant responsable de mettre à jour les poids en faisant un pas vers les optimiseurs et d’effectuer une propagation de la perte. Les choses importantes à noter ici sont : La méthode step() est utilisée pour l’apprentissage et la validation. Vous devez être prudent car vous ne devez modifier les poids que lorsque vous êtes en apprentissage. Encore une fois, vous pouvez obtenir des informations complètes sur l’objet de contexte avec help(\"ctx\"). ctx$optimizers est une liste nommée contenant chaque optimiseur qui été créé lorsqu’appelait la méthode set_optimizers(). Vous devez suivre les pertes en cours de modification en les enregistrant dans une liste nommée dans ctx$loss. Conformément à la convention, nous utilisons le même nom que l’optimiseur auquel elle se réfère. Une bonne pratique consiste à les déconnecter avant leur sauvegarde pour réduire la consommation de mémoire. Les rappels qui seraient appelés dans la méthode step() par défaut comme on_train_batch_after_pred, on_train_batch_after_loss, etc., ne seront pas automatiquement appelés. Vous pouvez toujours les appeler manuellement en ajoutant ctx$call_callbacks(\"<nom du rappel>)à l'intérieur de votre  étape d'apprentissage. Voir le code pourfit_one_batch()etvalid_one_batch` pour trouver tous les rappels qui ne seront pas appelés. Si vous voulez que les métriques luz fonctionnent avec votre méthode step() personnalisée, vous devez assigner ctx$pred aux prédictions du modèle car les métriques seront toujours appelées avec metric$update(ctx$pred, ctx$target).","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$fc1 <- nn_linear(100, 50)     self$fc1 <- nn_linear(50, 10)   },   forward = function(x) {     x %>%        self$fc1() %>%        nnf_relu() %>%        self$fc2()   },   set_optimizers = function(lr_fc1 = 0.1, lr_fc2 = 0.01) {     list(       opt_fc1 = optim_adam(self$fc1$parameters, lr = lr_fc1),       opt_fc2 = optim_adam(self$fc2$parameters, lr = lr_fc2)     )   },   step = function() {     ctx$loss <- list()     for (opt_name in names(ctx$optimizers)) {            ctx$pred <- ctx$model(ctx$input)       opt <- ctx$optimizers[[opt_name]]       loss <- nnf_cross_entropy(pred, target)              if (opt_name == \"opt_fc1\") {         # nous avons une régularisation L1 dans la couche 1         loss <- nnf_cross_entropy(pred, target) +            torch_norm(self$fc1$weight, p = 1)       }                if (ctx$training) {         opt$zero_grad()         loss$backward()         opt$step()         }              ctx$loss[[opt_name]] <- loss$detach()     }   } )"},{"path":"/articles/custom_loop.html","id":"étapes-suivantes","dir":"Articles","previous_headings":"","what":"Étapes suivantes","title":"Boucles personnalisées avec luz","text":"Dans cet article, vous avez appris à personnaliser l’étape de formation du boucle d’apprentissage en utilisant la fonctionnalité multi-couche de luz. Luz permet également des modifications plus flexibles de la boucle d’apprentissage décrites dans le vignette “Accélérateur” (vignette(\"accelerator\")). Vous devriez maintenant pouvoir suivre les exemples marqués avec les catégories ‘intermédiaire’ et ‘avancé’ dans la galerie des exemples de luz Tous les exemples mentionnés ci-dessus sont disponibles en ligne.","code":""},{"path":"/articles/examples/mnist-autoencoder.html","id":"ensembles-et-chargeurs--","dir":"Articles > Examples","previous_headings":"","what":"Ensembles et chargeurs —————————————————-","title":"Autoencodeur","text":"dir <- “./mnist” # répertoire de mise en cache","code":""},{"path":[]},{"path":"/articles/examples/mnist-autoencoder.html","id":"category-basic","dir":"Articles > Examples","previous_headings":"Modifiez le dataset MNIST afin que la cible soit identique à l’entrée.","what":"category: ‘basic’","title":"Autoencodeur","text":"","code":"# Packages ---------------------------------------------------------------- library(torch) library(torchvision) library(luz)  # Jeu de données et chargeurs de données ----------------------------------------------------  dir <- \"./mnist\" # répertoire de mise en cache  # Modification du jeu de données MNIST afin que la cible soit identique à l'entrée. mnist_dataset2 <- torch::dataset(   inherit = mnist_dataset,   .getitem = function(i) {     output <- super$.getitem(i)     output$y <- output$x     output   } )  train_ds <- mnist_dataset2(   dir,   download = TRUE,   transform = transform_to_tensor )  test_ds <- mnist_dataset2(   dir,   train = FALSE,   transform = transform_to_tensor )  train_dl <- dataloader(train_ds, batch_size = 128, shuffle = TRUE) test_dl <- dataloader(test_ds, batch_size = 128)  # Construction du réseau ---------------------------------------------------  net <- nn_module(   \"Net\",   initialize = function() {     self$encoder <- nn_sequential(       nn_conv2d(1, 6, kernel_size=5),       nn_relu(),       nn_conv2d(6, 16, kernel_size=5),       nn_relu()     )     self$decoder <- nn_sequential(       nn_conv_transpose2d(16, 6, kernel_size = 5),       nn_relu(),       nn_conv_transpose2d(6, 1, kernel_size = 5),       nn_sigmoid()     )   },   forward = function(x) {     x %>%       self$encoder() %>%       self$decoder()   },   predict = function(x) {     self$encoder(x) %>%       torch_flatten(start_dim = 2)   } )  # Entraînement du modèle -------------------------------------------------------------------  fitted <- net %>%   setup(     loss = nn_mse_loss(),     optimizer = optim_adam   ) %>%   fit(train_dl, epochs = 1, valid_data = test_dl)  # Inférence ------------------------------------------------------  preds <- predict(fitted, test_dl)  # Sérialisation ---------------------------------------------------------------  luz_save(fitted, \"mnist-autoencoder.pt\")"},{"path":"/articles/examples/text-generation.html","id":"données","dir":"Articles > Examples","previous_headings":"","what":"Données","title":"Entraîner un modèle linguistique causal à partir de zéro","text":"La première étape est d’implémenter un jeu de données torch qui rassemble des données et les pré-traite pour qu’elles soient au format approprié pour entraîner le modèle. Cela signifie que nous devons : Télécharger les données Former un tokeniseur pour ce jeu de données Être en mesure de produire des séquences de tokens dans le format attendu par le modèle Nous allons utiliser 2 jeux de données disponibles sur le Hub d’Hugging Face. Le premier contient tous les codes sources des paquets R disponibles sur CRAN. Le second contient tous les codes R qui sont disponibles dans les dumps GitHub. Les deux jeux de données sont au format Parquet. Nous allons implémenter une fonction qui télécharge et cache les données, puis renvoie une seule table au format arrow contenant toutes les données. Ensuite, nous implémentons une fonction qui entraîne un tokeniseur sur notre jeu de données. Nous pouvons enfin implémenter le jeu de données torch que nous allons utiliser pour entraîner le modèle. Nous allons utiliser torch::iterable_dataset au lieu de torch::dataset. La principale motivation est que nous ne pouvons pas vraiment savoir le nombre total d’échantillons dans le jeu de données, donc nous pouvons implémenter une méthode .getitem() pour obtenir n’importe quel échantillon arbitraire. Ainsi, nous implémentons la méthode .iter qui retourne un nouvel échantillon à chaque appel. Ce jeu de données est bien trop volumineux pour entraîner le modèle sur tous les documents dans cet exemple. Il est également difficile de prédire combien de temps cela prendra d’arriver à la fin de l’entraînement. Pour simplifier, nous définissons un jeu de données itérable utilisé pour exécuter le jeu de données ci-dessus pendant un nombre fixe d’étapes. Ce n’est pas nécessaire, mais rend l’utilisation de luz plus agréable, car nous pouvons facilement définir combien de tokens nous voulons entraîner notre modèle. Maintenant, nous pouvons définir le modèle que nous allons entraîner. Nous utiliserons une version légère de GPT2. Nous définissons également une méthode generate nous permettant d’échantillonner à partir du modèle donné un contexte initial. Pour faciliter l’inspection de la formation, nous définirons également un callback qui imprime un échantillon du modèle à chaque époque. Nous pouvons maintenant entraîner le modèle. Nous définissons un entraînement du modèle pour un demi-milliard de tokens pendant un total de 100 époques. Ensuite, nous pouvons utiliser le modèle pour générer du texte en fonction d’un prompt avec :","code":"read_dataset <- function(source) {   d <- source |>     hfhub::hub_snapshot(repo_type = \"dataset\", allow_patterns = \"parquet$\") |>     fs::path(\"data/r\") |>     arrow::open_dataset() |>     dplyr::filter(stringr::str_detect(path, \".*\\\\.[rR]$\")) |>     dplyr::select(content) |>     dplyr::mutate(content = arrow::cast(content, arrow::string())) |>     dplyr::filter(!is.na(content)) |>     dplyr::collect() %>%     # le jeu de données contient des caractères utf8 invalides...     # nous devons les supprimer, sinon on obtient une erreur des tokenizers     dplyr::filter(utf8::utf8_valid(content)) }  read_datasets <- function() {   dplyr::bind_rows(     read_dataset(\"dfalbel/cran-packages\"),     read_dataset(\"dfalbel/github-r-repos\")   ) } create_tokenizer <- function(text, vocab_size, special_tokens) {   tok <- tok::tokenizer$new(tok::model_bpe$new())    tok$pre_tokenizer <- tok::pre_tokenizer_byte_level$new(add_prefix_space = FALSE)   tok$decoder <- tok::decoder_byte_level$new()   tok$post_processor <- tok::processor_byte_level$new(trim_offsets = FALSE)    tok$train_from_memory(     text,     tok::trainer_bpe$new(vocab_size = vocab_size, special_tokens = special_tokens)   )   tok }  # code de débogage pour le tokeniseur # data <- read_datasets() # tok <- create_tokenizer(data$content) r_sources_dataset <- torch::iterable_dataset(   \"r_sources_dataset\",   initialize = function(root = \".\", vocab_size = 20000, context_length = 128) {     self$data <- read_datasets()     self$context_length <- context_length     self$index <- sample.int(nrow(self$data))      # nous créons un tokeniseur que si celui-ci n'existe pas déjà, sinon nous le chargeons simplement     tok_path <- file.path(root, glue::glue(\"tokenizer-{vocab_size}.json\"))     if (!file.exists(tok_path)) {       self$tok <- create_tokenizer(         as.character(self$data$content),         vocab_size,         c(\"<fbegin>\", \"<fend>\")       )       fs::dir_create(root)       self$tok$save(tok_path)     } else {       self$tok <- tok::tokenizer$from_file(tok_path)     }   },   .iter = function() {     i <- 1L     sequence <- c()     function() {       while (length(sequence) < (self$context_length + 1) && i <= nrow(self$data)) {         sequence <<- c(           sequence,           self$tok$encode(paste(\"<fbegin>\", as.character(self$data$content[self$index[i]]), \"<fend>\"))$ids         )         i <- i + 1L       }        if (length(sequence) < (self$context_length + 1)) {         return(coro::exhausted())       }        on.exit({         sequence <<- sequence[-seq_len(self$context_length)]       })       list(         input_ids = sequence[seq_len(self$context_length)] + 1L,         labels = sequence[2:(self$context_length + 1)] + 1L       )     }   } )  # code de débogage pour le jeu de données # ds <- r_sources_dataset(\"~/Downloads/\") # it <- ds$.iter() # it() # ds$tok$get_vocab_size() fixed_steps_iterable_dataset <- iterable_dataset(   \"fixed_steps_dataset\",   initialize = function(dataset, steps) {     self$dataset <- dataset     self$steps <- steps   },   .iter = function() {     i <- 1L     iter <- NULL     function() {       if (i > self$steps) {         return(coro::exhausted())       }        i <<- i + 1L        if (is.null(iter) || coro::is_exhausted(data <- iter())) {         iter <<- self$dataset$.iter()         data <- iter()       }        data     }   },   .length = function() {     self$steps   } ) net <- nn_module(   initialize = function() {     self$gpt <- minhub::gpt2(       vocab_size = 20000,       pdrop = 0.1     )   },   forward = function(x) {     self$gpt(x)$transpose(2,3)   },   generate = function(x, temperature = 1, iter = 50, top_k = 10) {     # échantillonne à partir du modèle given un vecteur de contexte.     for (i in seq_len(iter)) {       logits <- self$forward(x)[,,-1]       logits <- logits/temperature       c(prob, ind) %<-% logits$topk(top_k)       logits <- torch_full_like(logits, -Inf)$scatter_(-1, ind, prob)       logits <- nnf_softmax(logits, dim = -1)       id_next <- torch_multinomial(logits, num_samples = 1)       x <- torch_cat(list(x, id_next), dim = 2)     }     x   } )  # code de débogage pour le modèle # ds <- torch::dataloader(r_sources_dataset(\"~/Downloads/\"), batch_size = 32) # batch <- coro::collect(ds, 1)[[1]] # str(batch) # m <- net() # str(m(batch$input_ids)) # échantillonne à partir du modèle en utilisant le contexte. generate <- function(model, tok, context, ...) {   local_no_grad() # désactive les gradients pour l'échantillonnage   x <- tok$encode(context)$ids + 1L   x <- torch_tensor(x)[NULL,]$to(device = model$device)   content <- as.integer(model$generate(x, ...)$cpu())   tok$decode(content - 1L) }  display_cb <- luz_callback(   initialize = function() {},   on_epoch_end = function() {     local_no_grad()     # sample from the model...     context <- \"# creates a linear model\"     text <- generate(ctx$model, dataset$dataset$tok, context, iter = 100)     cli::cli_rule()     cat(text, \"\\n\")     cli::cli_rule()   } ) n_tokens <- 500e6 batch_size <- 16 epochs <- 100 context_length <- 256L  steps <- n_tokens / context_length / epochs dataset <- fixed_steps_iterable_dataset(   r_sources_dataset(context_length = context_length),   steps = steps )  fitted <- net %>%   setup(     optimizer = optim_adam,     loss = nn_cross_entropy_loss()   ) %>%   set_opt_hparams(lr = 3e-4) |>   fit(     dataset,     epochs = epochs,     dataloader_options = list(batch_size = batch_size),     callbacks = list(       luz_callback_lr_scheduler(         torch::lr_one_cycle,         max_lr = 0.1,         epochs = epochs,         steps_per_epoch = steps/batch_size,         call_on = \"on_batch_end\"       ),       luz_callback_gradient_clip(max_norm = 1),       display_cb()     ),     verbose = TRUE   )  luz::luz_save(fitted, \"model.pt\") fitted <- luz::luz_load(\"model.pt\") tok <- tok::tokenizer$from_file(\"tokenizer-20000.json\") context <- \"#' Crée un modèle linéaire linear_model <- function(x, y) { \" text <- generate(fitted$model, tok, context, iter = 100) cat(text)"},{"path":"/articles/get-started.html","id":"entraînement-dun-nn_module","dir":"Articles","previous_headings":"","what":"Entraînement d’un nn_module","title":"Bien démarrer avec luz","text":"Luz tente, autant que possible, de réutiliser les structures existantes de torch. Un modèle en luz est défini de la même manière que vous le définiriez si vous utilisez torch brut. Par exemple, voici la définition d’un CNN feed-forward qui peut être utilisé pour classer les chiffres de l’ensemble de données MNIST: Nous pouvons maintenant entraîner ce modèle dans le train_dl et l’évaluer dans le torch::dataloaders() nomé test_dl avec: Voyons en détail ce qui se passe dans ce bloc de code : La fonction setup vous permet de configurer la fonction de coût (objectif) et l’optimiseur que vous utiliserez pour entraîner votre modèle. En option, vous pouvez passer une liste de métriques qui sont suivies pendant la procédure d’apprentissage. Remarque : la fonction de coût peut être n’importe quelle fonction prenant en entrée input et target et retournant une valeur de tenseur scalaire, et l’optimiseur peut être n’importe quel optimiseur de torch natif ou personnalisé, créé avec la fonction torch::optimizer(). La fonction set_hparams() permet de définir les hyper-paramètres qui doivent être passées à la méthode initialize() du module. Par exemple dans ce cas nous passons num_classes = 10. La fonction set_opt_hparams() vous permet de passer des hyper-paramètres utilisés par la fonction d’optimisation. Par exemple, optim_adam() peut prendre le paramètre lr spécifiant le taux d’apprentissage et nous le spécifions avec lr = 0.003. La méthode fit va prendre les spécifications du modèle fournies par setup() et exécuter le processus d’apprentissage en utilisant les jeux de donnée d’entraînement et de validation spécifiés dans des torch::dataloaders() ainsi que le nombre d’époques. Remarque : nous réutilisons les structures de données de base de torch pour les chargeurs de donnée, au lieu de recréer notre propre fonctionnalité de chargement de données. L ’ objet retourné fitted contient le modèle entraîné ainsi que le registre de métriques et de pertes produites au cours de l’apprentissage. Il peut également être utilisé pour la production de prédictions et l’évaluation du modèle entraîné sur d’autres jeux de données. Au moment du déploiement du calcul, luz utilisera l’accélérateur le plus rapide possible; si un GPU doté de CUDA est disponible, il sera utilisé, sinon le calcul sera affecté sur la CPU. Il déplace également automatiquement les données, les optimisateurs et les modèles vers le périphérique sélectionné afin que vous n’ayez pas besoin de les manipuler manuellement (qui constitue une grande source d’erreurs en général). Pour créer des prédictions à partir du modèle entraîné, vous pouvez utiliser la méthode predict:","code":"net <- nn_module(   \"Net\",   initialize = function(num_class) {     self$conv1 <- nn_conv2d(1, 32, 3, 1)     self$conv2 <- nn_conv2d(32, 64, 3, 1)     self$dropout1 <- nn_dropout2d(0.25)     self$dropout2 <- nn_dropout2d(0.5)     self$fc1 <- nn_linear(9216, 128)     self$fc2 <- nn_linear(128, num_class)   },   forward = function(x) {     x <- self$conv1(x)     x <- nnf_relu(x)     x <- self$conv2(x)     x <- nnf_relu(x)     x <- nnf_max_pool2d(x, 2)     x <- self$dropout1(x)     x <- torch_flatten(x, start_dim = 2)     x <- self$fc1(x)     x <- nnf_relu(x)     x <- self$dropout2(x)     x <- self$fc2(x)     x   } ) fitted <- net %>%   setup(     loss = nn_cross_entropy_loss(),     optimizer = optim_adam,     metrics = list(       luz_metric_accuracy     )   ) %>%   set_hparams(num_class = 10) %>%    set_opt_hparams(lr = 0.003) %>%    fit(train_dl, epochs = 10, valid_data = test_dl) predictions <- predict(fitted, test_dl)"},{"path":"/articles/get-started.html","id":"la-boucle-dentraînement","dir":"Articles","previous_headings":"","what":"La boucle d’entraînement","title":"Bien démarrer avec luz","text":"Maintenant que vous avez une idée générale de la façon d’utiliser la fonction fit, il est important d’avoir un aperçu de ce qui se passe à l’intérieur. Voici ce que fit exécute (en pseudocode). Ce n’est pas détaillé complètement, mais celà devrait vous aider à construire votre intuition:","code":"# -> Initialiser les objets : modèle, optimiseurs. # -> Sélectionner le périphérique d'apprentissage. # -> Déplacer les données, le modèle et les optimiseurs vers le dispositif sélectionné. # -> Lancer l'apprentissage for (epoch in 1:epochs) {   # -> Procédure d'apprentissage   for (batch in train_dl) {     # -> Calculer la méthode `forward` du modèle.     # -> Calculer la perte.     # -> Mettre à jour les poids.     # -> Mettre à jour les métriques et suivre la perte.   }   # -> Procédure de validation   for (batch in valid_dl) {     # -> Calculer la méthode `forward` du modèle.     # -> Calculer la perte.     # -> Mettre à jour les métriques et suivre la perte.   } } # -> Fin de l'apprentissage"},{"path":"/articles/get-started.html","id":"les-métriques","dir":"Articles","previous_headings":"","what":"Les métriques","title":"Bien démarrer avec luz","text":"L’une des parties les plus importantes des projets d’apprentissage automatique est le choix de la métrique d’évaluation. Luz permet de suivre de nombreuses métriques différentes pendant l’apprentissage avec des changements de code minimes. Pour suivre les métriques, il suffit de modifier le paramètre metrics dans la fonction setup: Luz fournit des implémentations de quelques-unes des métriques les plus utilisées. Si une métrique n’est pas disponible, vous pouvez toujours la mettre en place à l’aide de la fonction luz_metric. Pour implémenter une nouvelle métrique luz_metric, il faut définir 3 méthodes : initialize : définit l’état initial de la métrique. Cette fonction est appelée à chaque époque pour les boucles d’entraînement et de validation. update : met à jour l’état interne de la métrique. Cette fonction est appelée à chaque étape d’entraînement et de validation avec les prédictions obtenues par le modèle et les valeurs cibles renvoyées par le chargeur de données. compute : utilise l’état interne pour calculer les valeurs de la métrique. Cette fonction est appelée toutes les fois où il faut obtenir la valeur actuelle de la métrique. Par exemple, elle est appelée à chaque étape d’entraînement pour afficher les informations de progression, mais seulement appelée une fois par époque pour enregistrer sa valeur lorsqu’il n’y pas de barre de progression. Vous pouvez définir un champ optionnel abbrev qui donne à la métrique une abréviation utilisée lors de l’affichage des informations de métrique dans la console ou dans les enregistrements. Si aucune valeur n’est fournie pour abbrev, le nom de classe de la métrique est utilisé. Essayons maintenant de voir l’implémentation de luz_metric_accuracy pour mettre en œuvre une nouvelle métrique : Remarque: Il est préférable que la fonction compute retourne des valeurs R régulières plutôt qu’éventuellement des tenseurs torch. D’autres parties de luz s’attendent à cela et s’y attacheront.","code":"fitted <- net %>%   setup(     ...     metrics = list(       luz_metric_accuracy     )   ) %>%   fit(...) luz_metric_accuracy <- luz_metric(   # Une abréviation à afficher dans les barres de progression ou    # lors de l'affichage des informations de progression   abbrev = \"Acc\",    # Initialisation pour la métrique. Les métriques sont initialisées   # à chaque époque, pour les entraînements et les validations.   initialize = function() {     self$correct <- 0     self$total <- 0   },   # Mise à jour à chaque étape d'entraînement ou de validation.   # La fonction update prend `preds`    # et `target` en paramètres et met à jour l'état interne `self`.   update = function(preds, target) {     pred <- torch::torch_argmax(preds, dim = 2)     self$correct <- self$correct + (pred == target)$       to(dtype = torch::torch_float())$       sum()$       item()     self$total <- self$total + pred$numel()   },   # Utilise l'état interne pour demander la valeur de la métrique.   compute = function() {     self$correct/self$total   } )"},{"path":"/articles/get-started.html","id":"évaluation","dir":"Articles","previous_headings":"","what":"Évaluation","title":"Bien démarrer avec luz","text":"Une fois un modèle entraîné, vous voulez peut-être évaluer sa performance sur un autre jeu de données. Pour cela, luz fournit la fonction ?evaluate qui prend, en entrée, un modèle ajusté et un jeu de données et calcule les métriques attachées au modèle. L’opération evaluate() retourne un objet luz_module_evaluation que vous pouvez interroger pour des métriques à l’aide de la fonction get_metrics() ou simplement imprimer pour voir les résultats. Par exemple :","code":"evaluation <- fitted %>% evaluate(data = valid_dl) metrics <- get_metrics(evaluation) print(evaluation) #> A `luz_module_evaluation` #> -- Results --------------------------------------------------------------------- #> loss: 1.8892 #> mae: 1.0522 #> mse: 1.645 #> rmse: 1.2826"},{"path":"/articles/get-started.html","id":"personnalisation-avec-les-callbacks","dir":"Articles","previous_headings":"","what":"Personnalisation avec les callbacks","title":"Bien démarrer avec luz","text":"Luz fournit différentes façons de personnaliser la boucle d’apprentissage, en fonction du niveau de contrôle dont vous avez besoin pendant qu’elle s’exécute. La façon la plus rapide et la plus « réutilisable » est via les callbacks. Ils permettent de créer des modifications d’apprentissage qui peuvent être utilisées dans de nombreuses situations. La boucle d’apprentissage en luz de nombreux points d’arrêt qui peuvent appeler des fonctions R arbitraires. Cette fonctionnalité vous permet de personnaliser le processus d’apprentissage sans avoir à modifier la logique générale de l’apprentissage. Luz implémente 3 callbacks par défaut qui se produisent dans chaque procédure d’apprentissage : callback train-eval: Bascule le modèle en train() ou eval() selon si la procédure est en cours de d’entraînement ou de validation. callback metrics : évaluer les paramètres au cours du processus d’entraînement et de validation. callback progress : implémente une barre de progression et imprime des informations sur la progression pendant l’apprentissage. Vous pouvez également mettre en place des callbacks personnalisés qui modifient ou agissent spécifiquement pour votre procédure d’apprentissage. Par exemple: Implémentons un callback qui imprime ‘Itération n’ (où n est le numéro d’itération) pour chaque batch dans le jeu de données d’apprentissage et ‘Fini!’ lorsque la fin d’une époque est atteinte. Pour cela, nous utilisons la fonction luz_callback() : luz_callback() prend des fonctions nommées en argument ..., où le nom indique le moment auquel le callback doit être appelé. Par exemple, on_train_batch_end() est appelé pour chaque fin de batch lors du processus d’apprentissage, et on_epoch_end() est appelé à la fin de chaque époque. La valeur retournée par luz_callback() est une fonction qui initie une instance du callback. Les callbacks peuvent avoir besoin de paramètres d’initialisation, comme le nom d’un fichier où vous souhaitez logger les résultats. Dans ce cas, vous pouvez passer par une méthode initialize lors de la définition du callback, et sauvegarder ces paramètres dans l’objet self. Dans l’exemple ci-dessus, le callback un paramètre message qui est imprimé à la fin de chaque épisode. Une fois que le callback est défini, il peut être passé à la fonction fit via le paramètre callbacks : Les callbacks peuvent être appelés à de nombreux endroits de la boucle d’apprentissage, y compris en combinaison les uns avec les autres. Voici un aperçu des endroits possibles pour insérer les callbacks : Chaque étape marquée avec on_* est un point dans le processus d’apprentissage qui est disponible pour les callbacks pour être appelés. L’autre partie importante des callbacks est l’objet ctx (contexte). Voir help(\"ctx\") pour plus de détails. Par défaut, les callbacks sont appelés dans l’ordre dans lequel ils ont été passés à fit (ou predict ou evaluate), mais vous pouvez fournir un attribut weight qui contrôlera l’ordre croissant dans lequel il sera appelé. Par exemple, si un callback weight = 10 et un autre weight = 1, alors le premier est appelé après le second. Les callbacks qui ne spécifient pas d’attribut de poids sont considérés comme ayant un weight = 0. Certains callbacks intégrés dans luz fournissent déjà une valeur de poids. Par exemple, ?luz_callback_early_stopping une valeur de poids de Inf, puisque en général souhaite l’exécuter à la toute fin dans la boucle. Notez que les callbacks peuvent être combinés pour effectuer des opérations complexes sur le processus d’apprentissage. La variable ctx est un objet utilisé dans luz pour partager des informations entre le boucle d’entraînement et les callbacks, les méthodes du modèle et les métriques. La table suivante décrit les informations disponibles par défaut dans ctx. D’autres rappels peuvent potentiellement modifier ces attributs ou en ajouter de nouveaux. Attributs du contexte Les attributs de ctx peuvent être utilisés pour produire le comportement souhaité des callbacks. Vous pouvez trouver de plus amples informations sur l’objet de contexte à l’aide de help(\"ctx\"). Dans notre exemple, nous utilisons l’attribut ctx$iter pour imprimer le numéro d’itération pour chaque lot d’apprentissage.","code":"print_callback <- luz_callback(   name = \"print_callback\",   initialize = function(message) {     self$message <- message   },   on_train_batch_end = function() {     cat(\"Itération \", ctx$iter, \"\\n\")   },   on_epoch_end = function() {     cat(self$message, \"\\n\")   } ) fitted <- net %>%   setup(...) %>%   fit(..., callbacks = list(     print_callback(message = \"Fini!\")   )) Début de boucle d'ajustement    - on_fit_begin   Début de l'époque      - on_epoch_begin     Début de l'apprentissage        - on_train_begin       Début de la boucle de batch          - on_train_batch_begin           Début du pas d'apprentissage par défaut             - on_train_batch_after_pred             - on_train_batch_after_loss             - on_train_batch_before_backward             - on_train_batch_before_step             - on_train_batch_after_step           Fin du pas d'apprentissage par défaut :          - on_train_batch_end       Fin de la boucle de batch        - on_train_end     Fin de l'apprentissage     Début de la validation        - on_valid_begin       Début de la boucle de batch          - on_valid_batch_begin           Début du pas de validation par défaut             - on_valid_batch_after_pred             - on_valid_batch_after_loss           Fin du pas de validation par défaut          - on_valid_batch_end       Fin de la boucle de batch        - on_valid_end     Fin de la validation       - on_epoch_end   Fin de l'époque    - on_fit_end Fin de l'ajustement"},{"path":"/articles/get-started.html","id":"étapes-suivantes","dir":"Articles","previous_headings":"","what":"Étapes suivantes","title":"Bien démarrer avec luz","text":"Dans cet article, vous avez appris à entraîner votre premier modèle en utilisant luz et les bases de la personnalisation en utilisant à la fois des métriques personnalisées et des callbacks. Luz permet également des modifications plus flexibles du processus d’apprentissage décrites dans vignette(\"custom-loop\"). Vous devriez maintenant être en mesure de suivre les exemples marqués avec la catégorie ‘basique’ dans la galerie d’exemples.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Auteur·rice·s","title":"Auteur·rice·s et Citation","text":"Christophe Regouby. Auteur·rice, mainteneur·se, titulaire des droits d'auteur.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Auteur·rice·s et Citation","text":"Regouby C (2024). luz.fr: Une interface de programmation de haut-niveau pour 'torch'. R package version 0.4.0.","code":"@Manual{,   title = {luz.fr: Une interface de programmation de haut-niveau pour 'torch'},   author = {Christophe Regouby},   year = {2024},   note = {R package version 0.4.0}, }"},{"path":"/index.html","id":"luzfr-","dir":"","previous_headings":"","what":"Une interface de programmation de haut-niveau pour torch","title":"Une interface de programmation de haut-niveau pour torch","text":"Le paquet d’internationalisation de {luz} en français (fr_FR)","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Une interface de programmation de haut-niveau pour torch","text":"Vous pouvez installer la version de development de {luz.fr} depuis GitHub via:","code":"# install.packages(\"devtools\") devtools::install_github(\"eliocamp/rhelpi18n\") devtools::install_github(\"cregouby/luz.fr\")"},{"path":"/index.html","id":"exemple","dir":"","previous_headings":"","what":"Exemple","title":"Une interface de programmation de haut-niveau pour torch","text":"Voici comment utiliser {luz} avec l’aide en français :","code":"# configure la session en langue française Sys.setenv(LANGUAGE = \"fr\")  # charge la librairie d'aide de luz en traduction française et {luz} library(luz.fr) library(luz)  # consulte l'aide normalement ??lr_finder"},{"path":"/reference/accelerator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an accelerator — accelerator","title":"Create an accelerator — accelerator","text":"Create accelerator","code":""},{"path":"/reference/accelerator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Create an accelerator — accelerator","text":"","code":"accelerator(   device_placement = TRUE,   cpu = FALSE,   cuda_index = torch::cuda_current_device() )"},{"path":"/reference/accelerator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an accelerator — accelerator","text":"device_placement (logical) whether accelerator object handle device placement. Default: TRUE cpu (logical) whether training procedure run CPU. cuda_index (integer) index CUDA device use multiple GPUs available. Default: result torch::cuda_current_device().","code":""},{"path":"/reference/as_dataloader.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a dataloader from its input — as_dataloader","title":"Creates a dataloader from its input — as_dataloader","text":"as_dataloader used internally luz convert input data valid_data passed fit.luz_module_generator() torch::dataloader","code":""},{"path":"/reference/as_dataloader.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Creates a dataloader from its input — as_dataloader","text":"","code":"as_dataloader(x, ...)  # Méthode S3 pour la classe dataset as_dataloader(x, ..., batch_size = 32)  # Méthode S3 pour la classe iterable_dataset as_dataloader(x, ..., batch_size = 32)  # Méthode S3 pour la classe list as_dataloader(x, ...)  # Méthode S3 pour la classe dataloader as_dataloader(x, ...)  # Méthode S3 pour la classe matrix as_dataloader(x, ...)  # Méthode S3 pour la classe numeric as_dataloader(x, ...)  # Méthode S3 pour la classe array as_dataloader(x, ...)  # Méthode S3 pour la classe torch_tensor as_dataloader(x, ...)"},{"path":"/reference/as_dataloader.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a dataloader from its input — as_dataloader","text":"x input object. ... Passed torch::dataloader(). batch_size (int, optional): many samples per batch load (default: 1).","code":""},{"path":"/reference/as_dataloader.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Creates a dataloader from its input — as_dataloader","text":"as_dataloader methods sensible defaults batch_size, parallel workers, etc. allows users quickly experiment fit.luz_module_generator() requiring create torch::dataset torch::dataloader simple experiments.","code":""},{"path":"/reference/as_dataloader.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Creates a dataloader from its input — as_dataloader","text":"as_dataloader(dataset): Converts torch::dataset() torch::dataloader(). as_dataloader(iterable_dataset): Converts torch::iterable_dataset() torch::dataloader() as_dataloader(list): Converts list tensors arrays size first dimension  torch::dataloader() as_dataloader(dataloader): Returns dataloader as_dataloader(matrix): Converts matrix dataloader as_dataloader(numeric): Converts numeric vector dataloader as_dataloader(array): Converts array dataloader as_dataloader(torch_tensor): Converts tensor dataloader","code":""},{"path":"/reference/as_dataloader.html","id":"overriding","dir":"Reference","previous_headings":"","what":"Overriding","title":"Creates a dataloader from its input — as_dataloader","text":"can implement as_dataloader S3 method want data structure automatically supported luz's fit.luz_module_generator(). method must satisfy following conditions: method return torch::dataloader(). required argument x. good default arguments. better avoid implementing as_dataloader methods common S3 classes like data.frames. case, better assign different class inputs implement as_dataloader .","code":""},{"path":"/reference/context.html","id":null,"dir":"Reference","previous_headings":"","what":"Context object — context","title":"Context object — context","text":"Context object storing information model training context. See also ctx.","code":""},{"path":"/reference/context.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Context object — context","text":"buffers list buffers callbacks can use write temporary information ctx.","code":""},{"path":"/reference/context.html","id":"active-bindings","dir":"Reference","previous_headings":"","what":"Active bindings","title":"Context object — context","text":"records stores information values logged self$log. device allows querying current accelerator device callbacks list callbacks called. iter current iteration batch current batch data. list input data targets. input shortcut ctx$batch[[1]] target shortcut ctx$batch[[2]] min_epochs minimum number epochs model run . max_epochs maximum number epochs model run. hparams list hyperparameters used initialize ctx$model. opt_hparams list hyperparameters used initialize ctx$optimizers. train_data dataloader used training model valid_data dataloader using model validation accelerator accelerator() used move data, model etc correct device. optimizers named list optimizers used model training. verbose bool wether process verbose mode . handlers List error handlers can used. See rlang::try_fetch() info. epoch_handlers List error handlers can used. See rlang::try_fetch() info. training bool indicating model training validation mode. model model trained. pred Last predicted values. opt Current optimizer. opt_name Current optimizer name. data Current dataloader use. loss_fn Loss function used train model loss Last computed loss values. Detached graph. loss_grad Last computed loss value, detached, can additional tranformation. epoch Current epoch. metrics List metrics tracked process. step_opt Defines step called optimizer. must function taking optimizer argument.","code":""},{"path":[]},{"path":"/reference/context.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Context object — context","text":"context$new() context$log() context$log_metric() context$get_log() context$get_metrics() context$get_metric() context$get_formatted_metrics() context$get_metrics_df() context$set_verbose() context$clean() context$call_callbacks() context$state_dict() context$unsafe_set_records() context$clone()","code":""},{"path":"/reference/context.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Context object — context","text":"Initializes context object minimal necessary information.","code":""},{"path":"/reference/context.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$new(verbose, accelerator, callbacks, training)"},{"path":"/reference/context.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"verbose Whether context verbose mode . accelerator luz accelerator() configures device placement others. callbacks list callbacks used model. See luz_callback(). training boolean indicates context training mode .","code":""},{"path":"/reference/context.html","id":"method-log-","dir":"Reference","previous_headings":"","what":"Method log()","title":"Context object — context","text":"Allows logging arbitrary information ctx.","code":""},{"path":"/reference/context.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$log(what, set, value, index = NULL, append = TRUE)"},{"path":"/reference/context.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"(string) logging. set (string) Usually 'train' 'valid' indicating set want log . can arbitrary info. value Arbitrary value log. index Index value logged. NULL value added end list, otherwise index used. append TRUE value corresponding index already exists, value appended current value. FALSE value overwritten favor new value.","code":""},{"path":"/reference/context.html","id":"method-log-metric-","dir":"Reference","previous_headings":"","what":"Method log_metric()","title":"Context object — context","text":"Log metric name value. Metric values indexed epoch.","code":""},{"path":"/reference/context.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$log_metric(name, value)"},{"path":"/reference/context.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"name name metric value Arbitrary value log.","code":""},{"path":"/reference/context.html","id":"method-get-log-","dir":"Reference","previous_headings":"","what":"Method get_log()","title":"Context object — context","text":"Get specific value log.","code":""},{"path":"/reference/context.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$get_log(what, set, index = NULL)"},{"path":"/reference/context.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"(string) logging. set (string) Usually 'train' 'valid' indicating set want log . can arbitrary info. index Index value logged. NULL value added end list, otherwise index used.","code":""},{"path":"/reference/context.html","id":"method-get-metrics-","dir":"Reference","previous_headings":"","what":"Method get_metrics()","title":"Context object — context","text":"Get metric given epoch set.","code":""},{"path":"/reference/context.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$get_metrics(set, epoch = NULL)"},{"path":"/reference/context.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"set (string) Usually 'train' 'valid' indicating set want log . can arbitrary info. epoch epoch want extract metrics .","code":""},{"path":"/reference/context.html","id":"method-get-metric-","dir":"Reference","previous_headings":"","what":"Method get_metric()","title":"Context object — context","text":"Get value metric given name, epoch set.","code":""},{"path":"/reference/context.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$get_metric(name, set, epoch = NULL)"},{"path":"/reference/context.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"name name metric set (string) Usually 'train' 'valid' indicating set want log . can arbitrary info. epoch epoch want extract metrics .","code":""},{"path":"/reference/context.html","id":"method-get-formatted-metrics-","dir":"Reference","previous_headings":"","what":"Method get_formatted_metrics()","title":"Context object — context","text":"Get formatted metrics values","code":""},{"path":"/reference/context.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$get_formatted_metrics(set, epoch = NULL)"},{"path":"/reference/context.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"set (string) Usually 'train' 'valid' indicating set want log . can arbitrary info. epoch epoch want extract metrics .","code":""},{"path":"/reference/context.html","id":"method-get-metrics-df-","dir":"Reference","previous_headings":"","what":"Method get_metrics_df()","title":"Context object — context","text":"Get data.frame containing metrics.","code":""},{"path":"/reference/context.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$get_metrics_df()"},{"path":"/reference/context.html","id":"method-set-verbose-","dir":"Reference","previous_headings":"","what":"Method set_verbose()","title":"Context object — context","text":"Allows setting verbose attribute.","code":""},{"path":"/reference/context.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$set_verbose(verbose = NULL)"},{"path":"/reference/context.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"verbose boolean. TRUE verbose mode used. FALSE non verbose. NULL use result interactive().","code":""},{"path":"/reference/context.html","id":"method-clean-","dir":"Reference","previous_headings":"","what":"Method clean()","title":"Context object — context","text":"Removes unnecessary information context object.","code":""},{"path":"/reference/context.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$clean()"},{"path":"/reference/context.html","id":"method-call-callbacks-","dir":"Reference","previous_headings":"","what":"Method call_callbacks()","title":"Context object — context","text":"Call selected callbacks. name callback types call, eg 'on_epoch_begin'.","code":""},{"path":"/reference/context.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$call_callbacks(name)"},{"path":"/reference/context.html","id":"arguments-8","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"name name metric","code":""},{"path":"/reference/context.html","id":"method-state-dict-","dir":"Reference","previous_headings":"","what":"Method state_dict()","title":"Context object — context","text":"Returns list containing minimal information context. Used create returned values.","code":""},{"path":"/reference/context.html","id":"usage-11","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$state_dict()"},{"path":"/reference/context.html","id":"method-unsafe-set-records-","dir":"Reference","previous_headings":"","what":"Method unsafe_set_records()","title":"Context object — context","text":"sure know ?","code":""},{"path":"/reference/context.html","id":"usage-12","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$unsafe_set_records(records)"},{"path":"/reference/context.html","id":"arguments-9","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"records New set records set.","code":""},{"path":"/reference/context.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Context object — context","text":"objects class cloneable method.","code":""},{"path":"/reference/context.html","id":"usage-13","dir":"Reference","previous_headings":"","what":"Usage","title":"Context object — context","text":"","code":"context$clone(deep = FALSE)"},{"path":"/reference/context.html","id":"arguments-10","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context object — context","text":"deep Whether make deep clone.","code":""},{"path":"/reference/ctx.html","id":null,"dir":"Reference","previous_headings":"","what":"Context object — ctx","title":"Context object — ctx","text":"Context objects used luz share information model methods, metrics callbacks.","code":""},{"path":"/reference/ctx.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Context object — ctx","text":"ctx object used luz share information training loop callbacks, model methods, metrics. table describes information available ctx default. callbacks potentially modify attributes add new ones. Context attributes","code":""},{"path":[]},{"path":"/reference/evaluate.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluates a fitted model on a dataset — evaluate","title":"Evaluates a fitted model on a dataset — evaluate","text":"Evaluates fitted model dataset","code":""},{"path":"/reference/evaluate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Evaluates a fitted model on a dataset — evaluate","text":"","code":"evaluate(   object,   data,   ...,   metrics = NULL,   callbacks = list(),   accelerator = NULL,   verbose = NULL,   dataloader_options = NULL )"},{"path":"/reference/evaluate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates a fitted model on a dataset — evaluate","text":"object fitted model evaluate. data (dataloader, dataset list) dataloader created torch::dataloader() used training model, dataset created torch::dataset() list. Dataloaders datasets must return list 2 items. first item used input module second used target loss function. ... Currently unused. metrics list luz metrics tracked evaluation. NULL (default) metrics used training tracked. callbacks (list, optional) list callbacks defined luz_callback() called training procedure. callbacks luz_callback_metrics(), luz_callback_progress() luz_callback_train_valid() always added default. accelerator (accelerator, optional) optional accelerator() object used configure device placement components like nn_modules, optimizers batches data. verbose (logical, optional) optional boolean value indicating fitting procedure emit output console training. default, produce output interactive() TRUE, otherwise print console. dataloader_options Options used creating dataloader. See torch::dataloader(). shuffle=TRUE default training data batch_size=32 default. error NULL data already dataloader.","code":""},{"path":"/reference/evaluate.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Evaluates a fitted model on a dataset — evaluate","text":"model trained might want evaluate performance different dataset. reason, luz provides ?evaluate function takes fitted model dataset computes metrics attached model. Evaluate returns luz_module_evaluation object can query metrics using get_metrics function simply print see results. example:","code":"evaluation <- fitted %>% evaluate(data = valid_dl) metrics <- get_metrics(evaluation) print(evaluation) ## A `luz_module_evaluation` ## -- Results --------------------------------------------------------------------- ## loss: 1.5146 ## mae: 1.0251 ## mse: 1.5159 ## rmse: 1.2312"},{"path":[]},{"path":"/reference/fit.luz_module_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a nn_module — fit.luz_module_generator","title":"Fit a nn_module — fit.luz_module_generator","text":"Fit nn_module","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Fit a nn_module — fit.luz_module_generator","text":"","code":"# Méthode S3 pour la classe luz_module_generator fit(   object,   data,   epochs = 10,   callbacks = NULL,   valid_data = NULL,   accelerator = NULL,   verbose = NULL,   ...,   dataloader_options = NULL )"},{"path":"/reference/fit.luz_module_generator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a nn_module — fit.luz_module_generator","text":"object nn_module setup(). data (dataloader, dataset list) dataloader created torch::dataloader() used training model, dataset created torch::dataset() list. Dataloaders datasets must return list 2 items. first item used input module second used target loss function. epochs (int) maximum number epochs training model. single value provided, taken max_epochs min_epochs set 0. vector two numbers provided, first value min_epochs second value max_epochs. minimum maximum number epochs included context object ctx$min_epochs ctx$max_epochs, respectively. callbacks (list, optional) list callbacks defined luz_callback() called training procedure. callbacks luz_callback_metrics(), luz_callback_progress() luz_callback_train_valid() always added default. valid_data (dataloader, dataset, list scalar value; optional) dataloader created torch::dataloader() dataset created torch::dataset() used validation procedure. must return list (input, target). data torch dataset list, can also supply numeric value 0 1 - case random sample size corresponding proportion data used validation. accelerator (accelerator, optional) optional accelerator() object used configure device placement components like nn_modules, optimizers batches data. verbose (logical, optional) optional boolean value indicating fitting procedure emit output console training. default, produce output interactive() TRUE, otherwise print console. ... Currently unused. dataloader_options Options used creating dataloader. See torch::dataloader(). shuffle=TRUE default training data batch_size=32 default. error NULL data already dataloader.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Fit a nn_module — fit.luz_module_generator","text":"fitted object can saved luz_save() can printed print() plotted plot().","code":""},{"path":[]},{"path":"/reference/get_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Get metrics from the object — get_metrics","title":"Get metrics from the object — get_metrics","text":"Get metrics object","code":""},{"path":"/reference/get_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Get metrics from the object — get_metrics","text":"","code":"get_metrics(object, ...)  # Méthode S3 pour la classe luz_module_fitted get_metrics(object, ...)"},{"path":"/reference/get_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get metrics from the object — get_metrics","text":"object object query metrics. ... Currently unused.","code":""},{"path":"/reference/get_metrics.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Get metrics from the object — get_metrics","text":"data.frame containing metric values.","code":""},{"path":"/reference/get_metrics.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Get metrics from the object — get_metrics","text":"get_metrics(luz_module_fitted): Extract metrics luz fitted model.","code":""},{"path":"/reference/lr_finder.html","id":null,"dir":"Reference","previous_headings":"","what":"Learning Rate Finder — lr_finder","title":"Learning Rate Finder — lr_finder","text":"Learning Rate Finder","code":""},{"path":"/reference/lr_finder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Learning Rate Finder — lr_finder","text":"","code":"lr_finder(   object,   data,   steps = 100,   start_lr = 1e-07,   end_lr = 0.1,   log_spaced_intervals = TRUE,   ...,   verbose = NULL )"},{"path":"/reference/lr_finder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Learning Rate Finder — lr_finder","text":"object nn_module setup(). data (dataloader) dataloader created torch::dataloader()  used learning rate finding. steps (integer) number steps iterate learning rate finder. Default: 100. start_lr (float) smallest learning rate. Default: 1e-7. end_lr (float) highest learning rate. Default: 1e-1. log_spaced_intervals (logical) Whether divide range start_lr end_lr log-spaced intervals (alternative: uniform intervals). Default: TRUE ... arguments passed fit. verbose Wether show progress bar process.","code":""},{"path":"/reference/lr_finder.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Learning Rate Finder — lr_finder","text":"dataframe two columns: learning rate loss","code":""},{"path":"/reference/lr_finder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Learning Rate Finder — lr_finder","text":"","code":"if (torch::torch_is_installed()) { library(torch) ds <- torch::tensor_dataset(x = torch_randn(100, 10), y = torch_randn(100, 1)) dl <- torch::dataloader(ds, batch_size = 32) model <- torch::nn_linear model <- model %>% setup(   loss = torch::nn_mse_loss(),   optimizer = torch::optim_adam ) %>%   set_hparams(in_features = 10, out_features = 1) records <- lr_finder(model, dl, verbose = FALSE) plot(records) }"},{"path":"/reference/luz_callback.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new callback — luz_callback","title":"Create a new callback — luz_callback","text":"Create new callback","code":""},{"path":"/reference/luz_callback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Create a new callback — luz_callback","text":"","code":"luz_callback(   name = NULL,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame(),   inherit = NULL )"},{"path":"/reference/luz_callback.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new callback — luz_callback","text":"name name callback ... Public methods callback. name methods used know called. See details section. private optional list private members, can functions non-functions. active optional list active binding functions. parent_env environment use parent newly-created objects. inherit R6ClassGenerator object inherit ; words, superclass. captured unevaluated expression evaluated parent_env time object instantiated.","code":""},{"path":"/reference/luz_callback.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Create a new callback — luz_callback","text":"luz_callback can passed fit.luz_module_generator().","code":""},{"path":"/reference/luz_callback.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Create a new callback — luz_callback","text":"Let’s implement callback prints ‘Iteration n’ (n iteration number) every batch training set ‘Done’ epoch finished. task use luz_callback function:   luz_callback() takes named functions ... arguments, name indicates moment callback called. instance on_train_batch_end() called every batch end training procedure, on_epoch_end() called end every epoch. returned value luz_callback() function initializes instance callback. Callbacks can initialization parameters, like name file want log results. case, can pass initialize method creating callback definition, save parameters self object. example, callback message parameter printed end epoch. callback defined can passed fit function via callbacks parameter:   Callbacks can called many different positions training loop, including combinations . ’s overview possible callback breakpoints:   Every step marked on_* point training procedure available callbacks called. important part callbacks ctx (context) object. See help(\"ctx\") details. default, callbacks called order passed fit (predict evaluate), can provide weight attribute control order called. example, one callback weight = 10 another weight = 1, first one called second one. Callbacks don’t specify weight attribute considered weight = 0. built-callbacks luz already provide weight value. example, ?luz_callback_early_stopping weight Inf, since general want run last thing loop.","code":"print_callback <- luz_callback(   name = \"print_callback\",   initialize = function(message) {     self$message <- message   },   on_train_batch_end = function() {     cat(\"Iteration \", ctx$iter, \"\\n\")   },   on_epoch_end = function() {     cat(self$message, \"\\n\")   } ) fitted <- net %>%   setup(...) %>%   fit(..., callbacks = list(     print_callback(message = \"Done!\")   )) Start Fit    - on_fit_begin   Start Epoch Loop      - on_epoch_begin     Start Train        - on_train_begin       Start Batch Loop          - on_train_batch_begin           Start Default Training Step             - on_train_batch_after_pred             - on_train_batch_after_loss             - on_train_batch_before_backward             - on_train_batch_before_step             - on_train_batch_after_step           End Default Training Step:          - on_train_batch_end       End Batch Loop        - on_train_end     End Train     Start Valid        - on_valid_begin       Start Batch Loop          - on_valid_batch_begin           Start Default Validation Step             - on_valid_batch_after_pred             - on_valid_batch_after_loss           End Default Validation Step          - on_valid_batch_end       End Batch Loop        - on_valid_end     End Valid       - on_epoch_end   End Epoch Loop    - on_fit_end End Fit"},{"path":"/reference/luz_callback.html","id":"prediction-callbacks","dir":"Reference","previous_headings":"","what":"Prediction callbacks","title":"Create a new callback — luz_callback","text":"can also use callbacks using predict(). case supported callback methods detailed :","code":"Start predict  - on_predict_begin  Start prediction loop   - on_predict_batch_begin   - on_predict_batch_end  End prediction loop  - on_predict_end End predict"},{"path":"/reference/luz_callback.html","id":"evaluate-callbacks","dir":"Reference","previous_headings":"","what":"Evaluate callbacks","title":"Create a new callback — luz_callback","text":"Callbacks can also used evaluate(), case, callbacks used equivalent validation loop using fit():","code":"Start Valid  - on_valid_begin  Start Batch Loop   - on_valid_batch_begin   Start Default Validation Step    - on_valid_batch_after_pred    - on_valid_batch_after_loss   End Default Validation Step   - on_valid_batch_end  End Batch Loop  - on_valid_end End Valid"},{"path":[]},{"path":"/reference/luz_callback.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Create a new callback — luz_callback","text":"","code":"print_callback <- luz_callback(  name = \"print_callback\",  on_train_batch_end = function() {    cat(\"Iteration \", ctx$iter, \"\\n\")  },  on_epoch_end = function() {    cat(\"Done!\\n\")  } )"},{"path":"/reference/luz_callback_auto_resume.html","id":null,"dir":"Reference","previous_headings":"","what":"Resume training callback — luz_callback_auto_resume","title":"Resume training callback — luz_callback_auto_resume","text":"callback allows resume training model.","code":""},{"path":"/reference/luz_callback_auto_resume.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Resume training callback — luz_callback_auto_resume","text":"","code":"luz_callback_auto_resume(path = \"./state.pt\")"},{"path":"/reference/luz_callback_auto_resume.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resume training callback — luz_callback_auto_resume","text":"path Path save state files model.","code":""},{"path":"/reference/luz_callback_auto_resume.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Resume training callback — luz_callback_auto_resume","text":"using , model weights, optimizer state serialized end epoch. something fails training simply re-running script restart model training epoch right last epoch serialized.","code":""},{"path":"/reference/luz_callback_auto_resume.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Resume training callback — luz_callback_auto_resume","text":"general want add callback last callbacks list, way, serialized state likely contain possible changes callbacks made 'on_epoch_end'. default weight attribute callback Inf. Read checkpointing article pkgdown website information.","code":""},{"path":"/reference/luz_callback_auto_resume.html","id":"customizing-serialization","dir":"Reference","previous_headings":"","what":"Customizing serialization","title":"Resume training callback — luz_callback_auto_resume","text":"default model, optimizer state records serialized. Callbacks can used customize serialization implementing state_dict() load_state_dict() methods. methods implemented, state_dict() called end epoch load_state_dict() called model resumed.","code":""},{"path":[]},{"path":"/reference/luz_callback_auto_resume.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Resume training callback — luz_callback_auto_resume","text":"","code":"if (torch::torch_is_installed()) { library(torch) library(luz)  x <- torch_randn(1000, 10) y <- torch_randn(1000, 1)  model <- nn_linear %>%   setup(optimizer = optim_sgd, loss = nnf_mse_loss) %>%   set_hparams(in_features = 10, out_features = 1) %>%   set_opt_hparams(lr = 0.01)   # simulate a failure in the middle of epoch 5 happening only once. callback_stop <- luz_callback(   \"interrupt\",   failed = FALSE,   on_epoch_end = function() {     if (ctx$epoch == 5 && !self$failed) {       self$failed <- TRUE       stop(\"Error on epoch 5\")     }   } )  path <- tempfile() autoresume <- luz_callback_auto_resume(path = path) interrupt <- callback_stop()  # try once and the model fails try({   results <- model %>% fit(     list(x, y),     callbacks = list(autoresume, interrupt),     verbose = FALSE   ) })  # model resumes and completes results <- model %>% fit(   list(x, y),   callbacks = list(autoresume, interrupt),   verbose = FALSE )  get_metrics(results)  } #> Error in FUN(X[[i]], ...) :  #>   Error while calling callback with class <interrupt/LuzCallback/R6> at #> on_epoch_end. #> Caused by error in `self[[callback_nm]]()`: #> ! Error on epoch 5 #>      set metric epoch     value #> 1  train   loss     1 1.1759156 #> 2  train   loss     2 1.0254978 #> 3  train   loss     3 0.9808912 #> 4  train   loss     4 0.9642012 #> 5  train   loss     5 0.9649528 #> 6  train   loss     6 0.9656119 #> 7  train   loss     7 0.9528627 #> 8  train   loss     8 0.9662954 #> 9  train   loss     9 0.9660462 #> 10 train   loss    10 0.9588689"},{"path":"/reference/luz_callback_csv_logger.html","id":null,"dir":"Reference","previous_headings":"","what":"CSV logger callback — luz_callback_csv_logger","title":"CSV logger callback — luz_callback_csv_logger","text":"Logs metrics obtained training file disk. file 1 line epoch/validation.","code":""},{"path":"/reference/luz_callback_csv_logger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"CSV logger callback — luz_callback_csv_logger","text":"","code":"luz_callback_csv_logger(path)"},{"path":"/reference/luz_callback_csv_logger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CSV logger callback — luz_callback_csv_logger","text":"path path file disk.","code":""},{"path":[]},{"path":"/reference/luz_callback_early_stopping.html","id":null,"dir":"Reference","previous_headings":"","what":"Early stopping callback — luz_callback_early_stopping","title":"Early stopping callback — luz_callback_early_stopping","text":"Stops training monitored metric stops improving","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Early stopping callback — luz_callback_early_stopping","text":"","code":"luz_callback_early_stopping(   monitor = \"valid_loss\",   min_delta = 0,   patience = 0,   mode = \"min\",   baseline = NULL )"},{"path":"/reference/luz_callback_early_stopping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Early stopping callback — luz_callback_early_stopping","text":"monitor string format <set>_<metric> <set> can 'train' 'valid' <metric> can abbreviation metric tracking training. metric name case insensitive. min_delta Minimum improvement reset patience counter. patience Number epochs without improving stoping training. mode Specifies direction considered improvement. default 'min' used. Can also 'max' (higher better) 'zero' (closer zero better). baseline initial value used best seen value begining. Model stopm training better baseline value found first patience epochs.","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Early stopping callback — luz_callback_early_stopping","text":"luz_callback early stopping.","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Early stopping callback — luz_callback_early_stopping","text":"callback adds on_early_stopping callback can used call callbacks soon model stops training. verbose=TRUE fit.luz_module_generator() message printed early stopping.","code":""},{"path":[]},{"path":"/reference/luz_callback_early_stopping.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Early stopping callback — luz_callback_early_stopping","text":"","code":"cb <- luz_callback_early_stopping()"},{"path":"/reference/luz_callback_gradient_clip.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient clipping callback — luz_callback_gradient_clip","title":"Gradient clipping callback — luz_callback_gradient_clip","text":"adding GradientClip callback, gradient norm_type (default:2) norm clipped max_norm (default:1) using torch::nn_utils_clip_grad_norm_(), can avoid loss divergence.","code":""},{"path":"/reference/luz_callback_gradient_clip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Gradient clipping callback — luz_callback_gradient_clip","text":"","code":"luz_callback_gradient_clip(max_norm = 1, norm_type = 2)"},{"path":"/reference/luz_callback_gradient_clip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient clipping callback — luz_callback_gradient_clip","text":"max_norm (float int): max norm gradients norm_type (float int): type used p-norm. Can Inf infinity norm.","code":""},{"path":"/reference/luz_callback_gradient_clip.html","id":"r-f-rences","dir":"Reference","previous_headings":"","what":"Références","title":"Gradient clipping callback — luz_callback_gradient_clip","text":"See FastAI documentation GradientClip callback.","code":""},{"path":"/reference/luz_callback_interrupt.html","id":null,"dir":"Reference","previous_headings":"","what":"Interrupt callback — luz_callback_interrupt","title":"Interrupt callback — luz_callback_interrupt","text":"Adds handler allows interrupting training loop using ctrl + C. Also registers on_interrupt breakpoint users can register callbacks run training loop interruption.","code":""},{"path":"/reference/luz_callback_interrupt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Interrupt callback — luz_callback_interrupt","text":"","code":"luz_callback_interrupt()"},{"path":"/reference/luz_callback_interrupt.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Interrupt callback — luz_callback_interrupt","text":"luz_callback","code":""},{"path":"/reference/luz_callback_interrupt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Interrupt callback — luz_callback_interrupt","text":"general need use callback always included default fit.luz_module_generator().","code":""},{"path":[]},{"path":"/reference/luz_callback_interrupt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Interrupt callback — luz_callback_interrupt","text":"","code":"interrupt_callback <- luz_callback_interrupt()"},{"path":"/reference/luz_callback_keep_best_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Keep the best model — luz_callback_keep_best_model","title":"Keep the best model — luz_callback_keep_best_model","text":"epoch, improvement monitored metric serialize model weights temp file. training done, reload weights best model.","code":""},{"path":"/reference/luz_callback_keep_best_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Keep the best model — luz_callback_keep_best_model","text":"","code":"luz_callback_keep_best_model(   monitor = \"valid_loss\",   mode = \"min\",   min_delta = 0 )"},{"path":"/reference/luz_callback_keep_best_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Keep the best model — luz_callback_keep_best_model","text":"monitor string format <set>_<metric> <set> can 'train' 'valid' <metric> can abbreviation metric tracking training. metric name case insensitive. mode Specifies direction considered improvement. default 'min' used. Can also 'max' (higher better) 'zero' (closer zero better). min_delta Minimum improvement reset patience counter.","code":""},{"path":[]},{"path":"/reference/luz_callback_keep_best_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Keep the best model — luz_callback_keep_best_model","text":"","code":"cb <- luz_callback_keep_best_model()"},{"path":"/reference/luz_callback_lr_scheduler.html","id":null,"dir":"Reference","previous_headings":"","what":"Learning rate scheduler callback — luz_callback_lr_scheduler","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"Initializes runs torch::lr_scheduler()s.","code":""},{"path":"/reference/luz_callback_lr_scheduler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"","code":"luz_callback_lr_scheduler(   lr_scheduler,   ...,   call_on = \"on_epoch_end\",   opt_name = NULL )"},{"path":"/reference/luz_callback_lr_scheduler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"lr_scheduler torch::lr_scheduler() initialized optimizer ... parameters. ... Additional arguments passed lr_scheduler together optimizers. call_on callback breakpoint scheduler$step() called. Default 'on_epoch_end'. See luz_callback() information. opt_name name optimizer affected callback. match name given set_optimizers. module single optimizer, opt_name used.","code":""},{"path":"/reference/luz_callback_lr_scheduler.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"luz_callback() generator.","code":""},{"path":[]},{"path":"/reference/luz_callback_lr_scheduler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"","code":"if (torch::torch_is_installed()) { cb <- luz_callback_lr_scheduler(torch::lr_step, step_size = 30) }"},{"path":"/reference/luz_callback_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Metrics callback — luz_callback_metrics","title":"Metrics callback — luz_callback_metrics","text":"Tracks metrics passed setup() training validation.","code":""},{"path":"/reference/luz_callback_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Metrics callback — luz_callback_metrics","text":"","code":"luz_callback_metrics()"},{"path":"/reference/luz_callback_metrics.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Metrics callback — luz_callback_metrics","text":"luz_callback","code":""},{"path":"/reference/luz_callback_metrics.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Metrics callback — luz_callback_metrics","text":"callback takes care 2 ctx attributes: ctx$metrics: stores current metrics objects initialized epoch, update()d compute()d every batch. rarely need work metrics. ctx$records$metrics: Stores metrics per training/validation epoch. structure similar ctx$losses.","code":""},{"path":"/reference/luz_callback_metrics.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Metrics callback — luz_callback_metrics","text":"general need explicitly use metrics callback used default fit.luz_module_generator().","code":""},{"path":[]},{"path":"/reference/luz_callback_mixed_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic Mixed Precision callback — luz_callback_mixed_precision","title":"Automatic Mixed Precision callback — luz_callback_mixed_precision","text":"callback enable torch::local_autocast() training model forward loss computation. disable autocast scale loss backward() opt$step(). See information.","code":""},{"path":"/reference/luz_callback_mixed_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Automatic Mixed Precision callback — luz_callback_mixed_precision","text":"","code":"luz_callback_mixed_precision(...)"},{"path":"/reference/luz_callback_mixed_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic Mixed Precision callback — luz_callback_mixed_precision","text":"... Passed torch::cuda_amp_grad_scaler().","code":""},{"path":"/reference/luz_callback_mixed_precision.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Automatic Mixed Precision callback — luz_callback_mixed_precision","text":"luz_callback","code":""},{"path":[]},{"path":"/reference/luz_callback_mixup.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixup callback — luz_callback_mixup","title":"Mixup callback — luz_callback_mixup","text":"Implementation 'mixup: Beyond Empirical Risk Minimization'. today, tested categorical data, targets expected integers, one-hot encoded vectors. callback supposed used together nn_mixup_loss().","code":""},{"path":"/reference/luz_callback_mixup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Mixup callback — luz_callback_mixup","text":"","code":"luz_callback_mixup(alpha = 0.4, ..., run_valid = FALSE, auto_loss = FALSE)"},{"path":"/reference/luz_callback_mixup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixup callback — luz_callback_mixup","text":"alpha parameter beta distribution used sample mixing coefficients ... currently unused. Just force named arguments. run_valid run validation auto_loss automatically modify loss function? wrap loss function create mixup loss. TRUE make sure loss function apply reductions. run_valid=FALSE, loss mean reduced validation.","code":""},{"path":"/reference/luz_callback_mixup.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Mixup callback — luz_callback_mixup","text":"luz_callback","code":""},{"path":"/reference/luz_callback_mixup.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Mixup callback — luz_callback_mixup","text":"Overall, follow fastai implementation described . Namely, work single dataloader , randomly mixing two observations batch. linearly combine losses computed targets: loss(output, new_target) = weight * loss(output, target1) + (1-weight) * loss(output, target2) draw different mixing coefficients every pair. replace weight weight = max(weight, 1-weight) avoid duplicates.","code":""},{"path":[]},{"path":"/reference/luz_callback_mixup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Mixup callback — luz_callback_mixup","text":"","code":"if (torch::torch_is_installed()) { mixup_callback <- luz_callback_mixup() }"},{"path":"/reference/luz_callback_model_checkpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Checkpoints model weights — luz_callback_model_checkpoint","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"saves checkpoints model according specified metric behavior.","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"","code":"luz_callback_model_checkpoint(   path,   monitor = \"valid_loss\",   save_best_only = FALSE,   mode = \"min\",   min_delta = 0 )"},{"path":"/reference/luz_callback_model_checkpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"path Path save model disk. path interpolated glue, can use attribute within ctx using '{ctx$epoch}'. Specially epoch monitor quantities already environment. specified path path directory (ends / \\), models saved name given epoch-{epoch:02d}-{self$monitor}-{monitor:.3f}.pt. See examples. can use sprintf() quickly format quantities, example:'{epoch:02d}'. monitor string format <set>_<metric> <set> can 'train' 'valid' <metric> can abbreviation metric tracking training. metric name case insensitive. save_best_only TRUE models saved improvement previously saved model. mode Specifies direction considered improvement. default 'min' used. Can also 'max' (higher better) 'zero' (closer zero better). min_delta Minimum difference consider improvement. used save_best_only=TRUE.","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"mode min_delta used save_best_only=TRUE. save_best_only overwrite saved models path parameter differentiate epochs. Read checkpointing article pkgdown website information.","code":""},{"path":[]},{"path":"/reference/luz_callback_model_checkpoint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"","code":"luz_callback_model_checkpoint(path= \"path/to/dir\") #> <model_checkpoint_callback> #>   Inherits from: <monitor_metrics> #>   Public: #>     call: function (callback_nm)  #>     clone: function (deep = FALSE)  #>     compare: function (new, old)  #>     find_quantity: function ()  #>     fmt_path: function (path)  #>     initialize: function (path, monitor = \"valid_loss\", save_best_only = FALSE,  #>     min_delta: 0 #>     mode: min #>     monitor: valid_loss #>     on_epoch_end: function ()  #>     path: path/to/dir #>     save_best_only: FALSE #>     set_ctx: function (ctx)  luz_callback_model_checkpoint(path= \"path/to/dir/epoch-{epoch:02d}/model.pt\") #> <model_checkpoint_callback> #>   Inherits from: <monitor_metrics> #>   Public: #>     call: function (callback_nm)  #>     clone: function (deep = FALSE)  #>     compare: function (new, old)  #>     find_quantity: function ()  #>     fmt_path: function (path)  #>     initialize: function (path, monitor = \"valid_loss\", save_best_only = FALSE,  #>     min_delta: 0 #>     mode: min #>     monitor: valid_loss #>     on_epoch_end: function ()  #>     path: path/to/dir/epoch-{epoch:02d}/model.pt #>     save_best_only: FALSE #>     set_ctx: function (ctx)  luz_callback_model_checkpoint(path= \"path/to/dir/epoch-{epoch:02d}/model-{monitor:.2f}.pt\") #> <model_checkpoint_callback> #>   Inherits from: <monitor_metrics> #>   Public: #>     call: function (callback_nm)  #>     clone: function (deep = FALSE)  #>     compare: function (new, old)  #>     find_quantity: function ()  #>     fmt_path: function (path)  #>     initialize: function (path, monitor = \"valid_loss\", save_best_only = FALSE,  #>     min_delta: 0 #>     mode: min #>     monitor: valid_loss #>     on_epoch_end: function ()  #>     path: path/to/dir/epoch-{epoch:02d}/model-{monitor:.2f}.pt #>     save_best_only: FALSE #>     set_ctx: function (ctx)"},{"path":"/reference/luz_callback_profile.html","id":null,"dir":"Reference","previous_headings":"","what":"Profile callback — luz_callback_profile","title":"Profile callback — luz_callback_profile","text":"Computes times high-level operations training loops.","code":""},{"path":"/reference/luz_callback_profile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Profile callback — luz_callback_profile","text":"","code":"luz_callback_profile()"},{"path":"/reference/luz_callback_profile.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Profile callback — luz_callback_profile","text":"luz_callback","code":""},{"path":"/reference/luz_callback_profile.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Profile callback — luz_callback_profile","text":"Records saved ctx$records$profile. Times stored seconds. Data stored following structure: fit time entire fit procedure. epoch times per epoch","code":""},{"path":"/reference/luz_callback_profile.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Profile callback — luz_callback_profile","text":"general need use callback always included default fit.luz_module_generator().","code":""},{"path":[]},{"path":"/reference/luz_callback_profile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Profile callback — luz_callback_profile","text":"","code":"profile_callback <- luz_callback_profile()"},{"path":"/reference/luz_callback_progress.html","id":null,"dir":"Reference","previous_headings":"","what":"Progress callback — luz_callback_progress","title":"Progress callback — luz_callback_progress","text":"Responsible printing progress training.","code":""},{"path":"/reference/luz_callback_progress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Progress callback — luz_callback_progress","text":"","code":"luz_callback_progress()"},{"path":"/reference/luz_callback_progress.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Progress callback — luz_callback_progress","text":"luz_callback","code":""},{"path":"/reference/luz_callback_progress.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Progress callback — luz_callback_progress","text":"general need use callback always included default fit.luz_module_generator(). Printing can disabled passing verbose=FALSE fit.luz_module_generator().","code":""},{"path":[]},{"path":"/reference/luz_callback_resume_from_checkpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","title":"Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","text":"Allow resume model training specific checkpoint","code":""},{"path":"/reference/luz_callback_resume_from_checkpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","text":"","code":"luz_callback_resume_from_checkpoint(   path,   ...,   restore_model_state = TRUE,   restore_records = FALSE,   restore_optimizer_state = FALSE,   restore_callbacks_state = FALSE )"},{"path":"/reference/luz_callback_resume_from_checkpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","text":"path Path checkpoint want resume. ... currently unused. restore_model_state Wether restore model state checkpoint. restore_records Wether restore records checkpoint. restore_optimizer_state Wether restore optimizer state checkpoint. restore_callbacks_state Wether restore callbacks state checkpoint.","code":""},{"path":"/reference/luz_callback_resume_from_checkpoint.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Allow resume model training from a specific checkpoint — luz_callback_resume_from_checkpoint","text":"Read checkpointing article pkgdown website information.","code":""},{"path":[]},{"path":"/reference/luz_callback_tfevents.html","id":null,"dir":"Reference","previous_headings":"","what":"tfevents callback — luz_callback_tfevents","title":"tfevents callback — luz_callback_tfevents","text":"Logs metrics model information tfevents file format. Assuming tensorboard installed, result can visualized ","code":""},{"path":"/reference/luz_callback_tfevents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"tfevents callback — luz_callback_tfevents","text":"","code":"luz_callback_tfevents(logdir = \"logs\", histograms = FALSE, ...)"},{"path":"/reference/luz_callback_tfevents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"tfevents callback — luz_callback_tfevents","text":"logdir directory log written . histograms boolean specifying histograms model weights logged. can also character vector specifying name parameters logged (names names(model$parameters)). ... Currently used. future expansion.","code":""},{"path":"/reference/luz_callback_tfevents.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"tfevents callback — luz_callback_tfevents","text":"","code":"tensorboard --logdir=logs"},{"path":"/reference/luz_callback_tfevents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"tfevents callback — luz_callback_tfevents","text":"","code":"if (torch::torch_is_installed()) { library(torch) x <- torch_randn(1000, 10) y <- torch_randn(1000, 1)  model <- nn_linear %>%   setup(loss = nnf_mse_loss, optimizer = optim_adam) %>%   set_hparams(in_features = 10, out_features = 1) %>%   set_opt_hparams(lr = 1e-4)  tmp <- tempfile()  model %>% fit(list(x, y), valid_data = 0.2, callbacks = list(   luz_callback_tfevents(tmp, histograms = TRUE) )) } #> Error in initialize(...): The package \"tfevents\" is required."},{"path":"/reference/luz_callback_train_valid.html","id":null,"dir":"Reference","previous_headings":"","what":"Train-eval callback — luz_callback_train_valid","title":"Train-eval callback — luz_callback_train_valid","text":"Switches important flags training evaluation modes.","code":""},{"path":"/reference/luz_callback_train_valid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Train-eval callback — luz_callback_train_valid","text":"","code":"luz_callback_train_valid()"},{"path":"/reference/luz_callback_train_valid.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Train-eval callback — luz_callback_train_valid","text":"luz_callback","code":""},{"path":"/reference/luz_callback_train_valid.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Train-eval callback — luz_callback_train_valid","text":"takes care three ctx attributes: ctx$model: Responsible calling ctx$model$train() ctx$model$eval(), appropriate. ctx$training: Sets flag TRUE training FALSE validation mode. ctx$loss: Resets loss attribute list() finished training/ validating.","code":""},{"path":"/reference/luz_callback_train_valid.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Train-eval callback — luz_callback_train_valid","text":"general need explicitly use train_valid callback used default fit.luz_module_generator().","code":""},{"path":[]},{"path":"/reference/luz_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Load trained model — luz_load","title":"Load trained model — luz_load","text":"Loads fitted model. See documentation luz_save().","code":""},{"path":"/reference/luz_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Load trained model — luz_load","text":"","code":"luz_load(path)"},{"path":"/reference/luz_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load trained model — luz_load","text":"path path file system object.","code":""},{"path":[]},{"path":"/reference/luz_load_checkpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads a checkpoint — luz_load_checkpoint","title":"Loads a checkpoint — luz_load_checkpoint","text":"Works checkpoints created typically luz_callback_model_checkpoint().","code":""},{"path":"/reference/luz_load_checkpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Loads a checkpoint — luz_load_checkpoint","text":"","code":"luz_load_checkpoint(obj, path, ...)"},{"path":"/reference/luz_load_checkpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loads a checkpoint — luz_load_checkpoint","text":"obj Object want load checkpoint. path Path checkpoint disk. ... unused. allow future extensions.","code":""},{"path":"/reference/luz_load_model_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads model weights into a fitted object. — luz_load_model_weights","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"can useful saved model checkpoints training want reload best checkpoint end.","code":""},{"path":"/reference/luz_load_model_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"","code":"luz_load_model_weights(obj, path, ...)  luz_save_model_weights(obj, path)"},{"path":"/reference/luz_load_model_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"obj luz object want copy new weights. path path saved model disk. ... arguments passed torch_load().","code":""},{"path":"/reference/luz_load_model_weights.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"Returns NULL invisibly.","code":""},{"path":"/reference/luz_load_model_weights.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"luz_save_model_weights operates inplace, ie modifies model object contain new weights.","code":""},{"path":"/reference/luz_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a new luz metric — luz_metric","title":"Creates a new luz metric — luz_metric","text":"Creates new luz metric","code":""},{"path":"/reference/luz_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Creates a new luz metric — luz_metric","text":"","code":"luz_metric(   name = NULL,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame(),   inherit = NULL )"},{"path":"/reference/luz_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a new luz metric — luz_metric","text":"name string naming new metric. ... named list public methods. implement least initialize, update compute. See details section information. private optional list private members, can functions non-functions. active optional list active binding functions. parent_env environment use parent newly-created objects. inherit R6ClassGenerator object inherit ; words, superclass. captured unevaluated expression evaluated parent_env time object instantiated.","code":""},{"path":"/reference/luz_metric.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Creates a new luz metric — luz_metric","text":"Returns new luz metric.","code":""},{"path":"/reference/luz_metric.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Creates a new luz metric — luz_metric","text":"order implement new luz_metric need implement 3 methods: initialize: defines metric initial state. function called epoch training validation loops. update: updates metric internal state. function called every training validation step predictions obtained model target values obtained dataloader. compute: uses internal state compute metric values. function called whenever need obtain current metric value. Eg, ’s called every training step metrics displayed progress bar, called per epoch record ’s value progress bar displayed. Optionally, can implement abbrev field gives metric abbreviation used displaying metric information console tracking record. abbrev passed, class name used. Let’s take look implementation luz_metric_accuracy can see implement new one:   Note: ’s good practice compute metric returns regular R values instead torch tensors parts luz expect .","code":"luz_metric_accuracy <- luz_metric(   # An abbreviation to be shown in progress bars, or   # when printing progress   abbrev = \"Acc\",   # Initial setup for the metric. Metrics are initialized   # every epoch, for both training and validation   initialize = function() {     self$correct <- 0     self$total <- 0   },   # Run at every training or validation step and updates   # the internal state. The update function takes `preds`   # and `target` as parameters.   update = function(preds, target) {     pred <- torch::torch_argmax(preds, dim = 2)     self$correct <- self$correct + (pred == target)$       to(dtype = torch::torch_float())$       sum()$       item()     self$total <- self$total + pred$numel()   },   # Use the internal state to query the metric value   compute = function() {     self$correct/self$total   } )"},{"path":[]},{"path":"/reference/luz_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Creates a new luz metric — luz_metric","text":"","code":"luz_metric_accuracy <- luz_metric(   # An abbreviation to be shown in progress bars, or   # when printing progress   abbrev = \"Acc\",   # Initial setup for the metric. Metrics are initialized   # every epoch, for both training and validation   initialize = function() {     self$correct <- 0     self$total <- 0   },   # Run at every training or validation step and updates   # the internal state. The update function takes `preds`   # and `target` as parameters.   update = function(preds, target) {     pred <- torch::torch_argmax(preds, dim = 2)     self$correct <- self$correct + (pred == target)$       to(dtype = torch::torch_float())$       sum()$       item()     self$total <- self$total + pred$numel()   },   # Use the internal state to query the metric value   compute = function() {     self$correct/self$total   } )"},{"path":"/reference/luz_metric_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Accuracy — luz_metric_accuracy","title":"Accuracy — luz_metric_accuracy","text":"Computes accuracy multi-class classification problems.","code":""},{"path":"/reference/luz_metric_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Accuracy — luz_metric_accuracy","text":"","code":"luz_metric_accuracy()"},{"path":"/reference/luz_metric_accuracy.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Accuracy — luz_metric_accuracy","text":"Returns new luz metric.","code":""},{"path":"/reference/luz_metric_accuracy.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Accuracy — luz_metric_accuracy","text":"metric expects take logits probabilities every update. take columnwise argmax compare target.","code":""},{"path":[]},{"path":"/reference/luz_metric_accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Accuracy — luz_metric_accuracy","text":"","code":"if (torch::torch_is_installed()) { library(torch) metric <- luz_metric_accuracy() metric <- metric$new() metric$update(torch_randn(100, 10), torch::torch_randint(1, 10, size = 100)) metric$compute() } #> [1] 0.17"},{"path":"/reference/luz_metric_binary_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary accuracy — luz_metric_binary_accuracy","title":"Binary accuracy — luz_metric_binary_accuracy","text":"Computes accuracy binary classification problems model returns probabilities. Commonly used loss torch::nn_bce_loss().","code":""},{"path":"/reference/luz_metric_binary_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Binary accuracy — luz_metric_binary_accuracy","text":"","code":"luz_metric_binary_accuracy(threshold = 0.5)"},{"path":"/reference/luz_metric_binary_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary accuracy — luz_metric_binary_accuracy","text":"threshold value used classifiy observations 0 1.","code":""},{"path":"/reference/luz_metric_binary_accuracy.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Binary accuracy — luz_metric_binary_accuracy","text":"Returns new luz metric.","code":""},{"path":[]},{"path":"/reference/luz_metric_binary_accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Binary accuracy — luz_metric_binary_accuracy","text":"","code":"if (torch::torch_is_installed()) { library(torch) metric <- luz_metric_binary_accuracy(threshold = 0.5) metric <- metric$new() metric$update(torch_rand(100), torch::torch_randint(0, 1, size = 100)) metric$compute() } #> [1] 0.48"},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"Computes accuracy binary classification problems model return logits. Commonly used together torch::nn_bce_with_logits_loss().","code":""},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"","code":"luz_metric_binary_accuracy_with_logits(threshold = 0.5)"},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"threshold value used classifiy observations 0 1.","code":""},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"Returns new luz metric.","code":""},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"Probabilities generated using torch::nnf_sigmoid() threshold used classify 0 1.","code":""},{"path":[]},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"","code":"if (torch::torch_is_installed()) { library(torch) metric <- luz_metric_binary_accuracy_with_logits(threshold = 0.5) metric <- metric$new() metric$update(torch_randn(100), torch::torch_randint(0, 1, size = 100)) metric$compute() } #> [1] 0.43"},{"path":"/reference/luz_metric_binary_auroc.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the area under the ROC — luz_metric_binary_auroc","title":"Computes the area under the ROC — luz_metric_binary_auroc","text":"avoid storing predictions targets epoch compute confusion matrices across range pre-established thresholds.","code":""},{"path":"/reference/luz_metric_binary_auroc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Computes the area under the ROC — luz_metric_binary_auroc","text":"","code":"luz_metric_binary_auroc(   num_thresholds = 200,   thresholds = NULL,   from_logits = FALSE )"},{"path":"/reference/luz_metric_binary_auroc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the area under the ROC — luz_metric_binary_auroc","text":"num_thresholds Number thresholds used compute confusion matrices. case, thresholds created getting num_thresholds values linearly spaced unit interval. thresholds (optional) threshold passed, used compute confusion matrices num_thresholds ignored. from_logits Boolean indicating predictions logits, case use sigmoid put unit interval.","code":""},{"path":[]},{"path":"/reference/luz_metric_binary_auroc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Computes the area under the ROC — luz_metric_binary_auroc","text":"","code":"if (torch::torch_is_installed()){ library(torch) actual <- c(1, 1, 1, 0, 0, 0) predicted <- c(0.9, 0.8, 0.4, 0.5, 0.3, 0.2)  y_true <- torch_tensor(actual) y_pred <- torch_tensor(predicted)  m <- luz_metric_binary_auroc(thresholds = predicted) m <- m$new()  m$update(y_pred[1:2], y_true[1:2]) m$update(y_pred[3:4], y_true[3:4]) m$update(y_pred[5:6], y_true[5:6])  m$compute() } #> [1] 0.8888889"},{"path":"/reference/luz_metric_mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean absolute error — luz_metric_mae","title":"Mean absolute error — luz_metric_mae","text":"Computes mean absolute error.","code":""},{"path":"/reference/luz_metric_mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Mean absolute error — luz_metric_mae","text":"","code":"luz_metric_mae()"},{"path":"/reference/luz_metric_mae.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Mean absolute error — luz_metric_mae","text":"Returns new luz metric.","code":""},{"path":[]},{"path":"/reference/luz_metric_mae.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Mean absolute error — luz_metric_mae","text":"","code":"if (torch::torch_is_installed()) { library(torch) metric <- luz_metric_mae() metric <- metric$new() metric$update(torch_randn(100), torch_randn(100)) metric$compute() } #> [1] 1.201094"},{"path":"/reference/luz_metric_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean squared error — luz_metric_mse","title":"Mean squared error — luz_metric_mse","text":"Computes mean squared error","code":""},{"path":"/reference/luz_metric_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Mean squared error — luz_metric_mse","text":"","code":"luz_metric_mse()"},{"path":"/reference/luz_metric_mse.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Mean squared error — luz_metric_mse","text":"luz_metric object.","code":""},{"path":[]},{"path":"/reference/luz_metric_multiclass_auroc.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the multi-class AUROC — luz_metric_multiclass_auroc","title":"Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"definition Keras used default. equivalent 'micro' method SciKit Learn . See docs.","code":""},{"path":"/reference/luz_metric_multiclass_auroc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"","code":"luz_metric_multiclass_auroc(   num_thresholds = 200,   thresholds = NULL,   from_logits = FALSE,   average = c(\"micro\", \"macro\", \"weighted\", \"none\") )"},{"path":"/reference/luz_metric_multiclass_auroc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"num_thresholds Number thresholds used compute confusion matrices. case, thresholds created getting num_thresholds values linearly spaced unit interval. thresholds (optional) threshold passed, used compute confusion matrices num_thresholds ignored. from_logits TRUE call torch::nnf_softmax() predictions computing metric. average averaging method: 'micro': Stack classes computes AUROC binary classification problem. 'macro': Finds AUCROC class computes mean. 'weighted': Finds AUROC class computes weighted mean pondering number instances class. 'none': Returns AUROC class list.","code":""},{"path":"/reference/luz_metric_multiclass_auroc.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"Note class imbalance can affect metric unlike AUC binary classification. Currently AUC approximated using 'interpolation' method described Keras.","code":""},{"path":[]},{"path":"/reference/luz_metric_multiclass_auroc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Computes the multi-class AUROC — luz_metric_multiclass_auroc","text":"","code":"if (torch::torch_is_installed()) { library(torch) actual <- c(1, 1, 1, 0, 0, 0) + 1L predicted <- c(0.9, 0.8, 0.4, 0.5, 0.3, 0.2) predicted <- cbind(1-predicted, predicted)  y_true <- torch_tensor(as.integer(actual)) y_pred <- torch_tensor(predicted)  m <- luz_metric_multiclass_auroc(thresholds = as.numeric(predicted),                                  average = \"micro\") m <- m$new()  m$update(y_pred[1:2,], y_true[1:2]) m$update(y_pred[3:4,], y_true[3:4]) m$update(y_pred[5:6,], y_true[5:6]) m$compute() } #> [1] 0.9027778"},{"path":"/reference/luz_metric_rmse.html","id":null,"dir":"Reference","previous_headings":"","what":"Root mean squared error — luz_metric_rmse","title":"Root mean squared error — luz_metric_rmse","text":"Computes root mean squared error.","code":""},{"path":"/reference/luz_metric_rmse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Root mean squared error — luz_metric_rmse","text":"","code":"luz_metric_rmse()"},{"path":"/reference/luz_metric_rmse.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Root mean squared error — luz_metric_rmse","text":"Returns new luz metric.","code":""},{"path":[]},{"path":"/reference/luz_metric_set.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a metric set — luz_metric_set","title":"Creates a metric set — luz_metric_set","text":"metric set can used specify metrics evaluated training, validation .","code":""},{"path":"/reference/luz_metric_set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Creates a metric set — luz_metric_set","text":"","code":"luz_metric_set(metrics = NULL, train_metrics = NULL, valid_metrics = NULL)"},{"path":"/reference/luz_metric_set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a metric set — luz_metric_set","text":"metrics list luz_metrics meant used training validation. train_metrics list luz_metrics used training. valid_metrics list luz_metrics sued validation.","code":""},{"path":"/reference/luz_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves luz objects to disk — luz_save","title":"Saves luz objects to disk — luz_save","text":"Allows saving luz fitted models disk. Objects can loaded back luz_load().","code":""},{"path":"/reference/luz_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Saves luz objects to disk — luz_save","text":"","code":"luz_save(obj, path, ...)"},{"path":"/reference/luz_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves luz objects to disk — luz_save","text":"obj object class 'luz_module_fitted' returned fit.luz_module_generator(). path path file system object. ... currently unused.","code":""},{"path":"/reference/luz_save.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Saves luz objects to disk — luz_save","text":"Objects saved plain .rds files obj$model serialized torch_save saving .","code":""},{"path":"/reference/luz_save.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Saves luz objects to disk — luz_save","text":"ctx naively serialized. Ie, use saveRDS() serialize . expect luz_save work correctly unserializable objects ctx like torch_tensors external pointers general.","code":""},{"path":[]},{"path":"/reference/nn_mixup_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Loss to be used with callbacks_mixup(). — nn_mixup_loss","title":"Loss to be used with callbacks_mixup(). — nn_mixup_loss","text":"training phase, computes individual losses regard two targets, weights item-wise, averages linear combinations yield mean batch loss. validation testing, defers passed-loss.","code":""},{"path":"/reference/nn_mixup_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Loss to be used with callbacks_mixup(). — nn_mixup_loss","text":"","code":"nn_mixup_loss(loss)"},{"path":"/reference/nn_mixup_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loss to be used with callbacks_mixup(). — nn_mixup_loss","text":"loss underlying loss nn_module call. must support reduction field. training attribute changed 'none' get loss individual observations. See example documentation reduction argument torch::nn_cross_entropy_loss().","code":""},{"path":"/reference/nn_mixup_loss.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Loss to be used with callbacks_mixup(). — nn_mixup_loss","text":"used together luz_callback_mixup().","code":""},{"path":[]},{"path":"/reference/nnf_mixup.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixup logic — nnf_mixup","title":"Mixup logic — nnf_mixup","text":"Logic underlying luz_callback_mixup().","code":""},{"path":"/reference/nnf_mixup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Mixup logic — nnf_mixup","text":"","code":"nnf_mixup(x, y, weight)"},{"path":"/reference/nnf_mixup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixup logic — nnf_mixup","text":"x input batch y target batch weight weighting coefficient used torch_lerp()","code":""},{"path":"/reference/nnf_mixup.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Mixup logic — nnf_mixup","text":"list : x, new, mixed-input batch y, list : ys, list : y1, original target y1 y2, mixed-target y2 weight, mixing weights","code":""},{"path":"/reference/nnf_mixup.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Mixup logic — nnf_mixup","text":"Based passed-input target batches, well applicable mixing weights, return new tensors intended replace current batch. new input batch weighted linear combination input batch items, new target batch bundles original targets, well mixing weights, nested list.","code":""},{"path":[]},{"path":"/reference/nnf_mixup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Exemples","title":"Mixup logic — nnf_mixup","text":"","code":"if (torch::torch_is_installed()) { batch_x <- torch::torch_randn(c(10, 768)) batch_y <- torch::torch_randn(10) weight <- torch::torch_tensor(rep(0.9, 10))$view(c(10, 1)) nnf_mixup(batch_x, batch_y, weight) } #> $x #> torch_tensor #> Columns 1 to 6-1.2872e+00  1.4136e+00 -1.8332e+00 -3.3090e-01 -6.2604e-02  4.9432e-01 #> -1.3356e+00  1.0655e+00 -1.7194e+00  6.3000e-01 -6.8845e-01 -5.4155e-01 #>  2.6973e-01 -7.7269e-01  6.5100e-02  1.7287e-01  3.1672e-01 -2.2210e-01 #> -2.2688e+00 -6.1553e-02  6.5188e-01 -1.0883e+00  6.5451e-01 -6.8778e-01 #> -1.2350e-01  2.0100e+00 -1.8573e+00 -1.6985e+00 -9.1957e-01 -1.3777e-01 #> -2.0071e+00  1.5060e+00 -5.5942e-01  6.6334e-01 -6.9282e-01 -5.1689e-01 #>  6.3580e-01  2.0953e+00 -5.1135e-01  1.2231e+00  5.8742e-01 -6.1801e-01 #>  3.5529e-01  9.4825e-02  9.1851e-02  1.2833e-01  4.1424e-01 -1.0497e+00 #>  1.5839e-01  8.1604e-02  2.5780e-01  3.3110e-01 -2.8754e-01  7.9522e-01 #> -1.4099e+00  6.3899e-01  1.4118e+00 -1.1758e-02  6.3748e-01  6.4040e-01 #>  #> Columns 7 to 12 3.8770e-01 -2.6008e-01  6.1713e-01  9.0991e-01  2.8134e-01 -1.6521e-01 #> -4.2641e-01 -2.4860e-01 -1.0575e+00 -8.6838e-02  1.2945e+00 -2.4839e-01 #> -1.6721e-01 -1.6053e+00 -2.7452e-01  4.3914e-01  2.1941e-01 -6.5136e-01 #>  1.3890e-01 -1.0123e+00 -9.5899e-01 -2.0832e-02  5.2870e-01 -9.1342e-01 #>  3.2569e-01 -1.1673e+00  4.4014e-01  6.5711e-02  4.7709e-01  9.2014e-01 #>  8.8352e-01 -7.7464e-01 -4.7670e-01  2.2341e-01 -1.0183e+00 -9.8432e-02 #>  6.0511e-01 -1.6345e+00  1.3650e+00 -5.8359e-03  5.9221e-01 -8.7911e-02 #>  4.5094e-01 -2.7169e-01  1.5902e-01  7.3119e-01 -4.4887e-01 -1.5678e+00 #>  4.3740e-01 -1.5929e+00 -1.1334e+00 -2.8646e-01  1.6739e-02 -6.5084e-01 #> -1.0448e-01  1.4012e+00  1.2077e+00 -1.1542e+00 -4.9482e-01  3.2530e-01 #>  #> Columns 13 to 18-6.0305e-01 -1.6426e+00 -1.0482e+00  5.6974e-01 -5.8220e-01  2.0411e-01 #> -8.3677e-01  4.3185e-01  9.4704e-01 -5.2285e-01 -8.1141e-01  4.4026e-01 #> -1.6233e+00 -6.1969e-01  7.2057e-01 -1.3143e-01  1.0091e+00  2.2572e+00 #> -3.9286e-01  2.0943e+00  5.6198e-01  8.2051e-03 -8.4941e-01 -1.2467e+00 #> -5.7834e-01 -1.1068e+00 -4.8212e-02  5.2835e-02 -3.9035e-01 -1.9520e-01 #> -1.2165e+00 -7.3154e-01  8.7099e-01  1.2784e+00 -6.2991e-02 -2.2427e-02 #> -1.7835e-01  3.0908e-01  6.6114e-01 -1.6927e-01  8.8997e-01 -1.4978e+00 #>  6.2390e-01 -6.4348e-01  7.5932e-01 -8.7637e-01  2.5107e+00  3.3675e-01 #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{10,768} ] #>  #> $y #> $y$ys #> $y$ys$y1 #> torch_tensor #>  1.4264 #>  0.2039 #> -0.1360 #>  0.3177 #>  1.1650 #> -0.3436 #> -0.9074 #>  0.0631 #> -0.4187 #>  0.3716 #> [ CPUFloatType{10} ] #>  #> $y$ys$y2 #> torch_tensor #>  1.1650 #> -0.3436 #> -0.4187 #>  0.3716 #>  0.2039 #>  1.4264 #>  0.0631 #> -0.9074 #>  0.3177 #> -0.1360 #> [ CPUFloatType{10} ] #>  #>  #> $y$weight #> torch_tensor #>  0.9000 #>  0.9000 #>  0.9000 #>  0.9000 #>  0.9000 #>  0.9000 #>  0.9000 #>  0.9000 #>  0.9000 #>  0.9000 #> [ CPUFloatType{10,1} ] #>  #>"},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/predict.luz_module_fitted.html","id":null,"dir":"Reference","previous_headings":"","what":"Create predictions for a fitted model — predict.luz_module_fitted","title":"Create predictions for a fitted model — predict.luz_module_fitted","text":"Create predictions fitted model","code":""},{"path":"/reference/predict.luz_module_fitted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Create predictions for a fitted model — predict.luz_module_fitted","text":"","code":"# Méthode S3 pour la classe luz_module_fitted predict(   object,   newdata,   ...,   callbacks = list(),   accelerator = NULL,   verbose = NULL,   dataloader_options = NULL )"},{"path":"/reference/predict.luz_module_fitted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create predictions for a fitted model — predict.luz_module_fitted","text":"object (fitted model) fitted model object returned fit.luz_module_generator() newdata (dataloader, dataset, list array) returning list least 1 element. elements used. ... Currently unused. callbacks (list, optional) list callbacks defined luz_callback() called training procedure. callbacks luz_callback_metrics(), luz_callback_progress() luz_callback_train_valid() always added default. accelerator (accelerator, optional) optional accelerator() object used configure device placement components like nn_modules, optimizers batches data. verbose (logical, optional) optional boolean value indicating fitting procedure emit output console training. default, produce output interactive() TRUE, otherwise print console. dataloader_options Options used creating dataloader. See torch::dataloader(). shuffle=TRUE default training data batch_size=32 default. error NULL data already dataloader.","code":""},{"path":[]},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics fit","code":""},{"path":"/reference/set_hparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Set hyper-parameter of a module — set_hparams","title":"Set hyper-parameter of a module — set_hparams","text":"function used define hyper-parameters calling fit luz_modules.","code":""},{"path":"/reference/set_hparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Set hyper-parameter of a module — set_hparams","text":"","code":"set_hparams(module, ...)"},{"path":"/reference/set_hparams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set hyper-parameter of a module — set_hparams","text":"module nn_module setup(). ... parameters set used initialize nn_module, ie passed unchanged initialize method base nn_module.","code":""},{"path":"/reference/set_hparams.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Set hyper-parameter of a module — set_hparams","text":"luz module","code":""},{"path":[]},{"path":"/reference/set_opt_hparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Set optimizer hyper-parameters — set_opt_hparams","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"function used define hyper-parameters optimizer initialization method.","code":""},{"path":"/reference/set_opt_hparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"","code":"set_opt_hparams(module, ...)"},{"path":"/reference/set_opt_hparams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"module nn_module setup(). ... parameters passed used initialize optimizers. example, optimizer optim_adam pass lr=0.1, optim_adam function called optim_adam(parameters, lr=0.1) fitting model.","code":""},{"path":"/reference/set_opt_hparams.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"luz module","code":""},{"path":[]},{"path":"/reference/setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Set's up a nn_module to use with luz — setup","title":"Set's up a nn_module to use with luz — setup","text":"setup function used set important attributes method nn_modules used luz.","code":""},{"path":"/reference/setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Utilisation","title":"Set's up a nn_module to use with luz — setup","text":"","code":"setup(module, loss = NULL, optimizer = NULL, metrics = NULL, backward = NULL)"},{"path":"/reference/setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set's up a nn_module to use with luz — setup","text":"module (nn_module) nn_module want set . loss (function, optional) optional function signature function(input, target). requires nn_module implement method called loss. optimizer (torch_optimizer, optional) function signature function(parameters, ...) used initialize optimizer given model parameters. metrics (list, optional) list metrics tracked training procedure. Sometimes, want metrics evaluated training validation, case can pass luz_metric_set() object specify metrics used stage. backward (function) functions takes loss scalar values parameter. must call $backward() torch::autograd_backward(). general need set parameter unless need customize luz calls backward(), example, need add additional arguments backward call. Note becomes method nn_module thus can used custom step() override .","code":""},{"path":"/reference/setup.html","id":"valeur-de-retour","dir":"Reference","previous_headings":"","what":"Valeur de retour","title":"Set's up a nn_module to use with luz — setup","text":"luz module can trained fit().","code":""},{"path":"/reference/setup.html","id":"d-tails","dir":"Reference","previous_headings":"","what":"Détails","title":"Set's up a nn_module to use with luz — setup","text":"makes sure module necessary ingredients order fitted.","code":""},{"path":"/reference/setup.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Set's up a nn_module to use with luz — setup","text":"also adds device active field can used query current module device within methods, eg self$device. useful ctx() available, eg, calling methods outside luz wrappers. Users can override default implementing device active method input module.","code":""},{"path":[]},{"path":"/news/index.html","id":"luzfr-040","dir":"Changelog","previous_headings":"","what":"luz.fr 0.4.0","title":"luz.fr 0.4.0","text":"Initial help translation.","code":""}]
