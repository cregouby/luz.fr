title:
  original: Loss to be used with \code{callbacks_mixup()}.
  translation: ~
arguments:
  loss:
    original: |-
      the underlying loss \code{nn_module} to call. It must
      support the \code{reduction} field. During training the attribute will be changed to
      \code{'none'} so we get the loss for individual observations. See for for example
      documentation for the \code{reduction} argument in \code{\link[torch:nn_cross_entropy_loss]{torch::nn_cross_entropy_loss()}}.
    translation: ~
description:
  original: |
    In the training phase, computes individual losses with regard to two targets, weights them item-wise,
    and averages the linear combinations to yield the mean batch loss.
    For validation and testing, defers to the passed-in loss.
  translation: ~
details:
  original: |
    It should be used together with \code{\link[=luz_callback_mixup]{luz_callback_mixup()}}.
  translation: ~
seealso:
  original: |
    \code{\link[=luz_callback_mixup]{luz_callback_mixup()}}
  translation: ~
untranslatable:
- alias
- name
- keyword
- concept
- usage
