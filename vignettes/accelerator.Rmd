---
title: "L'API des accélérateurs"
output: rmarkdown::html_vignette
lang: fr
vignette: >
  %\VignetteIndexEntry{L'API des accélérateurs}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(luz)
```

L'API des accélérateurs est une API de gestion des périphériques d'accélération de calcul. C'est une version simplifiée de la [bibliothèque Accelerate](https://github.com/huggingface/accelerate) de Hugging Face.
Elle permet aux développeurs d'éviter le code de gestion nécessaire pour écrire les boucles d'apprentissage qui fonctionnent correctement sur plusieurs périphériques de calcul (les CPUs et les GPUs).
Actuellement, elle ne gère que l'utilisation des CPUs et d'un unique GPU.

Cette API est conçue pour permettre un développement plus flexible des réseaux et des `nn_modules` gérés par luz. 
Vous écrivez le code torch d'apprentissage brut et, après quelques modifications, l'API s'occupe automatiquement 
du deploiement sur les périphériques de calcul de l'ensemble  modèle, optimiseurs et chargeurs de donnée. Vous n'avez donc plus besoin 
d'ajouter à tout moment des `$to(device="cuda")` dans votre code ou penser à l'ordre dans lequel créer le modèle et les optimiseurs.

## Exemple

L'usage est facile à comprendre sur un exemple de différence `diff` du code avec une boucle d'apprentissage torch brut.

```diff
library(torch)
+ library(luz)

+ acc <- accelerator()
- device <- "cpu"

data <- tensor_dataset(
  x = torch_randn(100, 10),
  y = torch_rand(100, 1)
)

dl <- dataloader(data, batch_size = 10)

model <- nn_linear(10, 1)
- model$to(device = device)
opt <- optim_adam(model$parameters)

+ c(model, opt, dl) %<-% acc$prepare(model, opt, dl)

model$train()
coro::loop(for (batch in dl) {

  opt$zero_grad()

-  preds <- model(batch$x$to(device = device))
+  preds <- model(batch$x)
-  loss <- nnf_mse_loss(preds, batch$y$to(device = device))
+  loss <- nnf_mse_loss(preds, batch$y)

  loss$backward()
  opt$step()
})
```

Au travers des modifications de code mises en valeur, vous comprenez que vous n'avez plus besoin de déplacer manuellement les données et les modèles entre périphériques, ce qui rend votre code plus lisible et moins sujet aux erreurs.

Vous pouvez trouver des informations supplémentaires en utilisant `help(accelerator)`.
