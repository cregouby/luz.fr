---
title: "Boucles personnalisées avec luz"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Boucles personnalisées avec luz}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup}
library(torch)
library(luz)
```

Luz est une interface d'API plus élevée pour torch conçue pour être très flexible, permettant ainsi d'avoir un contrôle total sur la boucle d'entraînement.

Dans la vignette "débutant", nous avons vu les bases de luz et comment modifier facilement des parties de la boucle d'entraînement à l'aide de rappels 
(callbacks) et de métriques personnalisées. 
Dans ce document, nous allons décrire en détail comment luz permet à l'utilisateur d'avoir un contrôle très fin sur la boucle d'entraînement.

Outre l'utilisation de callbacks, il existe trois autres façons d'utiliser luz (en fonction du niveau de contrôle nécessaire) :

-   **Optimiseurs ou fonctions de perte multiples** : Vous pouvez optimiser deux fonctions de perte chacune avec son propre optimiseur, tout en maintenant la 
possibilité de ne pas modifier les appels `backward()` - `zero_grad()` et `step()`. C'est commun dans les modèles comme les GANs (Réseaux Adversaires 
Génératifs) lorsqu'on a des réseaux neuronaux concurrents entraînés avec différentes pertes et optimiseurs.

-   **Étapes complètement flexibles** : Vous pouvez contrôler complètement comment appeler `backward()`, `zero_grad()` et `step()`. Vous pouvez aussi 
avoir un contrôle plus grand sur la calcul de gradients. Par exemple, vous pouvez utiliser des 'tailles de lot virtuelles', où vous accumulez les 
gradients pendant quelques étapes avant d'actualiser les poids.

-   **Boucles complètement flexibles** : Votre boucle d'entraînement peut être absolument n'importe quoi, mais vous voulez toujours utiliser luz pour gérer 
le déplacement vers un périphérique des chargeurs de données, optimiseurs et modèles. Voir la vignette "accélérateur" .

Considérons une version simplifiée du `net` que nous avons implémenté dans la vignette de début :

```{r}
net <- nn_module(
  "Net",
  initialize = function() {
    self$fc1 <- nn^A_linear(100, 50)
    self$fc2 <- nn_linear(50, ^A10)
  },
  forward = function(x) {
    x %>% 
      self$fc1() %>% 
      nnf_relu() %>% 
      self$fc2()
  }
)
```

En utilisant l'API de luz au plus haut niveau, on peut l'entraîner comme suit :

```{r}
fitted <- net %>%
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_adam,
    metrics = list(
      luz_metric_accuracy
    )
  ) %>%
  fit(train_dl, epochs = 10, valid_data = test_dl)
```

## Optimiseurs multiples

Supposons que nous voulions faire une expérience où nous formons la première couche de connexion complète avec un taux d'apprentissage de 0.1 et la 
deuxième avec un taux d'apprentissage de 0.01.
Nous allons minimiser la même `nn_cross_entropy_loss()` pour les deux, mais pour la première couche nous voulons ajouter une régularisation L1.

```{r}
net <- nn_module(
  "Net",
  initialize = function() {
    self$fc1 <- nn_linear(100, 50) %>%
      l1()
    self$fc2 <- nn_linear(50, 10)
  },
  forward = function(x) {
    x %>% 
      self$fc1() %>% 
      nnf_relu() %>% 
      self$fc2()
  }
)
```

Nous pouvons finalement utiliser `setup` et `fit` sur ce module, mais nous ne devons plus spécifier les optimiseurs et les fonctions de perte.


```{r}
fitted <- net %>% 
  setup(metrics = list(luz_metric_accuracy)) %>% 
  fit(train_dl, epochs = 10, valid_data = test_dl)
```

Maintenant, nous allons re-implementer ce même modèle en utilisant une approche légèrement plus flexible qui consiste à surcharger l'étape d'apprentissage et de validation.

## Étape complètement flexible

Au lieu d'implémenter la méthode `loss()`, nous pouvons implémenter la méthode `step()`.
Cela permet de modifier en toute flexibilité ce qui se passe lors de l'apprentissage et de la validation pour chaque lot dans le jeu de données. 
Vous êtes maintenant responsable de mettre à jour les poids en faisant un pas vers les optimiseurs et d'effectuer une propagation de la perte.

```{r}
net <- nn_module(
  "Net",
  initialize = function() {
    self$fc1 <- nn_linear(100, 50)
    self$fc1 <- nn_linear(50, 10)
  },
  forward = function(x) {
    x %>% 
      self$fc1() %>% 
      nnf_relu() %>% 
      self$fc2()
  },
  set_optimizers = function(lr_fc1 = 0.1, lr_fc2 = 0.01) {
    list(
      opt_fc1 = optim_adam(self$fc1$parameters, lr = lr_fc1),
      opt_fc2 = optim_adam(self$fc2$parameters, lr = lr_fc2)
    )
  },
  step = function() {
    ctx$loss <- list()
    for (opt_name in names(ctx$optimizers)) {
    
      ctx$pred <- ctx$model(ctx$input)
      opt <- ctx$optimizers[[opt_name]]
      loss <- nnf_cross_entropy(pred, target)
      
      if (opt_name == "opt_fc1") {
        # nous avons une régularisation L1 dans la couche 1
        loss <- nnf_cross_entropy(pred, target) + 
          torch_norm(self$fc1$weight, p = 1)
      }
        
      if (ctx$training) {
        opt$zero_grad()
        loss$backward()
        opt$step()  
      }
      
      ctx$loss[[opt_name]] <- loss$detach()
    }
  }
)
```

Les choses importantes à noter ici sont :

-   La méthode `step()` est utilisée pour l'apprentissage et la validation. Vous devez être prudent car vous ne devez modifier les poids que lorsque vous 
êtes en apprentissage. Encore une fois, vous pouvez obtenir des informations complètes sur l'objet de contexte avec `help("ctx")`.

-   `ctx$optimizers` est une liste nommée contenant chaque optimiseur qui a été créé lorsqu'on appelait la méthode `set_optimizers()`.

-   Vous devez suivre les pertes en cours de modification en les enregistrant dans une liste nommée dans `ctx$loss`. Conformément à la convention, nous 
utilisons le même nom que l'optimiseur auquel elle se réfère. Une bonne pratique consiste à les déconnecter avant leur sauvegarde pour réduire la 
consommation de mémoire.

-   Les rappels qui seraient appelés dans la méthode `step()` par défaut comme `on_train_batch_after_pred`, `on_train_batch_after_loss`, etc., ne seront 
pas automatiquement appelés. Vous pouvez toujours les appeler manuellement en ajoutant `ctx$call_callbacks("<nom du rappel>`)` à l'intérieur de votre 
étape d'apprentissage. Voir le code pour `fit_one_batch()` et `valid_one_batch` pour trouver tous les rappels qui ne seront pas appelés.

- Si vous voulez que les métriques luz fonctionnent avec votre méthode `step()` personnalisée, vous devez assigner `ctx$pred` aux prédictions du modèle 
car les métriques seront toujours appelées avec `metric$update(ctx$pred, ctx$target)`.

## Étapes suivantes

Dans cet article, vous avez appris à personnaliser l'étape de formation du boucle d'apprentissage en utilisant la fonctionnalité multi-couche de luz.

Luz permet également des modifications plus flexibles de la boucle d'apprentissage décrites dans le vignette "Accélérateur" (`vignette("accelerator")`).

Vous devriez maintenant pouvoir suivre les exemples marqués avec les catégories 'intermédiaire' et 'avancé' dans la galerie des 
[exemples](https://mlverse.github.io/luz/articles/examples/index.html) de luz

---

Tous les exemples mentionnés ci-dessus sont disponibles en ligne.
