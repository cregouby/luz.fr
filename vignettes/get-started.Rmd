---
title: "Get started with luz"
output: rmarkdown::html_vignette
lang: fr
vignette: >
  %\VignetteIndexEntry{Get started with luz}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(luz)
library(torch)
```


Luz est une API de haut niveau pour torch qui vise à encapsuler la **boucle d'entraînement** dans un ensemble de blocs de code réutilisables.
Luz réduit le code de gestion requis pour former un modèle avec torch et évite les erreurs fréquentes sur la séquence des appels à `zero_grad()` - `backward()` - `step()`, et simplifie également le processus de déplacement des données et des modèles entre les CPUs et la GPU.
Luz est conçu pour être très flexible en fournissant une API en couches qui lui permet d'être utile quel que soit le niveau de contrôle dont vous avez besoin pour votre boucle d'entraînement.

Luz est fortement inspiré par d'autres framework de haut-niveau  pour l'apprentissage profond, pour citer quelques-uns:

- [FastAI](https://docs.fast.ai/): nous avons été fortement inspirés par la bibliothèque FastAI, en particulier l'objet `Learner` et l'API callbacks.

- [Keras](https://keras.io/): Nous sommes également fortement inspirés par Keras, en particulier les noms de callback. L'interface du module `lightning` est aussi similaire à `compile`.

- [PyTorch Lightning](https://lightning.ai/pages/open-source/): L'idée que le `luz_module` soit une sous-classe de `nn_module` s'inspire de l'objet **`LightningModule`** dans la `lightning`.

- [HuggingFace Accelerate](https://huggingface.co/docs/accelerate/): L'API interne de placement sur les périphériques de calcul est fortement inspirée par Accelerate, mais est beaucoup plus modeste dans les fonctionnalités.

## Entraînement d'un `nn_module`

Luz tente, autant que possible, de réutiliser les structures existantes de torch.
Un modèle en luz est défini de la même manière que vous le définiriez si vous utilisez torch brut.
Par exemple, voici la définition d'un CNN feed-forward qui peut être utilisé pour classer les chiffres de l'ensemble de données MNIST:
```{r, eval = FALSE}
net <- nn_module(
  "Net",
  initialize = function(num_class) {
    self$conv1 <- nn_conv2d(1, 32, 3, 1)
    self$conv2 <- nn_conv2d(32, 64, 3, 1)
    self$dropout1 <- nn_dropout2d(0.25)
    self$dropout2 <- nn_dropout2d(0.5)
    self$fc1 <- nn_linear(9216, 128)
    self$fc2 <- nn_linear(128, num_class)
  },
  forward = function(x) {
    x <- self$conv1(x)
    x <- nnf_relu(x)
    x <- self$conv2(x)
    x <- nnf_relu(x)
    x <- nnf_max_pool2d(x, 2)
    x <- self$dropout1(x)
    x <- torch_flatten(x, start_dim = 2)
    x <- self$fc1(x)
    x <- nnf_relu(x)
    x <- self$dropout2(x)
    x <- self$fc2(x)
    x
  }
)
```


Nous pouvons maintenant entraîner ce modèle dans le `train_dl` et l'évaluer dans le `torch::dataloaders()` nomé `test_dl` avec:
```{r, eval = FALSE}
fitted <- net %>%
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_adam,
    metrics = list(
      luz_metric_accuracy
    )
  ) %>%
  set_hparams(num_class = 10) %>% 
  set_opt_hparams(lr = 0.003) %>% 
  fit(train_dl, epochs = 10, valid_data = test_dl)
```


Voyons en détail ce qui se passe dans ce bloc de code :

1. La fonction `setup` vous permet de configurer la fonction de coût (objectif) et l'optimiseur que vous utiliserez pour entraîner votre modèle. En option, vous pouvez passer une liste de métriques qui sont suivies pendant la procédure d'apprentissage. **Remarque** : la fonction de coût peut être n'importe quelle fonction prenant en entrée `input` et `target` et retournant une valeur de tenseur scalaire, et l'optimiseur peut être n'importe quel optimiseur de torch natif ou personnalisé, créé avec la fonction `torch::optimizer()`.
2. La fonction `set_hparams()` permet de définir les hyper-paramètres qui doivent être passées à la méthode `initialize()` du module. Par exemple dans ce cas nous passons `num_classes = 10`.
3. La fonction `set_opt_hparams()` vous permet de passer des hyper-paramètres utilisés par la fonction d'optimisation. Par exemple, `optim_adam()` peut prendre le paramètre `lr` spécifiant le taux d'apprentissage et nous le spécifions avec `lr = 0.003`.
4. La méthode `fit` va prendre les spécifications du modèle fournies par `setup()` et exécuter le processus d'apprentissage en utilisant les jeux de donnée d'entraînement et de validation spécifiés dans des `torch::dataloaders()` ainsi que le nombre d'époques. **Remarque** : nous réutilisons les structures de données de base de torch pour les chargeurs de donnée, au lieu de recréer notre propre fonctionnalité de chargement de données.
5. L ' objet retourné `fitted` contient le modèle entraîné ainsi que le registre de métriques et de pertes produites au cours de l'apprentissage. Il peut également être utilisé pour la production de prédictions et l'évaluation du modèle entraîné sur d'autres jeux de données.

Au moment du déploiement du calcul, luz utilisera l'accélérateur le plus rapide possible; si un GPU doté de CUDA est disponible, il sera utilisé, sinon le calcul sera affecté sur la CPU.
Il déplace également automatiquement les données, les optimisateurs et les modèles vers le périphérique sélectionné afin que vous n'ayez pas besoin de les manipuler manuellement (qui constitue une grande source d'erreurs en général).

Pour créer des prédictions à partir du modèle entraîné, vous pouvez utiliser la méthode `predict`:

```{r, eval = FALSE}
predictions <- predict(fitted, test_dl)
```


## La boucle d'entraînement

Maintenant que vous avez une idée générale de la façon d'utiliser la fonction `fit`, il est important d'avoir un aperçu de ce qui se passe à l'intérieur.
Voici ce que `fit` exécute (en pseudocode).
Ce n'est pas détaillé complètement, mais celà devrait vous aider à construire votre intuition:

```{r, eval = FALSE}
# -> Initialiser les objets : modèle, optimiseurs.
# -> Sélectionner le périphérique d'apprentissage.
# -> Déplacer les données, le modèle et les optimiseurs vers le dispositif sélectionné.
# -> Lancer l'apprentissage
for (epoch in 1:epochs) {
  # -> Procédure d'apprentissage
  for (batch in train_dl) {
    # -> Calculer la méthode `forward` du modèle.
    # -> Calculer la perte.
    # -> Mettre à jour les poids.
    # -> Mettre à jour les métriques et suivre la perte.
  }
  # -> Procédure de validation
  for (batch in valid_dl) {
    # -> Calculer la méthode `forward` du modèle.
    # -> Calculer la perte.
    # -> Mettre à jour les métriques et suivre la perte.
  }
}
# -> Fin de l'apprentissage
```


## Les métriques

L'une des parties les plus importantes des projets d'apprentissage automatique est le choix de la métrique d'évaluation.
Luz permet de suivre de nombreuses métriques différentes pendant l'apprentissage avec des changements de code minimes.

Pour suivre les métriques, il suffit de modifier le paramètre `metrics` dans la fonction `setup`:

```{r, eval=FALSE}
fitted <- net %>%
  setup(
    ...
    metrics = list(
      luz_metric_accuracy
    )
  ) %>%
  fit(...)
```


Luz fournit des implémentations de quelques-unes des métriques les plus utilisées.
Si une métrique n'est pas disponible, vous pouvez toujours la mettre en place à l'aide de la fonction `luz_metric`.

```{r, child='../man/rmd/metrics.Rmd'}
```

## Évaluation

```{r, child='../man/rmd/evaluate.Rmd'}
```


## Personnalisation avec les callbacks

Luz fournit différentes façons de personnaliser la boucle d'apprentissage, en fonction du niveau de contrôle dont vous avez besoin pendant qu'elle s'exécute.
La façon la plus rapide et la plus « réutilisable » est via les **callbacks**. Ils permettent de créer des modifications d'apprentissage qui peuvent être utilisées dans de nombreuses situations.

La boucle d'apprentissage en luz a de nombreux *points d'arrêt* qui peuvent appeler des fonctions R arbitraires.
Cette fonctionnalité vous permet de personnaliser le processus d'apprentissage sans avoir à modifier la logique générale de l'apprentissage.

Luz implémente 3 callbacks par défaut qui se produisent dans chaque procédure d'apprentissage :

-   **callback train-eval**: Bascule le modèle en `train()` ou `eval()` selon si la procédure est en cours de  d'entraînement ou de validation.

-   **callback metrics** : évaluer les paramètres au cours du processus d'entraînement et de validation.

-   **callback progress** : implémente une barre de progression et imprime des informations sur la progression pendant l'apprentissage.

Vous pouvez également mettre en place des callbacks personnalisés qui modifient ou agissent spécifiquement pour votre procédure d'apprentissage.
Par exemple:

```{r, child='../man/rmd/callbacks.Rmd'}
```

```{r, child='../man/rmd/ctx.Rmd'}
```



Les attributs de `ctx` peuvent être utilisés pour produire le comportement souhaité des callbacks.
Vous pouvez trouver de plus amples informations sur l'objet de contexte à l'aide de `help("ctx")`. 
Dans notre exemple, nous utilisons l'attribut `ctx$iter` pour imprimer le numéro d'itération pour chaque lot d'apprentissage.

## Étapes suivantes

Dans cet article, vous avez appris à entraîner votre premier modèle en utilisant luz et les bases de la personnalisation en utilisant à la fois des métriques personnalisées et des callbacks.

Luz permet également des modifications plus flexibles du processus d'apprentissage décrites dans `vignette("custom-loop")`.

Vous devriez maintenant être en mesure de suivre les exemples marqués avec la catégorie 'basique' dans la [galerie d'exemples](https://mlverse.github.io/luz/articles/examples/index.html).
